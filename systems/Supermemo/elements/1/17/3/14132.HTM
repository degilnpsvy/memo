<SPAN class=arabic>2</SPAN>.<SPAN class=arabic>3</SPAN>.<SPAN class=arabic>3</SPAN> Dijkstra Revisited 
<P><A name=2932></A>
<P>So far two different kinds of dynamic programming have been covered. The value-iteration method of Section <A href="http://planning.cs.uiuc.edu/node56.html#sec:dopgc">2.3.2</A> involves repeated computations over the entire state space. Dijkstra's algorithm from Section <A href="http://planning.cs.uiuc.edu/node41.html#sec:partsearch">2.2.2</A> flows only once through the state space, but with the additional overhead of maintaining which states are <EM>alive</EM>.<A name=2936></A> 
<P>Dijkstra's algorithm can be derived by focusing on the forward value iterations, as in Example <A href="http://planning.cs.uiuc.edu/node56.html#exa:fivestate3">2.5</A>, and identifying exactly where the ``interesting'' changes occur. Recall that for Dijkstra's algorithm, it was assumed that all costs are nonnegative. For any states that are not reachable, their values remain at infinity. They are precisely the <EM>unvisited</EM> states. States for which the optimal cost-to-come has already become stationary are <EM>dead</EM>. For the remaining states, an initial cost is obtained, but this cost may be lowered one or more times until the optimal cost is obtained. All states for which the cost is finite, but possibly not optimal, are in the queue, <SPAN class=MATH><IMG height=34 alt="$ {Q}$" src="http://planning.cs.uiuc.edu/img7.gif" width=20 align=middle border=0></SPAN>. 
<P>After understanding value iteration, it is easier to understand why Dijkstra's form of dynamic programming correctly computes optimal solutions. It is clear that the unvisited states will remain at infinity in both algorithms because no plan has reached them. It is helpful to consider the forward value iterations in Example <A href="http://planning.cs.uiuc.edu/node56.html#exa:fivestate3">2.5</A> for comparison. In a sense, Dijkstra's algorithm is very much like the value iteration, except that it efficiently maintains the set of states within which cost-to-go values can change. It correctly inserts any states that are reached for the first time, changing their cost-to-come from infinity to a finite value. The values are changed in the same manner as in the value iterations. At the end of both algorithms, the resulting values correspond to the stationary, optimal cost-to-come, <SPAN class=MATH><IMG height=17 alt="$ C^*$" src="http://planning.cs.uiuc.edu/img310.gif" width=27 align=bottom border=0></SPAN>. 
<P>If Dijkstra's algorithm seems so clever, then why have we spent time covering the value-iteration method? For some problems it may become too expensive to maintain the sorted queue, and value iteration could provide a more efficient alternative. A more important reason is that value iteration extends easily to a much broader class of problems. Examples include optimal planning over continuous state spaces (Sections <A href="http://planning.cs.uiuc.edu/node406.html#sec:appvalit">8.5.2</A> and <A href="http://planning.cs.uiuc.edu/node783.html#sec:fmpdc">14.5</A>), stochastic optimal planning (Section <A href="http://planning.cs.uiuc.edu/node490.html#sec:algfeedplan">10.2</A>), and computing dynamic game equilibria (Section <A href="http://planning.cs.uiuc.edu/node518.html#sec:sgame">10.5</A>). In some cases, it is still possible to obtain a Dijkstra-like algorithm by focusing the computation on the ``interesting'' region; however, as the model becomes more complicated, it may be inefficient or impossible in practice to maintain this region. Therefore, it is important to have a good understanding of both algorithms to determine which is most appropriate for a given problem. 
<P>
<DIV align=center><A name=fig:labcor></A><A name=3355></A>
<TABLE>
<CAPTION align=bottom><STRONG>Figure 2.16:</STRONG> A generalization of Dijkstra's algorithm, which upon termination produces an optimal plan (if one exists) for any prioritization of <SPAN class=MATH><IMG height=34 alt="$ {Q}$" src="http://planning.cs.uiuc.edu/img7.gif" width=20 align=middle border=0></SPAN>, as long as <SPAN class=MATH><IMG height=17 alt="$ X$" src="http://planning.cs.uiuc.edu/img8.gif" width=22 align=bottom border=0></SPAN> is finite. Compare this to Figure <A href="http://planning.cs.uiuc.edu/node40.html#fig:gfs">2.4</A>.</CAPTION>
<TBODY>
<TR>
<TD><IMG height=265 alt="\begin{figure}\noindent \rule{\columnwidth}{0.25mm}&#10;FORWARD\_LABEL\_CORRECTING($...&#10;...{Q}.Insert(x')$ \\&#10;\end{tabular} \\&#10;\rule{\columnwidth}{0.25mm}\end{figure}" src="http://planning.cs.uiuc.edu/img504.gif" width=556 border=0></TD></TR></TBODY></TABLE></DIV>
<P><A name=2964></A>Dijkstra's algorithm belongs to a broader family of <EM>label-correcting algorithms</EM><A name=4074></A>, which all produce optimal plans by making small modifications to the general forward-search algorithm in Figure <A href="http://planning.cs.uiuc.edu/node40.html#fig:gfs">2.4</A>. Figure <A href="http://planning.cs.uiuc.edu/node57.html#fig:labcor">2.16</A> shows the resulting algorithm. The main difference is to allow states to become alive<A name=2968></A> again if a better cost-to-come is found. This enables other cost-to-come values to be improved accordingly. This is not important for Dijkstra's algorithm and <SPAN class=MATH><IMG height=17 alt="$ A^*$" src="http://planning.cs.uiuc.edu/img288.gif" width=26 align=bottom border=0></SPAN> search because they only need to visit each state once. Thus, the algorithms in Figures <A href="http://planning.cs.uiuc.edu/node40.html#fig:gfs">2.4</A> and <A href="http://planning.cs.uiuc.edu/node57.html#fig:labcor">2.16</A> are essentially the same in this case. However, the label-correcting algorithm produces optimal solutions for any sorting of <SPAN class=MATH><IMG height=34 alt="$ {Q}$" src="http://planning.cs.uiuc.edu/img7.gif" width=20 align=middle border=0></SPAN>, including FIFO (breadth first) and LIFO (depth first), as long as <SPAN class=MATH><IMG height=17 alt="$ X$" src="http://planning.cs.uiuc.edu/img8.gif" width=22 align=bottom border=0></SPAN> is finite. If <SPAN class=MATH><IMG height=17 alt="$ X$" src="http://planning.cs.uiuc.edu/img8.gif" width=22 align=bottom border=0></SPAN> is not finite, then the issue of systematic search dominates because one must guarantee that states are revisited sufficiently many times to guarantee that optimal solutions will eventually be found. 
<P>Another important difference between label-correcting algorithms and the standard forward-search model is that the label-correcting approach uses the cost at the goal state to prune away many candidate paths; this is shown in line 7. Thus, it is only formulated to work for a single goal state; it can be adapted to work for multiple goal states, but performance degrades. The motivation for including <!-- MATH
 $C({x_{G}})$
 --><SPAN class=MATH><IMG height=37 alt="$ C({x_{G}})$" src="http://planning.cs.uiuc.edu/img505.gif" width=56 align=middle border=0></SPAN> in line 7 is that there is no need to worry about improving costs at some state, <SPAN class=MATH><IMG height=18 alt="$ x'$" src="http://planning.cs.uiuc.edu/img254.gif" width=20 align=bottom border=0></SPAN>, if its new cost-to-come would be higher than <!-- MATH
 $C({x_{G}})$
 --><SPAN class=MATH><IMG height=37 alt="$ C({x_{G}})$" src="http://planning.cs.uiuc.edu/img505.gif" width=56 align=middle border=0></SPAN>; there is no way it could be along a path that improves the cost to go to <SPAN class=MATH><IMG height=33 alt="$ {x_{G}}$" src="http://planning.cs.uiuc.edu/img215.gif" width=27 align=middle border=0></SPAN>. Similarly, <SPAN class=MATH><IMG height=33 alt="$ {x_{G}}$" src="http://planning.cs.uiuc.edu/img215.gif" width=27 align=middle border=0></SPAN> is not inserted in line 10 because there is no need to consider plans that have <SPAN class=MATH><IMG height=33 alt="$ {x_{G}}$" src="http://planning.cs.uiuc.edu/img215.gif" width=27 align=middle border=0></SPAN> as an intermediate state. To recover the plan, either pointers can be stored from <SPAN class=MATH><IMG height=17 alt="$ x$" src="http://planning.cs.uiuc.edu/img86.gif" width=15 align=bottom border=0></SPAN> to <SPAN class=MATH><IMG height=18 alt="$ x'$" src="http://planning.cs.uiuc.edu/img254.gif" width=20 align=bottom border=0></SPAN> each time an update is made in line 7, or the final, optimal cost-to-come, <SPAN class=MATH><IMG height=17 alt="$ C^*$" src="http://planning.cs.uiuc.edu/img310.gif" width=27 align=bottom border=0></SPAN>, can be used to recover the actions using (<A href="http://planning.cs.uiuc.edu/node56.html#eqn:ctcgen">2.20</A>). <A name=2972></A><A name=2973></A><A name=2974></A>