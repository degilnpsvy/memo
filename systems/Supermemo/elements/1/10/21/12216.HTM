<B><SPAN style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt" lang=EN-US>The PCIe host interface</SPAN></B> 
<P></P>
<P><SPAN style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt" lang=EN-US>From a graphics programmer standpoint, this piece of hardware isn&#8217;t super-interesting. Actually, the same probably goes for a GPU hardware architect too. The thing is, you still start caring about it once it&#8217;s so slow that it&#8217;s a bottleneck. So what you do is get good people on it to do it properly, to make sure that doesn&#8217;t happen. Other than that, well, this gives the CPU read/write access to video memory and a bunch of GPU registers, the GPU read/write access to (a portion of) main memory, and everyone a headache because the latency for all these transactions is even worse than memory latency because the signals have to go out of the chip, into the slot, travel a bit across the mainboard then get to someplace in the CPU about a week later (or that&#8217;s how it feels compared to the CPU/GPU speeds anyway). <FONT class=extract>The bandwidth is decent though &#8211; up to about 8GB/s (theoretical) peak aggregate bandwidth across the 16-lane PCIe 2.0 connections that most GPUs use right now, so between half and a third of the aggregate CPU memory bandwidth; that&#8217;s a usable ratio. And unlike earlier standards like AGP, this is a symmetrical point-to-point link &#8211; that bandwidth goes both directions; AGP had a fast channel from the CPU to the GPU, but not the other way round.</FONT></SPAN>