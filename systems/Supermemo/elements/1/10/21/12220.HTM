<B><SPAN lang=EN-US style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt">Synchronization</SPAN></B>
<P></P>
<P><SPAN lang=EN-US style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt">Finally, the last family of commands deals with CPU/GPU and GPU/GPU synchronization.</SPAN></P>
<P><SPAN lang=EN-US style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt">Generally, all of these have the form &#8220;if event X happens, do Y&#8221;. I&#8217;ll deal with the &#8220;do Y&#8221; part first &#8211; there&#8217;s two sensible options for what Y can be here: it can be a push-model notification where the GPU yells at the CPU to do something&nbsp;<I>right now</I>&nbsp;(&#8220;Oi! CPU! I&#8217;m entering the vertical blanking interval on display 0 right now, so if you want to flip buffers without tearing, this would be the time to do it!&#8221;), or it can be a pull-model thing where the GPU just memorizes that something happened and the CPU can later ask about it (&#8220;Say, GPU, what was the most recent command buffer fragment you started processing?&#8221; &#8211; &#8220;Let me check&#8230; sequence id 303.&#8221;). The former is typically implemented using interrupts and only used for infrequent and high-priority events because interrupts are fairly expensive. All you need for the latter is some CPU-visible GPU registers and a way to write values into them from the command buffer once a certain event happens.</SPAN></P>
<P><SPAN lang=EN-US style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt">Say you have 16 such registers. Then you could assign current CommandBufferSeqId&nbsp;to register 0. You assign a sequence number to every command buffer you submit to the GPU (this is in the KMD), and then at the start of each command buffer, you add a &#8220;If you get to this point in the command buffer, write to register 0&#8243;. And voila, now we know which command buffer the GPU is currently chewing on! And we know that the command processor finishes commands strictly in sequence, so if the first command in command buffer 303 was executed, that means all command buffers up to and including sequence id 302 are finished and can now be reclaimed by the KMD, freed, modified, or turned into a cheesy amusement park.</SPAN></P>
<P><SPAN lang=EN-US style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt">We also now have an example of what X could be: &#8220;if you get here&#8221; &#8211; perhaps the simplest example, but already useful. Other examples are &#8220;if all shaders have finished all texture reads coming from batches before this point in the command buffer&#8221; (this marks safe points to reclaim texture/render target memory), &#8220;if rendering to all active render targets/UAVs has completed&#8221; (this marks points at which you can actually safely use them as textures), &#8220;if all operations up to this point are fully completed&#8221;, and so on.</SPAN></P>
<P><SPAN lang=EN-US style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt">Such operations are usually called &#8220;fences&#8221;, by the way. There&#8217;s different methods of picking the values you write into the status registers, but as far as I am concerned, the only sane way to do it is to use a sequential counter for this (probably stealing some of the bits for other information). Yeah, I&#8217;m really just dropping that one piece of random information without any rationale whatsoever here, because I think you should know. I might elaborate on it in a later blog post (though not in this series) :).</SPAN></P>
<P><SPAN lang=EN-US style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt">So, we got one half of it &#8211; we can now report status back from the GPU to the CPU, which allows us to do sane memory management in our drivers (notably, we can now find out when it&#8217;s safe to actually reclaim memory used for vertex buffers, command buffers, textures and other resources). But that&#8217;s not all of it &#8211; there&#8217;s a puzzle piece missing. What if we need to synchronize purely on the GPU side, for example? Let&#8217;s go back to the render target example. We can&#8217;t use that as a texture until the rendering is actually finished (and some other steps have taken place &#8211; more details on that once I get to the texturing units). The solution is a &#8220;wait&#8221;-style instruction: &#8220;Wait until register M contains value N&#8221;. This can either be a compare for equality, or less-than (note you need to deal with wraparounds here!), or more fancy stuff &#8211; I&#8217;m just going with equals for simplicity. This allows us to do the render target sync before we submit a batch. It also allows us to build a full GPU flush operation: &#8220;Set register 0 to ++seqId if all pending jobs finished&#8221; / &#8220;Wait until register 0 contains seqId&#8221;. Done and done. GPU/GPU synchronization: solved &#8211; and until the introduction of DX11 with Compute Shaders that have another type of more fine-grained synchronization, this was usually the&nbsp;<I>only</I>&nbsp;synchronization mechanism you had on the GPU side. For regular rendering, you simply don&#8217;t need more.</SPAN></P>
<P><SPAN lang=EN-US style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt">By the way, if you can write these registers from the CPU side, you can use this the other way too &#8211; submit a partial command buffer including a wait for a particular value, and then change the register from the CPU instead of the GPU. This kind of thing can be used to implement D3D11-style multithreaded rendering where you can submit a batch that references vertex/index buffers that are still locked on the CPU side (probably being written to by another thread). You simply stuff the wait just in front of the actual render call, and then the CPU can change the contents of the register once the vertex/index buffers are actually unlocked. If the GPU never got that far in the command buffer, the wait is now a no-op; if it did, it spend some (command processor) time spinning until the data was actually there. Pretty nifty, no? Actually, you can implement this kind of thing even without CPU-writeable status registers if you can modify the command buffer after you submit it, as long as there&#8217;s a command buffer &#8220;jump&#8221; instruction. The details are left to the interested reader :)</SPAN></P>
<P><SPAN lang=EN-US style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt">Of course, you don&#8217;t necessarily need the set register/wait register model; for GPU/GPU synchronization, you can just as simply have a &#8220;rendertarget barrier&#8221; instruction that makes sure a rendertarget is safe to use, and a &#8220;flush everything&#8221; command. But I like the set register-style model more because it kills two birds (back-reporting of in-use resources to the CPU, and GPU self-synchronization) with one well-designed stone.</SPAN></P>
<P><B><SPAN lang=EN-US style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt">Update:</SPAN></B><SPAN lang=EN-US style="FONT-SIZE: 16.5pt; mso-bidi-font-size: 12.0pt">&nbsp;Here, I&#8217;ve drawn&nbsp;<A href="http://www.daili987.com/weibo.com.php?u=uWbqpkPTKji0QsE1ZK2MyjMvnWFYUX4ywPXF5HFUIWV0ilTYSTRHOUY84isqhMgeUgk%3D&amp;b=3"><B>a diagram</B></A>&nbsp;for you. It got a bit convoluted so I&#8217;m going to lower the amount of detail in the future. The basic idea is this: The command processor has a FIFO in front, then the command decode logic, execution is handled by various blocks that communicate with the 2D unit, 3D front-end (regular 3D rendering) or shader units directly (compute shaders), then there&#8217;s a block that deals with sync/wait commands (which has the publicly visible registers I talked about), and one unit that handles command buffer jumps/calls (which changes the current fetch address that goes to the FIFO). And all of the units we dispatch work to need to send us back completion events so we know when e.g. textures aren&#8217;t being used anymore and their memory can be reclaimed.</SPAN>