# Documentation/RCU/checklist.txt
<P></P>
<P>Review Checklist for RCU Patches</P>
<P></P>
<P><BR>This document contains a checklist for producing and reviewing patches<BR>that make use of RCU.&nbsp; Violating any of the rules listed below will<BR>result in the same sorts of problems that leaving out a locking primitive<BR>would cause.&nbsp; This list is based on experiences reviewing such patches<BR>over a rather long period of time, but improvements are always welcome!</P>
<P>0.&nbsp;Is RCU being applied to a read-mostly situation?&nbsp; If the data<BR>&nbsp;structure is updated more than about 10% of the time, then you<BR>&nbsp;should strongly consider some other approach, unless detailed<BR>&nbsp;performance measurements show that RCU is nonetheless the right<BR>&nbsp;tool for the job.&nbsp; Yes, RCU does reduce read-side overhead by<BR>&nbsp;increasing write-side overhead, which is exactly why normal uses<BR>&nbsp;of RCU will do much more reading than updating.</P>
<P>&nbsp;Another exception is where performance is not an issue, and RCU<BR>&nbsp;provides a simpler implementation.&nbsp; An example of this situation<BR>&nbsp;is the dynamic NMI code in the Linux 2.6 kernel, at least on<BR>&nbsp;architectures where NMIs are rare.</P>
<P>&nbsp;Yet another exception is where the low real-time latency of RCU's<BR>&nbsp;read-side primitives is critically important.</P>
<P>1.&nbsp;Does the update code have proper mutual exclusion?</P>
<P>&nbsp;RCU does allow -readers- to run (almost) naked, but -writers- must<BR>&nbsp;still use some sort of mutual exclusion, such as:</P>
<P>&nbsp;a.&nbsp;locking,<BR>&nbsp;b.&nbsp;atomic operations, or<BR>&nbsp;c.&nbsp;restricting updates to a single task.</P>
<P>&nbsp;If you choose #b, be prepared to describe how you have handled<BR>&nbsp;memory barriers on weakly ordered machines (pretty much all of<BR>&nbsp;them -- even x86 allows later loads to be reordered to precede<BR>&nbsp;earlier stores), and be prepared to explain why this added<BR>&nbsp;complexity is worthwhile.&nbsp; If you choose #c, be prepared to<BR>&nbsp;explain how this single task does not become a major bottleneck on<BR>&nbsp;big multiprocessor machines (for example, if the task is updating<BR>&nbsp;information relating to itself that other tasks can read, there<BR>&nbsp;by definition can be no bottleneck).</P>
<P>2.&nbsp;Do the RCU read-side critical sections make proper use of<BR>&nbsp;rcu_read_lock() and friends?&nbsp; These primitives are needed<BR>&nbsp;to prevent grace periods from ending prematurely, which<BR>&nbsp;could result in data being unceremoniously freed out from<BR>&nbsp;under your read-side code, which can greatly increase the<BR>&nbsp;actuarial risk of your kernel.</P>
<P>&nbsp;As a rough rule of thumb, any dereference of an RCU-protected<BR>&nbsp;pointer must be covered by rcu_read_lock(), rcu_read_lock_bh(),<BR>&nbsp;rcu_read_lock_sched(), or by the appropriate update-side lock.<BR>&nbsp;Disabling of preemption can serve as rcu_read_lock_sched(), but<BR>&nbsp;is less readable.</P>
<P>3.&nbsp;Does the update code tolerate concurrent accesses?</P>
<P>&nbsp;The whole point of RCU is to permit readers to run without<BR>&nbsp;any locks or atomic operations.&nbsp; This means that readers will<BR>&nbsp;be running while updates are in progress.&nbsp; There are a number<BR>&nbsp;of ways to handle this concurrency, depending on the situation:</P>
<P>&nbsp;a.&nbsp;Use the RCU variants of the list and hlist update<BR>&nbsp;&nbsp;primitives to add, remove, and replace elements on<BR>&nbsp;&nbsp;an RCU-protected list.&nbsp;Alternatively, use the other<BR>&nbsp;&nbsp;RCU-protected data structures that have been added to<BR>&nbsp;&nbsp;the Linux kernel.</P>
<P>&nbsp;&nbsp;This is almost always the best approach.</P>
<P>&nbsp;b.&nbsp;Proceed as in (a) above, but also maintain per-element<BR>&nbsp;&nbsp;locks (that are acquired by both readers and writers)<BR>&nbsp;&nbsp;that guard per-element state.&nbsp; Of course, fields that<BR>&nbsp;&nbsp;the readers refrain from accessing can be guarded by<BR>&nbsp;&nbsp;some other lock acquired only by updaters, if desired.</P>
<P>&nbsp;&nbsp;This works quite well, also.</P>
<P>&nbsp;c.&nbsp;Make updates appear atomic to readers.&nbsp; For example,<BR>&nbsp;&nbsp;pointer updates to properly aligned fields will<BR>&nbsp;&nbsp;appear atomic, as will individual atomic primitives.<BR>&nbsp;&nbsp;Sequences of perations performed under a lock will -not-<BR>&nbsp;&nbsp;appear to be atomic to RCU readers, nor will sequences<BR>&nbsp;&nbsp;of multiple atomic primitives.</P>
<P>&nbsp;&nbsp;This can work, but is starting to get a bit tricky.</P>
<P>&nbsp;d.&nbsp;Carefully order the updates and the reads so that<BR>&nbsp;&nbsp;readers see valid data at all phases of the update.<BR>&nbsp;&nbsp;This is often more difficult than it sounds, especially<BR>&nbsp;&nbsp;given modern CPUs' tendency to reorder memory references.<BR>&nbsp;&nbsp;One must usually liberally sprinkle memory barriers<BR>&nbsp;&nbsp;(smp_wmb(), smp_rmb(), smp_mb()) through the code,<BR>&nbsp;&nbsp;making it difficult to understand and to test.</P>
<P>&nbsp;&nbsp;It is usually better to group the changing data into<BR>&nbsp;&nbsp;a separate structure, so that the change may be made<BR>&nbsp;&nbsp;to appear atomic by updating a pointer to reference<BR>&nbsp;&nbsp;a new structure containing updated values.</P>
<P>4.&nbsp;Weakly ordered CPUs pose special challenges.&nbsp; Almost all CPUs<BR>&nbsp;are weakly ordered -- even x86 CPUs allow later loads to be<BR>&nbsp;reordered to precede earlier stores.&nbsp; RCU code must take all of<BR>&nbsp;the following measures to prevent memory-corruption problems:</P>
<P>&nbsp;a.&nbsp;Readers must maintain proper ordering of their memory<BR>&nbsp;&nbsp;accesses.&nbsp; The rcu_dereference() primitive ensures that<BR>&nbsp;&nbsp;the CPU picks up the pointer before it picks up the data<BR>&nbsp;&nbsp;that the pointer points to.&nbsp; This really is necessary<BR>&nbsp;&nbsp;on Alpha CPUs.&nbsp;If you don't believe me, see:</P>
<P>&nbsp;&nbsp;&nbsp;<A href="http://www.openvms.compaq.com/wizard/wiz_2637.html">http://www.openvms.compaq.com/wizard/wiz_2637.html</A></P>
<P>&nbsp;&nbsp;The rcu_dereference() primitive is also an excellent<BR>&nbsp;&nbsp;documentation aid, letting the person reading the code<BR>&nbsp;&nbsp;know exactly which pointers are protected by RCU.<BR>&nbsp;&nbsp;Please note that compilers can also reorder code, and<BR>&nbsp;&nbsp;they are becoming increasingly aggressive about doing<BR>&nbsp;&nbsp;just that.&nbsp; The rcu_dereference() primitive therefore<BR>&nbsp;&nbsp;also prevents destructive compiler optimizations.</P>
<P>&nbsp;&nbsp;The rcu_dereference() primitive is used by the<BR>&nbsp;&nbsp;various "_rcu()" list-traversal primitives, such<BR>&nbsp;&nbsp;as the list_for_each_entry_rcu().&nbsp; Note that it is<BR>&nbsp;&nbsp;perfectly legal (if redundant) for update-side code to<BR>&nbsp;&nbsp;use rcu_dereference() and the "_rcu()" list-traversal<BR>&nbsp;&nbsp;primitives.&nbsp; This is particularly useful in code that<BR>&nbsp;&nbsp;is common to readers and updaters.&nbsp; However, lockdep<BR>&nbsp;&nbsp;will complain if you access rcu_dereference() outside<BR>&nbsp;&nbsp;of an RCU read-side critical section.&nbsp; See lockdep.txt<BR>&nbsp;&nbsp;to learn what to do about this.</P>
<P>&nbsp;&nbsp;Of course, neither rcu_dereference() nor the "_rcu()"<BR>&nbsp;&nbsp;list-traversal primitives can substitute for a good<BR>&nbsp;&nbsp;concurrency design coordinating among multiple updaters.</P>
<P>&nbsp;b.&nbsp;If the list macros are being used, the list_add_tail_rcu()<BR>&nbsp;&nbsp;and list_add_rcu() primitives must be used in order<BR>&nbsp;&nbsp;to prevent weakly ordered machines from misordering<BR>&nbsp;&nbsp;structure initialization and pointer planting.<BR>&nbsp;&nbsp;Similarly, if the hlist macros are being used, the<BR>&nbsp;&nbsp;hlist_add_head_rcu() primitive is required.</P>
<P>&nbsp;c.&nbsp;If the list macros are being used, the list_del_rcu()<BR>&nbsp;&nbsp;primitive must be used to keep list_del()'s pointer<BR>&nbsp;&nbsp;poisoning from inflicting toxic effects on concurrent<BR>&nbsp;&nbsp;readers.&nbsp; Similarly, if the hlist macros are being used,<BR>&nbsp;&nbsp;the hlist_del_rcu() primitive is required.</P>
<P>&nbsp;&nbsp;The list_replace_rcu() and hlist_replace_rcu() primitives<BR>&nbsp;&nbsp;may be used to replace an old structure with a new one<BR>&nbsp;&nbsp;in their respective types of RCU-protected lists.</P>
<P>&nbsp;d.&nbsp;Rules similar to (4b) and (4c) apply to the "hlist_nulls"<BR>&nbsp;&nbsp;type of RCU-protected linked lists.</P>
<P>&nbsp;e.&nbsp;Updates must ensure that initialization of a given<BR>&nbsp;&nbsp;structure happens before pointers to that structure are<BR>&nbsp;&nbsp;publicized.&nbsp; Use the rcu_assign_pointer() primitive<BR>&nbsp;&nbsp;when publicizing a pointer to a structure that can<BR>&nbsp;&nbsp;be traversed by an RCU read-side critical section.</P>
<P>5.&nbsp;If call_rcu(), or a related primitive such as call_rcu_bh(),<BR>&nbsp;call_rcu_sched(), or call_srcu() is used, the callback function<BR>&nbsp;must be written to be called from softirq context.&nbsp; In particular,<BR>&nbsp;it cannot block.</P>
<P>6.&nbsp;Since synchronize_rcu() can block, it cannot be called from<BR>&nbsp;any sort of irq context.&nbsp; The same rule applies for<BR>&nbsp;synchronize_rcu_bh(), synchronize_sched(), synchronize_srcu(),<BR>&nbsp;synchronize_rcu_expedited(), synchronize_rcu_bh_expedited(),<BR>&nbsp;synchronize_sched_expedite(), and synchronize_srcu_expedited().</P>
<P>&nbsp;The expedited forms of these primitives have the same semantics<BR>&nbsp;as the non-expedited forms, but expediting is both expensive<BR>&nbsp;and unfriendly to real-time workloads.&nbsp;Use of the expedited<BR>&nbsp;primitives should be restricted to rare configuration-change<BR>&nbsp;operations that would not normally be undertaken while a real-time<BR>&nbsp;workload is running.</P>
<P>&nbsp;In particular, if you find yourself invoking one of the expedited<BR>&nbsp;primitives repeatedly in a loop, please do everyone a favor:<BR>&nbsp;Restructure your code so that it batches the updates, allowing<BR>&nbsp;a single non-expedited primitive to cover the entire batch.<BR>&nbsp;This will very likely be faster than the loop containing the<BR>&nbsp;expedited primitive, and will be much much easier on the rest<BR>&nbsp;of the system, especially to real-time workloads running on<BR>&nbsp;the rest of the system.</P>
<P>&nbsp;In addition, it is illegal to call the expedited forms from<BR>&nbsp;a CPU-hotplug notifier, or while holding a lock that is acquired<BR>&nbsp;by a CPU-hotplug notifier.&nbsp; Failing to observe this restriction<BR>&nbsp;will result in deadlock.</P>
<P>7.&nbsp;If the updater uses call_rcu() or synchronize_rcu(), then the<BR>&nbsp;corresponding readers must use rcu_read_lock() and<BR>&nbsp;rcu_read_unlock().&nbsp; If the updater uses call_rcu_bh() or<BR>&nbsp;synchronize_rcu_bh(), then the corresponding readers must<BR>&nbsp;use rcu_read_lock_bh() and rcu_read_unlock_bh().&nbsp; If the<BR>&nbsp;updater uses call_rcu_sched() or synchronize_sched(), then<BR>&nbsp;the corresponding readers must disable preemption, possibly<BR>&nbsp;by calling rcu_read_lock_sched() and rcu_read_unlock_sched().<BR>&nbsp;If the updater uses synchronize_srcu() or call_srcu(),<BR>&nbsp;the the corresponding readers must use srcu_read_lock() and<BR>&nbsp;srcu_read_unlock(), and with the same srcu_struct.&nbsp; The rules for<BR>&nbsp;the expedited primitives are the same as for their non-expedited<BR>&nbsp;counterparts.&nbsp; Mixing things up will result in confusion and<BR>&nbsp;broken kernels.</P>
<P>&nbsp;One exception to this rule: rcu_read_lock() and rcu_read_unlock()<BR>&nbsp;may be substituted for rcu_read_lock_bh() and rcu_read_unlock_bh()<BR>&nbsp;in cases where local bottom halves are already known to be<BR>&nbsp;disabled, for example, in irq or softirq context.&nbsp; Commenting<BR>&nbsp;such cases is a must, of course!&nbsp; And the jury is still out on<BR>&nbsp;whether the increased speed is worth it.</P>
<P>8.&nbsp;Although synchronize_rcu() is slower than is call_rcu(), it<BR>&nbsp;usually results in simpler code.&nbsp; So, unless update performance is<BR>&nbsp;critically important, the updaters cannot block, or the latency of<BR>&nbsp;synchronize_rcu() is visible from userspace, synchronize_rcu()<BR>&nbsp;should be used in preference to call_rcu().&nbsp; Furthermore,<BR>&nbsp;kfree_rcu() usually results in even simpler code than does<BR>&nbsp;synchronize_rcu() without synchronize_rcu()'s multi-millisecond<BR>&nbsp;latency.&nbsp; So please take advantage of kfree_rcu()'s "fire and<BR>&nbsp;forget" memory-freeing capabilities where it applies.</P>
<P>&nbsp;An especially important property of the synchronize_rcu()<BR>&nbsp;primitive is that it automatically self-limits: if grace periods<BR>&nbsp;are delayed for whatever reason, then the synchronize_rcu()<BR>&nbsp;primitive will correspondingly delay updates.&nbsp; In contrast,<BR>&nbsp;code using call_rcu() should explicitly limit update rate in<BR>&nbsp;cases where grace periods are delayed, as failing to do so can<BR>&nbsp;result in excessive realtime latencies or even OOM conditions.</P>
<P>&nbsp;Ways of gaining this self-limiting property when using call_rcu()<BR>&nbsp;include:</P>
<P>&nbsp;a.&nbsp;Keeping a count of the number of data-structure elements<BR>&nbsp;&nbsp;used by the RCU-protected data structure, including<BR>&nbsp;&nbsp;those waiting for a grace period to elapse.&nbsp; Enforce a<BR>&nbsp;&nbsp;limit on this number, stalling updates as needed to allow<BR>&nbsp;&nbsp;previously deferred frees to complete.&nbsp;Alternatively,<BR>&nbsp;&nbsp;limit only the number awaiting deferred free rather than<BR>&nbsp;&nbsp;the total number of elements.</P>
<P>&nbsp;&nbsp;One way to stall the updates is to acquire the update-side<BR>&nbsp;&nbsp;mutex.&nbsp;(Don't try this with a spinlock -- other CPUs<BR>&nbsp;&nbsp;spinning on the lock could prevent the grace period<BR>&nbsp;&nbsp;from ever ending.)&nbsp; Another way to stall the updates<BR>&nbsp;&nbsp;is for the updates to use a wrapper function around<BR>&nbsp;&nbsp;the memory allocator, so that this wrapper function<BR>&nbsp;&nbsp;simulates OOM when there is too much memory awaiting an<BR>&nbsp;&nbsp;RCU grace period.&nbsp; There are of course many other<BR>&nbsp;&nbsp;variations on this theme.</P>
<P>&nbsp;b.&nbsp;Limiting update rate.&nbsp; For example, if updates occur only<BR>&nbsp;&nbsp;once per hour, then no explicit rate limiting is required,<BR>&nbsp;&nbsp;unless your system is already badly broken.&nbsp; The dcache<BR>&nbsp;&nbsp;subsystem takes this approach -- updates are guarded<BR>&nbsp;&nbsp;by a global lock, limiting their rate.</P>
<P>&nbsp;c.&nbsp;Trusted update -- if updates can only be done manually by<BR>&nbsp;&nbsp;superuser or some other trusted user, then it might not<BR>&nbsp;&nbsp;be necessary to automatically limit them.&nbsp; The theory<BR>&nbsp;&nbsp;here is that superuser already has lots of ways to crash<BR>&nbsp;&nbsp;the machine.</P>
<P>&nbsp;d.&nbsp;Use call_rcu_bh() rather than call_rcu(), in order to take<BR>&nbsp;&nbsp;advantage of call_rcu_bh()'s faster grace periods.</P>
<P>&nbsp;e.&nbsp;Periodically invoke synchronize_rcu(), permitting a limited<BR>&nbsp;&nbsp;number of updates per grace period.</P>
<P>&nbsp;The same cautions apply to call_rcu_bh(), call_rcu_sched(),<BR>&nbsp;call_srcu(), and kfree_rcu().</P>
<P>9.&nbsp;All RCU list-traversal primitives, which include<BR>&nbsp;rcu_dereference(), list_for_each_entry_rcu(), and<BR>&nbsp;list_for_each_safe_rcu(), must be either within an RCU read-side<BR>&nbsp;critical section or must be protected by appropriate update-side<BR>&nbsp;locks.&nbsp;RCU read-side critical sections are delimited by<BR>&nbsp;rcu_read_lock() and rcu_read_unlock(), or by similar primitives<BR>&nbsp;such as rcu_read_lock_bh() and rcu_read_unlock_bh(), in which<BR>&nbsp;case the matching rcu_dereference() primitive must be used in<BR>&nbsp;order to keep lockdep happy, in this case, rcu_dereference_bh().</P>
<P>&nbsp;The reason that it is permissible to use RCU list-traversal<BR>&nbsp;primitives when the update-side lock is held is that doing so<BR>&nbsp;can be quite helpful in reducing code bloat when common code is<BR>&nbsp;shared between readers and updaters.&nbsp; Additional primitives<BR>&nbsp;are provided for this case, as discussed in lockdep.txt.</P>
<P>10.&nbsp;Conversely, if you are in an RCU read-side critical section,<BR>&nbsp;and you don't hold the appropriate update-side lock, you -must-<BR>&nbsp;use the "_rcu()" variants of the list macros.&nbsp; Failing to do so<BR>&nbsp;will break Alpha, cause aggressive compilers to generate bad code,<BR>&nbsp;and confuse people trying to read your code.</P>
<P>11.&nbsp;Note that synchronize_rcu() -only- guarantees to wait until<BR>&nbsp;all currently executing rcu_read_lock()-protected RCU read-side<BR>&nbsp;critical sections complete.&nbsp; It does -not- necessarily guarantee<BR>&nbsp;that all currently running interrupts, NMIs, preempt_disable()<BR>&nbsp;code, or idle loops will complete.&nbsp; Therefore, if your<BR>&nbsp;read-side critical sections are protected by something other<BR>&nbsp;than rcu_read_lock(), do -not- use synchronize_rcu().</P>
<P>&nbsp;Similarly, disabling preemption is not an acceptable substitute<BR>&nbsp;for rcu_read_lock().&nbsp; Code that attempts to use preemption<BR>&nbsp;disabling where it should be using rcu_read_lock() will break<BR>&nbsp;in real-time kernel builds.</P>
<P>&nbsp;If you want to wait for interrupt handlers, NMI handlers, and<BR>&nbsp;code under the influence of preempt_disable(), you instead<BR>&nbsp;need to use synchronize_irq() or synchronize_sched().</P>
<P>&nbsp;This same limitation also applies to synchronize_rcu_bh()<BR>&nbsp;and synchronize_srcu(), as well as to the asynchronous and<BR>&nbsp;expedited forms of the three primitives, namely call_rcu(),<BR>&nbsp;call_rcu_bh(), call_srcu(), synchronize_rcu_expedited(),<BR>&nbsp;synchronize_rcu_bh_expedited(), and synchronize_srcu_expedited().</P>
<P>12.&nbsp;Any lock acquired by an RCU callback must be acquired elsewhere<BR>&nbsp;with softirq disabled, e.g., via spin_lock_irqsave(),<BR>&nbsp;spin_lock_bh(), etc.&nbsp; Failing to disable irq on a given<BR>&nbsp;acquisition of that lock will result in deadlock as soon as<BR>&nbsp;the RCU softirq handler happens to run your RCU callback while<BR>&nbsp;interrupting that acquisition's critical section.</P>
<P>13.&nbsp;RCU callbacks can be and are executed in parallel.&nbsp; In many cases,<BR>&nbsp;the callback code simply wrappers around kfree(), so that this<BR>&nbsp;is not an issue (or, more accurately, to the extent that it is<BR>&nbsp;an issue, the memory-allocator locking handles it).&nbsp; However,<BR>&nbsp;if the callbacks do manipulate a shared data structure, they<BR>&nbsp;must use whatever locking or other synchronization is required<BR>&nbsp;to safely access and/or modify that data structure.</P>
<P>&nbsp;RCU callbacks are -usually- executed on the same CPU that executed<BR>&nbsp;the corresponding call_rcu(), call_rcu_bh(), or call_rcu_sched(),<BR>&nbsp;but are by -no- means guaranteed to be.&nbsp; For example, if a given<BR>&nbsp;CPU goes offline while having an RCU callback pending, then that<BR>&nbsp;RCU callback will execute on some surviving CPU.&nbsp; (If this was<BR>&nbsp;not the case, a self-spawning RCU callback would prevent the<BR>&nbsp;victim CPU from ever going offline.)</P>
<P>14.&nbsp;SRCU (srcu_read_lock(), srcu_read_unlock(), srcu_dereference(),<BR>&nbsp;synchronize_srcu(), synchronize_srcu_expedited(), and call_srcu())<BR>&nbsp;may only be invoked from process context.&nbsp; Unlike other forms of<BR>&nbsp;RCU, it -is- permissible to block in an SRCU read-side critical<BR>&nbsp;section (demarked by srcu_read_lock() and srcu_read_unlock()),<BR>&nbsp;hence the "SRCU": "sleepable RCU".&nbsp; Please note that if you<BR>&nbsp;don't need to sleep in read-side critical sections, you should be<BR>&nbsp;using RCU rather than SRCU, because RCU is almost always faster<BR>&nbsp;and easier to use than is SRCU.</P>
<P>&nbsp;If you need to enter your read-side critical section in a<BR>&nbsp;hardirq or exception handler, and then exit that same read-side<BR>&nbsp;critical section in the task that was interrupted, then you need<BR>&nbsp;to srcu_read_lock_raw() and srcu_read_unlock_raw(), which avoid<BR>&nbsp;the lockdep checking that would otherwise this practice illegal.</P>
<P>&nbsp;Also unlike other forms of RCU, explicit initialization<BR>&nbsp;and cleanup is required via init_srcu_struct() and<BR>&nbsp;cleanup_srcu_struct().&nbsp;These are passed a "struct srcu_struct"<BR>&nbsp;that defines the scope of a given SRCU domain.&nbsp;Once initialized,<BR>&nbsp;the srcu_struct is passed to srcu_read_lock(), srcu_read_unlock()<BR>&nbsp;synchronize_srcu(), synchronize_srcu_expedited(), and call_srcu().<BR>&nbsp;A given synchronize_srcu() waits only for SRCU read-side critical<BR>&nbsp;sections governed by srcu_read_lock() and srcu_read_unlock()<BR>&nbsp;calls that have been passed the same srcu_struct.&nbsp; This property<BR>&nbsp;is what makes sleeping read-side critical sections tolerable --<BR>&nbsp;a given subsystem delays only its own updates, not those of other<BR>&nbsp;subsystems using SRCU.&nbsp;Therefore, SRCU is less prone to OOM the<BR>&nbsp;system than RCU would be if RCU's read-side critical sections<BR>&nbsp;were permitted to sleep.</P>
<P>&nbsp;The ability to sleep in read-side critical sections does not<BR>&nbsp;come for free.&nbsp;First, corresponding srcu_read_lock() and<BR>&nbsp;srcu_read_unlock() calls must be passed the same srcu_struct.<BR>&nbsp;Second, grace-period-detection overhead is amortized only<BR>&nbsp;over those updates sharing a given srcu_struct, rather than<BR>&nbsp;being globally amortized as they are for other forms of RCU.<BR>&nbsp;Therefore, SRCU should be used in preference to rw_semaphore<BR>&nbsp;only in extremely read-intensive situations, or in situations<BR>&nbsp;requiring SRCU's read-side deadlock immunity or low read-side<BR>&nbsp;realtime latency.</P>
<P>&nbsp;Note that, rcu_assign_pointer() relates to SRCU just as it does<BR>&nbsp;to other forms of RCU.</P>
<P>15.&nbsp;The whole point of call_rcu(), synchronize_rcu(), and friends<BR>&nbsp;is to wait until all pre-existing readers have finished before<BR>&nbsp;carrying out some otherwise-destructive operation.&nbsp; It is<BR>&nbsp;therefore critically important to -first- remove any path<BR>&nbsp;that readers can follow that could be affected by the<BR>&nbsp;destructive operation, and -only- -then- invoke call_rcu(),<BR>&nbsp;synchronize_rcu(), or friends.</P>
<P>&nbsp;Because these primitives only wait for pre-existing readers, it<BR>&nbsp;is the caller's responsibility to guarantee that any subsequent<BR>&nbsp;readers will execute safely.</P>
<P>16.&nbsp;The various RCU read-side primitives do -not- necessarily contain<BR>&nbsp;memory barriers.&nbsp; You should therefore plan for the CPU<BR>&nbsp;and the compiler to freely reorder code into and out of RCU<BR>&nbsp;read-side critical sections.&nbsp; It is the responsibility of the<BR>&nbsp;RCU update-side primitives to deal with this.</P>
<P>17.&nbsp;Use CONFIG_PROVE_RCU, CONFIG_DEBUG_OBJECTS_RCU_HEAD, and the<BR>&nbsp;__rcu sparse checks (enabled by CONFIG_SPARSE_RCU_POINTER) to<BR>&nbsp;validate your RCU code.&nbsp; These can help find problems as follows:</P>
<P>&nbsp;CONFIG_PROVE_RCU: check that accesses to RCU-protected data<BR>&nbsp;&nbsp;structures are carried out under the proper RCU<BR>&nbsp;&nbsp;read-side critical section, while holding the right<BR>&nbsp;&nbsp;combination of locks, or whatever other conditions<BR>&nbsp;&nbsp;are appropriate.</P>
<P>&nbsp;CONFIG_DEBUG_OBJECTS_RCU_HEAD: check that you don't pass the<BR>&nbsp;&nbsp;same object to call_rcu() (or friends) before an RCU<BR>&nbsp;&nbsp;grace period has elapsed since the last time that you<BR>&nbsp;&nbsp;passed that same object to call_rcu() (or friends).</P>
<P>&nbsp;__rcu sparse checks: tag the pointer to the RCU-protected data<BR>&nbsp;&nbsp;structure with __rcu, and sparse will warn you if you<BR>&nbsp;&nbsp;access that pointer without the services of one of the<BR>&nbsp;&nbsp;variants of rcu_dereference().</P>
<P>&nbsp;These debugging aids can help you find problems that are<BR>&nbsp;otherwise extremely difficult to spot.