# Documentation/development-process/4.Coding
<P></P>
<P>4: GETTING THE CODE RIGHT</P>
<P></P>
<P>While there is much to be said for a solid and community-oriented design<BR>process, the proof of any kernel development project is in the resulting<BR>code.&nbsp; It is the code which will be examined by other developers and merged<BR>(or not) into the mainline tree.&nbsp; So it is the quality of this code which<BR>will determine the ultimate success of the project.</P>
<P>This section will examine the coding process.&nbsp; We'll start with a look at a<BR>number of ways in which kernel developers can go wrong.&nbsp; Then the focus<BR>will shift toward doing things right and the tools which can help in that<BR>quest.</P>
<P><BR>4.1: PITFALLS</P>
<P>* Coding style</P>
<P>The kernel has long had a standard coding style, described in<BR>Documentation/CodingStyle.&nbsp; For much of that time, the policies described<BR>in that file were taken as being, at most, advisory.&nbsp; As a result, there is<BR>a substantial amount of code in the kernel which does not meet the coding<BR>style guidelines.&nbsp; The presence of that code leads to two independent<BR>hazards for kernel developers.</P>
<P>The first of these is to believe that the kernel coding standards do not<BR>matter and are not enforced.&nbsp; The truth of the matter is that adding new<BR>code to the kernel is very difficult if that code is not coded according to<BR>the standard; many developers will request that the code be reformatted<BR>before they will even review it.&nbsp; A code base as large as the kernel<BR>requires some uniformity of code to make it possible for developers to<BR>quickly understand any part of it.&nbsp; So there is no longer room for<BR>strangely-formatted code.</P>
<P>Occasionally, the kernel's coding style will run into conflict with an<BR>employer's mandated style.&nbsp; In such cases, the kernel's style will have to<BR>win before the code can be merged.&nbsp; Putting code into the kernel means<BR>giving up a degree of control in a number of ways - including control over<BR>how the code is formatted.</P>
<P>The other trap is to assume that code which is already in the kernel is<BR>urgently in need of coding style fixes.&nbsp; Developers may start to generate<BR>reformatting patches as a way of gaining familiarity with the process, or<BR>as a way of getting their name into the kernel changelogs - or both.&nbsp; But<BR>pure coding style fixes are seen as noise by the development community;<BR>they tend to get a chilly reception.&nbsp; So this type of patch is best<BR>avoided.&nbsp; It is natural to fix the style of a piece of code while working<BR>on it for other reasons, but coding style changes should not be made for<BR>their own sake.</P>
<P>The coding style document also should not be read as an absolute law which<BR>can never be transgressed.&nbsp; If there is a good reason to go against the<BR>style (a line which becomes far less readable if split to fit within the<BR>80-column limit, for example), just do it.</P>
<P><BR>* Abstraction layers</P>
<P>Computer Science professors teach students to make extensive use of<BR>abstraction layers in the name of flexibility and information hiding.<BR>Certainly the kernel makes extensive use of abstraction; no project<BR>involving several million lines of code could do otherwise and survive.<BR>But experience has shown that excessive or premature abstraction can be<BR>just as harmful as premature optimization.&nbsp; Abstraction should be used to<BR>the level required and no further.</P>
<P>At a simple level, consider a function which has an argument which is<BR>always passed as zero by all callers.&nbsp; One could retain that argument just<BR>in case somebody eventually needs to use the extra flexibility that it<BR>provides.&nbsp; By that time, though, chances are good that the code which<BR>implements this extra argument has been broken in some subtle way which was<BR>never noticed - because it has never been used.&nbsp; Or, when the need for<BR>extra flexibility arises, it does not do so in a way which matches the<BR>programmer's early expectation.&nbsp; Kernel developers will routinely submit<BR>patches to remove unused arguments; they should, in general, not be added<BR>in the first place.</P>
<P>Abstraction layers which hide access to hardware - often to allow the bulk<BR>of a driver to be used with multiple operating systems - are especially<BR>frowned upon.&nbsp; Such layers obscure the code and may impose a performance<BR>penalty; they do not belong in the Linux kernel.</P>
<P>On the other hand, if you find yourself copying significant amounts of code<BR>from another kernel subsystem, it is time to ask whether it would, in fact,<BR>make sense to pull out some of that code into a separate library or to<BR>implement that functionality at a higher level.&nbsp; There is no value in<BR>replicating the same code throughout the kernel.</P>
<P><BR>* #ifdef and preprocessor use in general</P>
<P>The C preprocessor seems to present a powerful temptation to some C<BR>programmers, who see it as a way to efficiently encode a great deal of<BR>flexibility into a source file.&nbsp; But the preprocessor is not C, and heavy<BR>use of it results in code which is much harder for others to read and<BR>harder for the compiler to check for correctness.&nbsp; Heavy preprocessor use<BR>is almost always a sign of code which needs some cleanup work.</P>
<P>Conditional compilation with #ifdef is, indeed, a powerful feature, and it<BR>is used within the kernel.&nbsp; But there is little desire to see code which is<BR>sprinkled liberally with #ifdef blocks.&nbsp; As a general rule, #ifdef use<BR>should be confined to header files whenever possible.<BR>Conditionally-compiled code can be confined to functions which, if the code<BR>is not to be present, simply become empty.&nbsp; The compiler will then quietly<BR>optimize out the call to the empty function.&nbsp; The result is far cleaner<BR>code which is easier to follow.</P>
<P>C preprocessor macros present a number of hazards, including possible<BR>multiple evaluation of expressions with side effects and no type safety.<BR>If you are tempted to define a macro, consider creating an inline function<BR>instead.&nbsp; The code which results will be the same, but inline functions are<BR>easier to read, do not evaluate their arguments multiple times, and allow<BR>the compiler to perform type checking on the arguments and return value.</P>
<P><BR>* Inline functions</P>
<P>Inline functions present a hazard of their own, though.&nbsp; Programmers can<BR>become enamored of the perceived efficiency inherent in avoiding a function<BR>call and fill a source file with inline functions.&nbsp; Those functions,<BR>however, can actually reduce performance.&nbsp; Since their code is replicated<BR>at each call site, they end up bloating the size of the compiled kernel.<BR>That, in turn, creates pressure on the processor's memory caches, which can<BR>slow execution dramatically.&nbsp; Inline functions, as a rule, should be quite<BR>small and relatively rare.&nbsp; The cost of a function call, after all, is not<BR>that high; the creation of large numbers of inline functions is a classic<BR>example of premature optimization.</P>
<P>In general, kernel programmers ignore cache effects at their peril.&nbsp; The<BR>classic time/space tradeoff taught in beginning data structures classes<BR>often does not apply to contemporary hardware.&nbsp; Space *is* time, in that a<BR>larger program will run slower than one which is more compact.</P>
<P>More recent compilers take an increasingly active role in deciding whether<BR>a given function should actually be inlined or not.&nbsp; So the liberal<BR>placement of "inline" keywords may not just be excessive; it could also be<BR>irrelevant.</P>
<P><BR>* Locking</P>
<P>In May, 2006, the "Devicescape" networking stack was, with great<BR>fanfare, released under the GPL and made available for inclusion in the<BR>mainline kernel.&nbsp; This donation was welcome news; support for wireless<BR>networking in Linux was considered substandard at best, and the Devicescape<BR>stack offered the promise of fixing that situation.&nbsp; Yet, this code did not<BR>actually make it into the mainline until June, 2007 (2.6.22).&nbsp; What<BR>happened?</P>
<P>This code showed a number of signs of having been developed behind<BR>corporate doors.&nbsp; But one large problem in particular was that it was not<BR>designed to work on multiprocessor systems.&nbsp; Before this networking stack<BR>(now called mac80211) could be merged, a locking scheme needed to be<BR>retrofitted onto it.&nbsp; </P>
<P>Once upon a time, Linux kernel code could be developed without thinking<BR>about the concurrency issues presented by multiprocessor systems.&nbsp; Now,<BR>however, this document is being written on a dual-core laptop.&nbsp; Even on<BR>single-processor systems, work being done to improve responsiveness will<BR>raise the level of concurrency within the kernel.&nbsp; The days when kernel<BR>code could be written without thinking about locking are long past.</P>
<P>Any resource (data structures, hardware registers, etc.) which could be<BR>accessed concurrently by more than one thread must be protected by a lock.<BR>New code should be written with this requirement in mind; retrofitting<BR>locking after the fact is a rather more difficult task.&nbsp; Kernel developers<BR>should take the time to understand the available locking primitives well<BR>enough to pick the right tool for the job.&nbsp; Code which shows a lack of<BR>attention to concurrency will have a difficult path into the mainline.</P>
<P><BR>* Regressions</P>
<P>One final hazard worth mentioning is this: it can be tempting to make a<BR>change (which may bring big improvements) which causes something to break<BR>for existing users.&nbsp; This kind of change is called a "regression," and<BR>regressions have become most unwelcome in the mainline kernel.&nbsp; With few<BR>exceptions, changes which cause regressions will be backed out if the<BR>regression cannot be fixed in a timely manner.&nbsp; Far better to avoid the<BR>regression in the first place.</P>
<P>It is often argued that a regression can be justified if it causes things<BR>to work for more people than it creates problems for.&nbsp; Why not make a<BR>change if it brings new functionality to ten systems for each one it<BR>breaks?&nbsp; The best answer to this question was expressed by Linus in July,<BR>2007:</P>
<P>&nbsp;So we don't fix bugs by introducing new problems.&nbsp; That way lies<BR>&nbsp;madness, and nobody ever knows if you actually make any real<BR>&nbsp;progress at all. Is it two steps forwards, one step back, or one<BR>&nbsp;step forward and two steps back?</P>
<P>(<A href="http://lwn.net/Articles/243460/">http://lwn.net/Articles/243460/</A>).</P>
<P>An especially unwelcome type of regression is any sort of change to the<BR>user-space ABI.&nbsp; Once an interface has been exported to user space, it must<BR>be supported indefinitely.&nbsp; This fact makes the creation of user-space<BR>interfaces particularly challenging: since they cannot be changed in<BR>incompatible ways, they must be done right the first time.&nbsp; For this<BR>reason, a great deal of thought, clear documentation, and wide review for<BR>user-space interfaces is always required.</P>
<P>&nbsp;</P>
<P>4.2: CODE CHECKING TOOLS</P>
<P>For now, at least, the writing of error-free code remains an ideal that few<BR>of us can reach.&nbsp; What we can hope to do, though, is to catch and fix as<BR>many of those errors as possible before our code goes into the mainline<BR>kernel.&nbsp; To that end, the kernel developers have put together an impressive<BR>array of tools which can catch a wide variety of obscure problems in an<BR>automated way.&nbsp; Any problem caught by the computer is a problem which will<BR>not afflict a user later on, so it stands to reason that the automated<BR>tools should be used whenever possible.</P>
<P>The first step is simply to heed the warnings produced by the compiler.<BR>Contemporary versions of gcc can detect (and warn about) a large number of<BR>potential errors.&nbsp; Quite often, these warnings point to real problems.<BR>Code submitted for review should, as a rule, not produce any compiler<BR>warnings.&nbsp; When silencing warnings, take care to understand the real cause<BR>and try to avoid "fixes" which make the warning go away without addressing<BR>its cause.</P>
<P>Note that not all compiler warnings are enabled by default.&nbsp; Build the<BR>kernel with "make EXTRA_CFLAGS=-W" to get the full set.</P>
<P>The kernel provides several configuration options which turn on debugging<BR>features; most of these are found in the "kernel hacking" submenu.&nbsp; Several<BR>of these options should be turned on for any kernel used for development or<BR>testing purposes.&nbsp; In particular, you should turn on:</P>
<P>&nbsp;- ENABLE_WARN_DEPRECATED, ENABLE_MUST_CHECK, and FRAME_WARN to get an<BR>&nbsp;&nbsp; extra set of warnings for problems like the use of deprecated interfaces<BR>&nbsp;&nbsp; or ignoring an important return value from a function.&nbsp; The output<BR>&nbsp;&nbsp; generated by these warnings can be verbose, but one need not worry about<BR>&nbsp;&nbsp; warnings from other parts of the kernel.</P>
<P>&nbsp;- DEBUG_OBJECTS will add code to track the lifetime of various objects<BR>&nbsp;&nbsp; created by the kernel and warn when things are done out of order.&nbsp; If<BR>&nbsp;&nbsp; you are adding a subsystem which creates (and exports) complex objects<BR>&nbsp;&nbsp; of its own, consider adding support for the object debugging<BR>&nbsp;&nbsp; infrastructure.</P>
<P>&nbsp;- DEBUG_SLAB can find a variety of memory allocation and use errors; it<BR>&nbsp;&nbsp; should be used on most development kernels.</P>
<P>&nbsp;- DEBUG_SPINLOCK, DEBUG_ATOMIC_SLEEP, and DEBUG_MUTEXES will find a<BR>&nbsp;&nbsp; number of common locking errors.</P>
<P>There are quite a few other debugging options, some of which will be<BR>discussed below.&nbsp; Some of them have a significant performance impact and<BR>should not be used all of the time.&nbsp; But some time spent learning the<BR>available options will likely be paid back many times over in short order. </P>
<P>One of the heavier debugging tools is the locking checker, or "lockdep."<BR>This tool will track the acquisition and release of every lock (spinlock or<BR>mutex) in the system, the order in which locks are acquired relative to<BR>each other, the current interrupt environment, and more.&nbsp; It can then<BR>ensure that locks are always acquired in the same order, that the same<BR>interrupt assumptions apply in all situations, and so on.&nbsp; In other words,<BR>lockdep can find a number of scenarios in which the system could, on rare<BR>occasion, deadlock.&nbsp; This kind of problem can be painful (for both<BR>developers and users) in a deployed system; lockdep allows them to be found<BR>in an automated manner ahead of time.&nbsp; Code with any sort of non-trivial<BR>locking should be run with lockdep enabled before being submitted for<BR>inclusion. </P>
<P>As a diligent kernel programmer, you will, beyond doubt, check the return<BR>status of any operation (such as a memory allocation) which can fail.&nbsp; The<BR>fact of the matter, though, is that the resulting failure recovery paths<BR>are, probably, completely untested.&nbsp; Untested code tends to be broken code;<BR>you could be much more confident of your code if all those error-handling<BR>paths had been exercised a few times.</P>
<P>The kernel provides a fault injection framework which can do exactly that,<BR>especially where memory allocations are involved.&nbsp; With fault injection<BR>enabled, a configurable percentage of memory allocations will be made to<BR>fail; these failures can be restricted to a specific range of code.<BR>Running with fault injection enabled allows the programmer to see how the<BR>code responds when things go badly.&nbsp; See<BR>Documentation/fault-injection/fault-injection.txt for more information on<BR>how to use this facility.</P>
<P>Other kinds of errors can be found with the "sparse" static analysis tool.<BR>With sparse, the programmer can be warned about confusion between<BR>user-space and kernel-space addresses, mixture of big-endian and<BR>small-endian quantities, the passing of integer values where a set of bit<BR>flags is expected, and so on.&nbsp; Sparse must be installed separately (it can<BR>be found at <A href="https://sparse.wiki.kernel.org/index.php/Main_Page">https://sparse.wiki.kernel.org/index.php/Main_Page</A> if your<BR>distributor does not package it); it can then be run on the code by adding<BR>"C=1" to your make command.</P>
<P>The "Coccinelle" tool (<A href="http://coccinelle.lip6.fr/">http://coccinelle.lip6.fr/</A>) is able to find a wide<BR>variety of potential coding problems; it can also propose fixes for those<BR>problems.&nbsp; Quite a few "semantic patches" for the kernel have been packaged<BR>under the scripts/coccinelle directory; running "make coccicheck" will run<BR>through those semantic patches and report on any problems found.&nbsp; See<BR>Documentation/coccinelle.txt for more information.</P>
<P>Other kinds of portability errors are best found by compiling your code for<BR>other architectures.&nbsp; If you do not happen to have an S/390 system or a<BR>Blackfin development board handy, you can still perform the compilation<BR>step.&nbsp; A large set of cross compilers for x86 systems can be found at </P>
<P>&nbsp;<A href="http://www.kernel.org/pub/tools/crosstool/">http://www.kernel.org/pub/tools/crosstool/</A></P>
<P>Some time spent installing and using these compilers will help avoid<BR>embarrassment later.</P>
<P><BR>4.3: DOCUMENTATION</P>
<P>Documentation has often been more the exception than the rule with kernel<BR>development.&nbsp; Even so, adequate documentation will help to ease the merging<BR>of new code into the kernel, make life easier for other developers, and<BR>will be helpful for your users.&nbsp; In many cases, the addition of<BR>documentation has become essentially mandatory.</P>
<P>The first piece of documentation for any patch is its associated<BR>changelog.&nbsp; Log entries should describe the problem being solved, the form<BR>of the solution, the people who worked on the patch, any relevant<BR>effects on performance, and anything else that might be needed to<BR>understand the patch.&nbsp; Be sure that the changelog says *why* the patch is<BR>worth applying; a surprising number of developers fail to provide that<BR>information.</P>
<P>Any code which adds a new user-space interface - including new sysfs or<BR>/proc files - should include documentation of that interface which enables<BR>user-space developers to know what they are working with.&nbsp; See<BR>Documentation/ABI/README for a description of how this documentation should<BR>be formatted and what information needs to be provided.</P>
<P>The file Documentation/kernel-parameters.txt describes all of the kernel's<BR>boot-time parameters.&nbsp; Any patch which adds new parameters should add the<BR>appropriate entries to this file.</P>
<P>Any new configuration options must be accompanied by help text which<BR>clearly explains the options and when the user might want to select them.</P>
<P>Internal API information for many subsystems is documented by way of<BR>specially-formatted comments; these comments can be extracted and formatted<BR>in a number of ways by the "kernel-doc" script.&nbsp; If you are working within<BR>a subsystem which has kerneldoc comments, you should maintain them and add<BR>them, as appropriate, for externally-available functions.&nbsp; Even in areas<BR>which have not been so documented, there is no harm in adding kerneldoc<BR>comments for the future; indeed, this can be a useful activity for<BR>beginning kernel developers.&nbsp; The format of these comments, along with some<BR>information on how to create kerneldoc templates can be found in the file<BR>Documentation/kernel-doc-nano-HOWTO.txt.</P>
<P>Anybody who reads through a significant amount of existing kernel code will<BR>note that, often, comments are most notable by their absence.&nbsp; Once again,<BR>the expectations for new code are higher than they were in the past;<BR>merging uncommented code will be harder.&nbsp; That said, there is little desire<BR>for verbosely-commented code.&nbsp; The code should, itself, be readable, with<BR>comments explaining the more subtle aspects.</P>
<P>Certain things should always be commented.&nbsp; Uses of memory barriers should<BR>be accompanied by a line explaining why the barrier is necessary.&nbsp; The<BR>locking rules for data structures generally need to be explained somewhere.<BR>Major data structures need comprehensive documentation in general.<BR>Non-obvious dependencies between separate bits of code should be pointed<BR>out.&nbsp; Anything which might tempt a code janitor to make an incorrect<BR>"cleanup" needs a comment saying why it is done the way it is.&nbsp; And so on.</P>
<P><BR>4.4: INTERNAL API CHANGES</P>
<P>The binary interface provided by the kernel to user space cannot be broken<BR>except under the most severe circumstances.&nbsp; The kernel's internal<BR>programming interfaces, instead, are highly fluid and can be changed when<BR>the need arises.&nbsp; If you find yourself having to work around a kernel API,<BR>or simply not using a specific functionality because it does not meet your<BR>needs, that may be a sign that the API needs to change.&nbsp; As a kernel<BR>developer, you are empowered to make such changes.</P>
<P>There are, of course, some catches.&nbsp; API changes can be made, but they need<BR>to be well justified.&nbsp; So any patch making an internal API change should be<BR>accompanied by a description of what the change is and why it is<BR>necessary.&nbsp; This kind of change should also be broken out into a separate<BR>patch, rather than buried within a larger patch.</P>
<P>The other catch is that a developer who changes an internal API is<BR>generally charged with the task of fixing any code within the kernel tree<BR>which is broken by the change.&nbsp; For a widely-used function, this duty can<BR>lead to literally hundreds or thousands of changes - many of which are<BR>likely to conflict with work being done by other developers.&nbsp; Needless to<BR>say, this can be a large job, so it is best to be sure that the<BR>justification is solid.&nbsp; Note that the Coccinelle tool can help with<BR>wide-ranging API changes.</P>
<P>When making an incompatible API change, one should, whenever possible,<BR>ensure that code which has not been updated is caught by the compiler.<BR>This will help you to be sure that you have found all in-tree uses of that<BR>interface.&nbsp; It will also alert developers of out-of-tree code that there is<BR>a change that they need to respond to.&nbsp; Supporting out-of-tree code is not<BR>something that kernel developers need to be worried about, but we also do<BR>not have to make life harder for out-of-tree developers than it needs to<BR>be.