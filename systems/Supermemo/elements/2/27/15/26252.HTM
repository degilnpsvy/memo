# lib/radix-tree.c
<P></P>
<P>/*<BR>&nbsp;* Copyright (C) 2001 Momchil Velikov<BR>&nbsp;* Portions Copyright (C) 2001 Christoph Hellwig<BR>&nbsp;* Copyright (C) 2005 SGI, Christoph Lameter<BR>&nbsp;* Copyright (C) 2006 Nick Piggin<BR>&nbsp;* Copyright (C) 2012 Konstantin Khlebnikov<BR>&nbsp;*<BR>&nbsp;* This program is free software; you can redistribute it and/or<BR>&nbsp;* modify it under the terms of the GNU General Public License as<BR>&nbsp;* published by the Free Software Foundation; either version 2, or (at<BR>&nbsp;* your option) any later version.<BR>&nbsp;*<BR>&nbsp;* This program is distributed in the hope that it will be useful, but<BR>&nbsp;* WITHOUT ANY WARRANTY; without even the implied warranty of<BR>&nbsp;* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.&nbsp; See the GNU<BR>&nbsp;* General Public License for more details.<BR>&nbsp;*<BR>&nbsp;* You should have received a copy of the GNU General Public License<BR>&nbsp;* along with this program; if not, write to the Free Software<BR>&nbsp;* Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.<BR>&nbsp;*/</P>
<P></P>
<P>#include &lt;linux/errno.h&gt;<BR>#include &lt;linux/init.h&gt;<BR>#include &lt;linux/kernel.h&gt;<BR>#include &lt;linux/export.h&gt;<BR>#include &lt;linux/radix-tree.h&gt;<BR>#include &lt;linux/percpu.h&gt;<BR>#include &lt;linux/slab.h&gt;<BR>#include &lt;linux/kmemleak.h&gt;<BR>#include &lt;linux/notifier.h&gt;<BR>#include &lt;linux/cpu.h&gt;<BR>#include &lt;linux/string.h&gt;<BR>#include &lt;linux/bitops.h&gt;<BR>#include &lt;linux/rcupdate.h&gt;<BR>#include &lt;linux/preempt.h&gt;&nbsp;&nbsp;/* in_interrupt() */</P>
<P><BR>/*<BR>&nbsp;* The height_to_maxindex array needs to be one deeper than the maximum<BR>&nbsp;* path as height 0 holds only 1 entry.<BR>&nbsp;*/<BR>static unsigned long height_to_maxindex[RADIX_TREE_MAX_PATH + 1] __read_mostly;</P>
<P>/*<BR>&nbsp;* Radix tree node cache.<BR>&nbsp;*/<BR>static struct kmem_cache *radix_tree_node_cachep;</P>
<P>/*<BR>&nbsp;* The radix tree is variable-height, so an insert operation not only has<BR>&nbsp;* to build the branch to its corresponding item, it also has to build the<BR>&nbsp;* branch to existing items if the size has to be increased (by<BR>&nbsp;* radix_tree_extend).<BR>&nbsp;*<BR>&nbsp;* The worst case is a zero height tree with just a single item at index 0,<BR>&nbsp;* and then inserting an item at index ULONG_MAX. This requires 2 new branches<BR>&nbsp;* of RADIX_TREE_MAX_PATH size to be created, with only the root node shared.<BR>&nbsp;* Hence:<BR>&nbsp;*/<BR>#define RADIX_TREE_PRELOAD_SIZE (RADIX_TREE_MAX_PATH * 2 - 1)</P>
<P>/*<BR>&nbsp;* Per-cpu pool of preloaded nodes<BR>&nbsp;*/<BR>struct radix_tree_preload {<BR>&nbsp;int nr;<BR>&nbsp;/* nodes-&gt;private_data points to next preallocated node */<BR>&nbsp;struct radix_tree_node *nodes;<BR>};<BR>static DEFINE_PER_CPU(struct radix_tree_preload, radix_tree_preloads) = { 0, };</P>
<P>static inline void *ptr_to_indirect(void *ptr)<BR>{<BR>&nbsp;return (void *)((unsigned long)ptr | RADIX_TREE_INDIRECT_PTR);<BR>}</P>
<P>static inline void *indirect_to_ptr(void *ptr)<BR>{<BR>&nbsp;return (void *)((unsigned long)ptr &amp; ~RADIX_TREE_INDIRECT_PTR);<BR>}</P>
<P>static inline gfp_t root_gfp_mask(struct radix_tree_root *root)<BR>{<BR>&nbsp;return root-&gt;gfp_mask &amp; __GFP_BITS_MASK;<BR>}</P>
<P>static inline void tag_set(struct radix_tree_node *node, unsigned int tag,<BR>&nbsp;&nbsp;int offset)<BR>{<BR>&nbsp;__set_bit(offset, node-&gt;tags[tag]);<BR>}</P>
<P>static inline void tag_clear(struct radix_tree_node *node, unsigned int tag,<BR>&nbsp;&nbsp;int offset)<BR>{<BR>&nbsp;__clear_bit(offset, node-&gt;tags[tag]);<BR>}</P>
<P>static inline int tag_get(struct radix_tree_node *node, unsigned int tag,<BR>&nbsp;&nbsp;int offset)<BR>{<BR>&nbsp;return test_bit(offset, node-&gt;tags[tag]);<BR>}</P>
<P>static inline void root_tag_set(struct radix_tree_root *root, unsigned int tag)<BR>{<BR>&nbsp;root-&gt;gfp_mask |= (__force gfp_t)(1 &lt;&lt; (tag + __GFP_BITS_SHIFT));<BR>}</P>
<P>static inline void root_tag_clear(struct radix_tree_root *root, unsigned int tag)<BR>{<BR>&nbsp;root-&gt;gfp_mask &amp;= (__force gfp_t)~(1 &lt;&lt; (tag + __GFP_BITS_SHIFT));<BR>}</P>
<P>static inline void root_tag_clear_all(struct radix_tree_root *root)<BR>{<BR>&nbsp;root-&gt;gfp_mask &amp;= __GFP_BITS_MASK;<BR>}</P>
<P>static inline int root_tag_get(struct radix_tree_root *root, unsigned int tag)<BR>{<BR>&nbsp;return (__force unsigned)root-&gt;gfp_mask &amp; (1 &lt;&lt; (tag + __GFP_BITS_SHIFT));<BR>}</P>
<P>/*<BR>&nbsp;* Returns 1 if any slot in the node has this tag set.<BR>&nbsp;* Otherwise returns 0.<BR>&nbsp;*/<BR>static inline int any_tag_set(struct radix_tree_node *node, unsigned int tag)<BR>{<BR>&nbsp;int idx;<BR>&nbsp;for (idx = 0; idx &lt; RADIX_TREE_TAG_LONGS; idx++) {<BR>&nbsp;&nbsp;if (node-&gt;tags[tag][idx])<BR>&nbsp;&nbsp;&nbsp;return 1;<BR>&nbsp;}<BR>&nbsp;return 0;<BR>}</P>
<P>/**<BR>&nbsp;* radix_tree_find_next_bit - find the next set bit in a memory region<BR>&nbsp;*<BR>&nbsp;* @addr: The address to base the search on<BR>&nbsp;* @size: The bitmap size in bits<BR>&nbsp;* @offset: The bitnumber to start searching at<BR>&nbsp;*<BR>&nbsp;* Unrollable variant of find_next_bit() for constant size arrays.<BR>&nbsp;* Tail bits starting from size to roundup(size, BITS_PER_LONG) must be zero.<BR>&nbsp;* Returns next bit offset, or size if nothing found.<BR>&nbsp;*/<BR>static __always_inline unsigned long<BR>radix_tree_find_next_bit(const unsigned long *addr,<BR>&nbsp;&nbsp;&nbsp; unsigned long size, unsigned long offset)<BR>{<BR>&nbsp;if (!__builtin_constant_p(size))<BR>&nbsp;&nbsp;return find_next_bit(addr, size, offset);</P>
<P>&nbsp;if (offset &lt; size) {<BR>&nbsp;&nbsp;unsigned long tmp;</P>
<P>&nbsp;&nbsp;addr += offset / BITS_PER_LONG;<BR>&nbsp;&nbsp;tmp = *addr &gt;&gt; (offset % BITS_PER_LONG);<BR>&nbsp;&nbsp;if (tmp)<BR>&nbsp;&nbsp;&nbsp;return __ffs(tmp) + offset;<BR>&nbsp;&nbsp;offset = (offset + BITS_PER_LONG) &amp; ~(BITS_PER_LONG - 1);<BR>&nbsp;&nbsp;while (offset &lt; size) {<BR>&nbsp;&nbsp;&nbsp;tmp = *++addr;<BR>&nbsp;&nbsp;&nbsp;if (tmp)<BR>&nbsp;&nbsp;&nbsp;&nbsp;return __ffs(tmp) + offset;<BR>&nbsp;&nbsp;&nbsp;offset += BITS_PER_LONG;<BR>&nbsp;&nbsp;}<BR>&nbsp;}<BR>&nbsp;return size;<BR>}</P>
<P>/*<BR>&nbsp;* This assumes that the caller has performed appropriate preallocation, and<BR>&nbsp;* that the caller has pinned this thread of control to the current CPU.<BR>&nbsp;*/<BR>static struct radix_tree_node *<BR>radix_tree_node_alloc(struct radix_tree_root *root)<BR>{<BR>&nbsp;struct radix_tree_node *ret = NULL;<BR>&nbsp;gfp_t gfp_mask = root_gfp_mask(root);</P>
<P>&nbsp;/*<BR>&nbsp; * Preload code isn't irq safe and it doesn't make sence to use<BR>&nbsp; * preloading in the interrupt anyway as all the allocations have to<BR>&nbsp; * be atomic. So just do normal allocation when in interrupt.<BR>&nbsp; */<BR>&nbsp;if (!gfpflags_allow_blocking(gfp_mask) &amp;&amp; !in_interrupt()) {<BR>&nbsp;&nbsp;struct radix_tree_preload *rtp;</P>
<P>&nbsp;&nbsp;/*<BR>&nbsp;&nbsp; * Provided the caller has preloaded here, we will always<BR>&nbsp;&nbsp; * succeed in getting a node here (and never reach<BR>&nbsp;&nbsp; * kmem_cache_alloc)<BR>&nbsp;&nbsp; */<BR>&nbsp;&nbsp;rtp = this_cpu_ptr(&amp;radix_tree_preloads);<BR>&nbsp;&nbsp;if (rtp-&gt;nr) {<BR>&nbsp;&nbsp;&nbsp;ret = rtp-&gt;nodes;<BR>&nbsp;&nbsp;&nbsp;rtp-&gt;nodes = ret-&gt;private_data;<BR>&nbsp;&nbsp;&nbsp;ret-&gt;private_data = NULL;<BR>&nbsp;&nbsp;&nbsp;rtp-&gt;nr--;<BR>&nbsp;&nbsp;}<BR>&nbsp;&nbsp;/*<BR>&nbsp;&nbsp; * Update the allocation stack trace as this is more useful<BR>&nbsp;&nbsp; * for debugging.<BR>&nbsp;&nbsp; */<BR>&nbsp;&nbsp;kmemleak_update_trace(ret);<BR>&nbsp;}<BR>&nbsp;if (ret == NULL)<BR>&nbsp;&nbsp;ret = kmem_cache_alloc(radix_tree_node_cachep, gfp_mask);</P>
<P>&nbsp;BUG_ON(radix_tree_is_indirect_ptr(ret));<BR>&nbsp;return ret;<BR>}</P>
<P>static void radix_tree_node_rcu_free(struct rcu_head *head)<BR>{<BR>&nbsp;struct radix_tree_node *node =<BR>&nbsp;&nbsp;&nbsp;container_of(head, struct radix_tree_node, rcu_head);<BR>&nbsp;int i;</P>
<P>&nbsp;/*<BR>&nbsp; * must only free zeroed nodes into the slab. radix_tree_shrink<BR>&nbsp; * can leave us with a non-NULL entry in the first slot, so clear<BR>&nbsp; * that here to make sure.<BR>&nbsp; */<BR>&nbsp;for (i = 0; i &lt; RADIX_TREE_MAX_TAGS; i++)<BR>&nbsp;&nbsp;tag_clear(node, i, 0);</P>
<P>&nbsp;node-&gt;slots[0] = NULL;<BR>&nbsp;node-&gt;count = 0;</P>
<P>&nbsp;kmem_cache_free(radix_tree_node_cachep, node);<BR>}</P>
<P>static inline void<BR>radix_tree_node_free(struct radix_tree_node *node)<BR>{<BR>&nbsp;call_rcu(&amp;node-&gt;rcu_head, radix_tree_node_rcu_free);<BR>}</P>
<P>/*<BR>&nbsp;* Load up this CPU's radix_tree_node buffer with sufficient objects to<BR>&nbsp;* ensure that the addition of a single element in the tree cannot fail.&nbsp; On<BR>&nbsp;* success, return zero, with preemption disabled.&nbsp; On error, return -ENOMEM<BR>&nbsp;* with preemption not disabled.<BR>&nbsp;*<BR>&nbsp;* To make use of this facility, the radix tree must be initialised without<BR>&nbsp;* __GFP_DIRECT_RECLAIM being passed to INIT_RADIX_TREE().<BR>&nbsp;*/<BR>static int __radix_tree_preload(gfp_t gfp_mask)<BR>{<BR>&nbsp;struct radix_tree_preload *rtp;<BR>&nbsp;struct radix_tree_node *node;<BR>&nbsp;int ret = -ENOMEM;</P>
<P>&nbsp;preempt_disable();<BR>&nbsp;rtp = this_cpu_ptr(&amp;radix_tree_preloads);<BR>&nbsp;while (rtp-&gt;nr &lt; RADIX_TREE_PRELOAD_SIZE) {<BR>&nbsp;&nbsp;preempt_enable();<BR>&nbsp;&nbsp;node = kmem_cache_alloc(radix_tree_node_cachep, gfp_mask);<BR>&nbsp;&nbsp;if (node == NULL)<BR>&nbsp;&nbsp;&nbsp;goto out;<BR>&nbsp;&nbsp;preempt_disable();<BR>&nbsp;&nbsp;rtp = this_cpu_ptr(&amp;radix_tree_preloads);<BR>&nbsp;&nbsp;if (rtp-&gt;nr &lt; RADIX_TREE_PRELOAD_SIZE) {<BR>&nbsp;&nbsp;&nbsp;node-&gt;private_data = rtp-&gt;nodes;<BR>&nbsp;&nbsp;&nbsp;rtp-&gt;nodes = node;<BR>&nbsp;&nbsp;&nbsp;rtp-&gt;nr++;<BR>&nbsp;&nbsp;} else {<BR>&nbsp;&nbsp;&nbsp;kmem_cache_free(radix_tree_node_cachep, node);<BR>&nbsp;&nbsp;}<BR>&nbsp;}<BR>&nbsp;ret = 0;<BR>out:<BR>&nbsp;return ret;<BR>}</P>
<P>/*<BR>&nbsp;* Load up this CPU's radix_tree_node buffer with sufficient objects to<BR>&nbsp;* ensure that the addition of a single element in the tree cannot fail.&nbsp; On<BR>&nbsp;* success, return zero, with preemption disabled.&nbsp; On error, return -ENOMEM<BR>&nbsp;* with preemption not disabled.<BR>&nbsp;*<BR>&nbsp;* To make use of this facility, the radix tree must be initialised without<BR>&nbsp;* __GFP_DIRECT_RECLAIM being passed to INIT_RADIX_TREE().<BR>&nbsp;*/<BR>int radix_tree_preload(gfp_t gfp_mask)<BR>{<BR>&nbsp;/* Warn on non-sensical use... */<BR>&nbsp;WARN_ON_ONCE(!gfpflags_allow_blocking(gfp_mask));<BR>&nbsp;return __radix_tree_preload(gfp_mask);<BR>}<BR>EXPORT_SYMBOL(radix_tree_preload);</P>
<P>/*<BR>&nbsp;* The same as above function, except we don't guarantee preloading happens.<BR>&nbsp;* We do it, if we decide it helps. On success, return zero with preemption<BR>&nbsp;* disabled. On error, return -ENOMEM with preemption not disabled.<BR>&nbsp;*/<BR>int radix_tree_maybe_preload(gfp_t gfp_mask)<BR>{<BR>&nbsp;if (gfpflags_allow_blocking(gfp_mask))<BR>&nbsp;&nbsp;return __radix_tree_preload(gfp_mask);<BR>&nbsp;/* Preloading doesn't help anything with this gfp mask, skip it */<BR>&nbsp;preempt_disable();<BR>&nbsp;return 0;<BR>}<BR>EXPORT_SYMBOL(radix_tree_maybe_preload);</P>
<P>/*<BR>&nbsp;*&nbsp;Return the maximum key which can be store into a<BR>&nbsp;*&nbsp;radix tree with height HEIGHT.<BR>&nbsp;*/<BR>static inline unsigned long radix_tree_maxindex(unsigned int height)<BR>{<BR>&nbsp;return height_to_maxindex[height];<BR>}</P>
<P>/*<BR>&nbsp;*&nbsp;Extend a radix tree so it can store key @index.<BR>&nbsp;*/<BR>static int radix_tree_extend(struct radix_tree_root *root, unsigned long index)<BR>{<BR>&nbsp;struct radix_tree_node *node;<BR>&nbsp;struct radix_tree_node *slot;<BR>&nbsp;unsigned int height;<BR>&nbsp;int tag;</P>
<P>&nbsp;/* Figure out what the height should be.&nbsp; */<BR>&nbsp;height = root-&gt;height + 1;<BR>&nbsp;while (index &gt; radix_tree_maxindex(height))<BR>&nbsp;&nbsp;height++;</P>
<P>&nbsp;if (root-&gt;rnode == NULL) {<BR>&nbsp;&nbsp;root-&gt;height = height;<BR>&nbsp;&nbsp;goto out;<BR>&nbsp;}</P>
<P>&nbsp;do {<BR>&nbsp;&nbsp;unsigned int newheight;<BR>&nbsp;&nbsp;if (!(node = radix_tree_node_alloc(root)))<BR>&nbsp;&nbsp;&nbsp;return -ENOMEM;</P>
<P>&nbsp;&nbsp;/* Propagate the aggregated tag info into the new root */<BR>&nbsp;&nbsp;for (tag = 0; tag &lt; RADIX_TREE_MAX_TAGS; tag++) {<BR>&nbsp;&nbsp;&nbsp;if (root_tag_get(root, tag))<BR>&nbsp;&nbsp;&nbsp;&nbsp;tag_set(node, tag, 0);<BR>&nbsp;&nbsp;}</P>
<P>&nbsp;&nbsp;/* Increase the height.&nbsp; */<BR>&nbsp;&nbsp;newheight = root-&gt;height+1;<BR>&nbsp;&nbsp;BUG_ON(newheight &amp; ~RADIX_TREE_HEIGHT_MASK);<BR>&nbsp;&nbsp;node-&gt;path = newheight;<BR>&nbsp;&nbsp;node-&gt;count = 1;<BR>&nbsp;&nbsp;node-&gt;parent = NULL;<BR>&nbsp;&nbsp;slot = root-&gt;rnode;<BR>&nbsp;&nbsp;if (newheight &gt; 1) {<BR>&nbsp;&nbsp;&nbsp;slot = indirect_to_ptr(slot);<BR>&nbsp;&nbsp;&nbsp;slot-&gt;parent = node;<BR>&nbsp;&nbsp;}<BR>&nbsp;&nbsp;node-&gt;slots[0] = slot;<BR>&nbsp;&nbsp;node = ptr_to_indirect(node);<BR>&nbsp;&nbsp;rcu_assign_pointer(root-&gt;rnode, node);<BR>&nbsp;&nbsp;root-&gt;height = newheight;<BR>&nbsp;} while (height &gt; root-&gt;height);<BR>out:<BR>&nbsp;return 0;<BR>}</P>
<P>/**<BR>&nbsp;*&nbsp;__radix_tree_create&nbsp;-&nbsp;create a slot in a radix tree<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@index:&nbsp;&nbsp;index key<BR>&nbsp;*&nbsp;@nodep:&nbsp;&nbsp;returns node<BR>&nbsp;*&nbsp;@slotp:&nbsp;&nbsp;returns slot<BR>&nbsp;*<BR>&nbsp;*&nbsp;Create, if necessary, and return the node and slot for an item<BR>&nbsp;*&nbsp;at position @index in the radix tree @root.<BR>&nbsp;*<BR>&nbsp;*&nbsp;Until there is more than one item in the tree, no nodes are<BR>&nbsp;*&nbsp;allocated and @root-&gt;rnode is used as a direct slot instead of<BR>&nbsp;*&nbsp;pointing to a node, in which case <A href="mailto:*@nodep">*@nodep</A> will be NULL.<BR>&nbsp;*<BR>&nbsp;*&nbsp;Returns -ENOMEM, or 0 for success.<BR>&nbsp;*/<BR>int __radix_tree_create(struct radix_tree_root *root, unsigned long index,<BR>&nbsp;&nbsp;&nbsp;struct radix_tree_node **nodep, void ***slotp)<BR>{<BR>&nbsp;struct radix_tree_node *node = NULL, *slot;<BR>&nbsp;unsigned int height, shift, offset;<BR>&nbsp;int error;</P>
<P>&nbsp;/* Make sure the tree is high enough.&nbsp; */<BR>&nbsp;if (index &gt; radix_tree_maxindex(root-&gt;height)) {<BR>&nbsp;&nbsp;error = radix_tree_extend(root, index);<BR>&nbsp;&nbsp;if (error)<BR>&nbsp;&nbsp;&nbsp;return error;<BR>&nbsp;}</P>
<P>&nbsp;slot = indirect_to_ptr(root-&gt;rnode);</P>
<P>&nbsp;height = root-&gt;height;<BR>&nbsp;shift = (height-1) * RADIX_TREE_MAP_SHIFT;</P>
<P>&nbsp;offset = 0;&nbsp;&nbsp;&nbsp;/* uninitialised var warning */<BR>&nbsp;while (height &gt; 0) {<BR>&nbsp;&nbsp;if (slot == NULL) {<BR>&nbsp;&nbsp;&nbsp;/* Have to add a child node.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;if (!(slot = radix_tree_node_alloc(root)))<BR>&nbsp;&nbsp;&nbsp;&nbsp;return -ENOMEM;<BR>&nbsp;&nbsp;&nbsp;slot-&gt;path = height;<BR>&nbsp;&nbsp;&nbsp;slot-&gt;parent = node;<BR>&nbsp;&nbsp;&nbsp;if (node) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;rcu_assign_pointer(node-&gt;slots[offset], slot);<BR>&nbsp;&nbsp;&nbsp;&nbsp;node-&gt;count++;<BR>&nbsp;&nbsp;&nbsp;&nbsp;slot-&gt;path |= offset &lt;&lt; RADIX_TREE_HEIGHT_SHIFT;<BR>&nbsp;&nbsp;&nbsp;} else<BR>&nbsp;&nbsp;&nbsp;&nbsp;rcu_assign_pointer(root-&gt;rnode, ptr_to_indirect(slot));<BR>&nbsp;&nbsp;}</P>
<P>&nbsp;&nbsp;/* Go a level down */<BR>&nbsp;&nbsp;offset = (index &gt;&gt; shift) &amp; RADIX_TREE_MAP_MASK;<BR>&nbsp;&nbsp;node = slot;<BR>&nbsp;&nbsp;slot = node-&gt;slots[offset];<BR>&nbsp;&nbsp;shift -= RADIX_TREE_MAP_SHIFT;<BR>&nbsp;&nbsp;height--;<BR>&nbsp;}</P>
<P>&nbsp;if (nodep)<BR>&nbsp;&nbsp;*nodep = node;<BR>&nbsp;if (slotp)<BR>&nbsp;&nbsp;*slotp = node ? node-&gt;slots + offset : (void **)&amp;root-&gt;rnode;<BR>&nbsp;return 0;<BR>}</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_insert&nbsp;&nbsp;&nbsp; -&nbsp;&nbsp;&nbsp; insert into a radix tree<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@index:&nbsp;&nbsp;index key<BR>&nbsp;*&nbsp;@item:&nbsp;&nbsp;item to insert<BR>&nbsp;*<BR>&nbsp;*&nbsp;Insert an item into the radix tree at position @index.<BR>&nbsp;*/<BR>int radix_tree_insert(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;unsigned long index, void *item)<BR>{<BR>&nbsp;struct radix_tree_node *node;<BR>&nbsp;void **slot;<BR>&nbsp;int error;</P>
<P>&nbsp;BUG_ON(radix_tree_is_indirect_ptr(item));</P>
<P>&nbsp;error = __radix_tree_create(root, index, &amp;node, &amp;slot);<BR>&nbsp;if (error)<BR>&nbsp;&nbsp;return error;<BR>&nbsp;if (*slot != NULL)<BR>&nbsp;&nbsp;return -EEXIST;<BR>&nbsp;rcu_assign_pointer(*slot, item);</P>
<P>&nbsp;if (node) {<BR>&nbsp;&nbsp;node-&gt;count++;<BR>&nbsp;&nbsp;BUG_ON(tag_get(node, 0, index &amp; RADIX_TREE_MAP_MASK));<BR>&nbsp;&nbsp;BUG_ON(tag_get(node, 1, index &amp; RADIX_TREE_MAP_MASK));<BR>&nbsp;} else {<BR>&nbsp;&nbsp;BUG_ON(root_tag_get(root, 0));<BR>&nbsp;&nbsp;BUG_ON(root_tag_get(root, 1));<BR>&nbsp;}</P>
<P>&nbsp;return 0;<BR>}<BR>EXPORT_SYMBOL(radix_tree_insert);</P>
<P>/**<BR>&nbsp;*&nbsp;__radix_tree_lookup&nbsp;-&nbsp;lookup an item in a radix tree<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@index:&nbsp;&nbsp;index key<BR>&nbsp;*&nbsp;@nodep:&nbsp;&nbsp;returns node<BR>&nbsp;*&nbsp;@slotp:&nbsp;&nbsp;returns slot<BR>&nbsp;*<BR>&nbsp;*&nbsp;Lookup and return the item at position @index in the radix<BR>&nbsp;*&nbsp;tree @root.<BR>&nbsp;*<BR>&nbsp;*&nbsp;Until there is more than one item in the tree, no nodes are<BR>&nbsp;*&nbsp;allocated and @root-&gt;rnode is used as a direct slot instead of<BR>&nbsp;*&nbsp;pointing to a node, in which case <A href="mailto:*@nodep">*@nodep</A> will be NULL.<BR>&nbsp;*/<BR>void *__radix_tree_lookup(struct radix_tree_root *root, unsigned long index,<BR>&nbsp;&nbsp;&nbsp;&nbsp; struct radix_tree_node **nodep, void ***slotp)<BR>{<BR>&nbsp;struct radix_tree_node *node, *parent;<BR>&nbsp;unsigned int height, shift;<BR>&nbsp;void **slot;</P>
<P>&nbsp;node = rcu_dereference_raw(root-&gt;rnode);<BR>&nbsp;if (node == NULL)<BR>&nbsp;&nbsp;return NULL;</P>
<P>&nbsp;if (!radix_tree_is_indirect_ptr(node)) {<BR>&nbsp;&nbsp;if (index &gt; 0)<BR>&nbsp;&nbsp;&nbsp;return NULL;</P>
<P>&nbsp;&nbsp;if (nodep)<BR>&nbsp;&nbsp;&nbsp;*nodep = NULL;<BR>&nbsp;&nbsp;if (slotp)<BR>&nbsp;&nbsp;&nbsp;*slotp = (void **)&amp;root-&gt;rnode;<BR>&nbsp;&nbsp;return node;<BR>&nbsp;}<BR>&nbsp;node = indirect_to_ptr(node);</P>
<P>&nbsp;height = node-&gt;path &amp; RADIX_TREE_HEIGHT_MASK;<BR>&nbsp;if (index &gt; radix_tree_maxindex(height))<BR>&nbsp;&nbsp;return NULL;</P>
<P>&nbsp;shift = (height-1) * RADIX_TREE_MAP_SHIFT;</P>
<P>&nbsp;do {<BR>&nbsp;&nbsp;parent = node;<BR>&nbsp;&nbsp;slot = node-&gt;slots + ((index &gt;&gt; shift) &amp; RADIX_TREE_MAP_MASK);<BR>&nbsp;&nbsp;node = rcu_dereference_raw(*slot);<BR>&nbsp;&nbsp;if (node == NULL)<BR>&nbsp;&nbsp;&nbsp;return NULL;</P>
<P>&nbsp;&nbsp;shift -= RADIX_TREE_MAP_SHIFT;<BR>&nbsp;&nbsp;height--;<BR>&nbsp;} while (height &gt; 0);</P>
<P>&nbsp;if (nodep)<BR>&nbsp;&nbsp;*nodep = parent;<BR>&nbsp;if (slotp)<BR>&nbsp;&nbsp;*slotp = slot;<BR>&nbsp;return node;<BR>}</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_lookup_slot&nbsp;&nbsp;&nbsp; -&nbsp;&nbsp;&nbsp; lookup a slot in a radix tree<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@index:&nbsp;&nbsp;index key<BR>&nbsp;*<BR>&nbsp;*&nbsp;Returns:&nbsp; the slot corresponding to the position @index in the<BR>&nbsp;*&nbsp;radix tree @root. This is useful for update-if-exists operations.<BR>&nbsp;*<BR>&nbsp;*&nbsp;This function can be called under rcu_read_lock iff the slot is not<BR>&nbsp;*&nbsp;modified by radix_tree_replace_slot, otherwise it must be called<BR>&nbsp;*&nbsp;exclusive from other writers. Any dereference of the slot must be done<BR>&nbsp;*&nbsp;using radix_tree_deref_slot.<BR>&nbsp;*/<BR>void **radix_tree_lookup_slot(struct radix_tree_root *root, unsigned long index)<BR>{<BR>&nbsp;void **slot;</P>
<P>&nbsp;if (!__radix_tree_lookup(root, index, NULL, &amp;slot))<BR>&nbsp;&nbsp;return NULL;<BR>&nbsp;return slot;<BR>}<BR>EXPORT_SYMBOL(radix_tree_lookup_slot);</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_lookup&nbsp;&nbsp;&nbsp; -&nbsp;&nbsp;&nbsp; perform lookup operation on a radix tree<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@index:&nbsp;&nbsp;index key<BR>&nbsp;*<BR>&nbsp;*&nbsp;Lookup the item at the position @index in the radix tree @root.<BR>&nbsp;*<BR>&nbsp;*&nbsp;This function can be called under rcu_read_lock, however the caller<BR>&nbsp;*&nbsp;must manage lifetimes of leaf nodes (eg. RCU may also be used to free<BR>&nbsp;*&nbsp;them safely). No RCU barriers are required to access or modify the<BR>&nbsp;*&nbsp;returned item, however.<BR>&nbsp;*/<BR>void *radix_tree_lookup(struct radix_tree_root *root, unsigned long index)<BR>{<BR>&nbsp;return __radix_tree_lookup(root, index, NULL, NULL);<BR>}<BR>EXPORT_SYMBOL(radix_tree_lookup);</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_tag_set - set a tag on a radix tree node<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@index:&nbsp;&nbsp;index key<BR>&nbsp;*&nbsp;@tag: &nbsp;&nbsp;tag index<BR>&nbsp;*<BR>&nbsp;*&nbsp;Set the search tag (which must be &lt; RADIX_TREE_MAX_TAGS)<BR>&nbsp;*&nbsp;corresponding to @index in the radix tree.&nbsp; From<BR>&nbsp;*&nbsp;the root all the way down to the leaf node.<BR>&nbsp;*<BR>&nbsp;*&nbsp;Returns the address of the tagged item.&nbsp;&nbsp; Setting a tag on a not-present<BR>&nbsp;*&nbsp;item is a bug.<BR>&nbsp;*/<BR>void *radix_tree_tag_set(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;unsigned long index, unsigned int tag)<BR>{<BR>&nbsp;unsigned int height, shift;<BR>&nbsp;struct radix_tree_node *slot;</P>
<P>&nbsp;height = root-&gt;height;<BR>&nbsp;BUG_ON(index &gt; radix_tree_maxindex(height));</P>
<P>&nbsp;slot = indirect_to_ptr(root-&gt;rnode);<BR>&nbsp;shift = (height - 1) * RADIX_TREE_MAP_SHIFT;</P>
<P>&nbsp;while (height &gt; 0) {<BR>&nbsp;&nbsp;int offset;</P>
<P>&nbsp;&nbsp;offset = (index &gt;&gt; shift) &amp; RADIX_TREE_MAP_MASK;<BR>&nbsp;&nbsp;if (!tag_get(slot, tag, offset))<BR>&nbsp;&nbsp;&nbsp;tag_set(slot, tag, offset);<BR>&nbsp;&nbsp;slot = slot-&gt;slots[offset];<BR>&nbsp;&nbsp;BUG_ON(slot == NULL);<BR>&nbsp;&nbsp;shift -= RADIX_TREE_MAP_SHIFT;<BR>&nbsp;&nbsp;height--;<BR>&nbsp;}</P>
<P>&nbsp;/* set the root's tag bit */<BR>&nbsp;if (slot &amp;&amp; !root_tag_get(root, tag))<BR>&nbsp;&nbsp;root_tag_set(root, tag);</P>
<P>&nbsp;return slot;<BR>}<BR>EXPORT_SYMBOL(radix_tree_tag_set);</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_tag_clear - clear a tag on a radix tree node<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@index:&nbsp;&nbsp;index key<BR>&nbsp;*&nbsp;@tag: &nbsp;&nbsp;tag index<BR>&nbsp;*<BR>&nbsp;*&nbsp;Clear the search tag (which must be &lt; RADIX_TREE_MAX_TAGS)<BR>&nbsp;*&nbsp;corresponding to @index in the radix tree.&nbsp; If<BR>&nbsp;*&nbsp;this causes the leaf node to have no tags set then clear the tag in the<BR>&nbsp;*&nbsp;next-to-leaf node, etc.<BR>&nbsp;*<BR>&nbsp;*&nbsp;Returns the address of the tagged item on success, else NULL.&nbsp; ie:<BR>&nbsp;*&nbsp;has the same return value and semantics as radix_tree_lookup().<BR>&nbsp;*/<BR>void *radix_tree_tag_clear(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;unsigned long index, unsigned int tag)<BR>{<BR>&nbsp;struct radix_tree_node *node = NULL;<BR>&nbsp;struct radix_tree_node *slot = NULL;<BR>&nbsp;unsigned int height, shift;<BR>&nbsp;int uninitialized_var(offset);</P>
<P>&nbsp;height = root-&gt;height;<BR>&nbsp;if (index &gt; radix_tree_maxindex(height))<BR>&nbsp;&nbsp;goto out;</P>
<P>&nbsp;shift = height * RADIX_TREE_MAP_SHIFT;<BR>&nbsp;slot = indirect_to_ptr(root-&gt;rnode);</P>
<P>&nbsp;while (shift) {<BR>&nbsp;&nbsp;if (slot == NULL)<BR>&nbsp;&nbsp;&nbsp;goto out;</P>
<P>&nbsp;&nbsp;shift -= RADIX_TREE_MAP_SHIFT;<BR>&nbsp;&nbsp;offset = (index &gt;&gt; shift) &amp; RADIX_TREE_MAP_MASK;<BR>&nbsp;&nbsp;node = slot;<BR>&nbsp;&nbsp;slot = slot-&gt;slots[offset];<BR>&nbsp;}</P>
<P>&nbsp;if (slot == NULL)<BR>&nbsp;&nbsp;goto out;</P>
<P>&nbsp;while (node) {<BR>&nbsp;&nbsp;if (!tag_get(node, tag, offset))<BR>&nbsp;&nbsp;&nbsp;goto out;<BR>&nbsp;&nbsp;tag_clear(node, tag, offset);<BR>&nbsp;&nbsp;if (any_tag_set(node, tag))<BR>&nbsp;&nbsp;&nbsp;goto out;</P>
<P>&nbsp;&nbsp;index &gt;&gt;= RADIX_TREE_MAP_SHIFT;<BR>&nbsp;&nbsp;offset = index &amp; RADIX_TREE_MAP_MASK;<BR>&nbsp;&nbsp;node = node-&gt;parent;<BR>&nbsp;}</P>
<P>&nbsp;/* clear the root's tag bit */<BR>&nbsp;if (root_tag_get(root, tag))<BR>&nbsp;&nbsp;root_tag_clear(root, tag);</P>
<P>out:<BR>&nbsp;return slot;<BR>}<BR>EXPORT_SYMBOL(radix_tree_tag_clear);</P>
<P>/**<BR>&nbsp;* radix_tree_tag_get - get a tag on a radix tree node<BR>&nbsp;* @root:&nbsp;&nbsp;radix tree root<BR>&nbsp;* @index:&nbsp;&nbsp;index key<BR>&nbsp;* @tag: &nbsp;&nbsp;tag index (&lt; RADIX_TREE_MAX_TAGS)<BR>&nbsp;*<BR>&nbsp;* Return values:<BR>&nbsp;*<BR>&nbsp;*&nbsp; 0: tag not present or not set<BR>&nbsp;*&nbsp; 1: tag set<BR>&nbsp;*<BR>&nbsp;* Note that the return value of this function may not be relied on, even if<BR>&nbsp;* the RCU lock is held, unless tag modification and node deletion are excluded<BR>&nbsp;* from concurrency.<BR>&nbsp;*/<BR>int radix_tree_tag_get(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;unsigned long index, unsigned int tag)<BR>{<BR>&nbsp;unsigned int height, shift;<BR>&nbsp;struct radix_tree_node *node;</P>
<P>&nbsp;/* check the root's tag bit */<BR>&nbsp;if (!root_tag_get(root, tag))<BR>&nbsp;&nbsp;return 0;</P>
<P>&nbsp;node = rcu_dereference_raw(root-&gt;rnode);<BR>&nbsp;if (node == NULL)<BR>&nbsp;&nbsp;return 0;</P>
<P>&nbsp;if (!radix_tree_is_indirect_ptr(node))<BR>&nbsp;&nbsp;return (index == 0);<BR>&nbsp;node = indirect_to_ptr(node);</P>
<P>&nbsp;height = node-&gt;path &amp; RADIX_TREE_HEIGHT_MASK;<BR>&nbsp;if (index &gt; radix_tree_maxindex(height))<BR>&nbsp;&nbsp;return 0;</P>
<P>&nbsp;shift = (height - 1) * RADIX_TREE_MAP_SHIFT;</P>
<P>&nbsp;for ( ; ; ) {<BR>&nbsp;&nbsp;int offset;</P>
<P>&nbsp;&nbsp;if (node == NULL)<BR>&nbsp;&nbsp;&nbsp;return 0;</P>
<P>&nbsp;&nbsp;offset = (index &gt;&gt; shift) &amp; RADIX_TREE_MAP_MASK;<BR>&nbsp;&nbsp;if (!tag_get(node, tag, offset))<BR>&nbsp;&nbsp;&nbsp;return 0;<BR>&nbsp;&nbsp;if (height == 1)<BR>&nbsp;&nbsp;&nbsp;return 1;<BR>&nbsp;&nbsp;node = rcu_dereference_raw(node-&gt;slots[offset]);<BR>&nbsp;&nbsp;shift -= RADIX_TREE_MAP_SHIFT;<BR>&nbsp;&nbsp;height--;<BR>&nbsp;}<BR>}<BR>EXPORT_SYMBOL(radix_tree_tag_get);</P>
<P>/**<BR>&nbsp;* radix_tree_next_chunk - find next chunk of slots for iteration<BR>&nbsp;*<BR>&nbsp;* @root:&nbsp;radix tree root<BR>&nbsp;* @iter:&nbsp;iterator state<BR>&nbsp;* @flags:&nbsp;RADIX_TREE_ITER_* flags and tag index<BR>&nbsp;* Returns:&nbsp;pointer to chunk first slot, or NULL if iteration is over<BR>&nbsp;*/<BR>void **radix_tree_next_chunk(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; struct radix_tree_iter *iter, unsigned flags)<BR>{<BR>&nbsp;unsigned shift, tag = flags &amp; RADIX_TREE_ITER_TAG_MASK;<BR>&nbsp;struct radix_tree_node *rnode, *node;<BR>&nbsp;unsigned long index, offset, height;</P>
<P>&nbsp;if ((flags &amp; RADIX_TREE_ITER_TAGGED) &amp;&amp; !root_tag_get(root, tag))<BR>&nbsp;&nbsp;return NULL;</P>
<P>&nbsp;/*<BR>&nbsp; * Catch next_index overflow after ~0UL. iter-&gt;index never overflows<BR>&nbsp; * during iterating; it can be zero only at the beginning.<BR>&nbsp; * And we cannot overflow iter-&gt;next_index in a single step,<BR>&nbsp; * because RADIX_TREE_MAP_SHIFT &lt; BITS_PER_LONG.<BR>&nbsp; *<BR>&nbsp; * This condition also used by radix_tree_next_slot() to stop<BR>&nbsp; * contiguous iterating, and forbid swithing to the next chunk.<BR>&nbsp; */<BR>&nbsp;index = iter-&gt;next_index;<BR>&nbsp;if (!index &amp;&amp; iter-&gt;index)<BR>&nbsp;&nbsp;return NULL;</P>
<P>&nbsp;rnode = rcu_dereference_raw(root-&gt;rnode);<BR>&nbsp;if (radix_tree_is_indirect_ptr(rnode)) {<BR>&nbsp;&nbsp;rnode = indirect_to_ptr(rnode);<BR>&nbsp;} else if (rnode &amp;&amp; !index) {<BR>&nbsp;&nbsp;/* Single-slot tree */<BR>&nbsp;&nbsp;iter-&gt;index = 0;<BR>&nbsp;&nbsp;iter-&gt;next_index = 1;<BR>&nbsp;&nbsp;iter-&gt;tags = 1;<BR>&nbsp;&nbsp;return (void **)&amp;root-&gt;rnode;<BR>&nbsp;} else<BR>&nbsp;&nbsp;return NULL;</P>
<P>restart:<BR>&nbsp;height = rnode-&gt;path &amp; RADIX_TREE_HEIGHT_MASK;<BR>&nbsp;shift = (height - 1) * RADIX_TREE_MAP_SHIFT;<BR>&nbsp;offset = index &gt;&gt; shift;</P>
<P>&nbsp;/* Index outside of the tree */<BR>&nbsp;if (offset &gt;= RADIX_TREE_MAP_SIZE)<BR>&nbsp;&nbsp;return NULL;</P>
<P>&nbsp;node = rnode;<BR>&nbsp;while (1) {<BR>&nbsp;&nbsp;if ((flags &amp; RADIX_TREE_ITER_TAGGED) ?<BR>&nbsp;&nbsp;&nbsp;&nbsp;!test_bit(offset, node-&gt;tags[tag]) :<BR>&nbsp;&nbsp;&nbsp;&nbsp;!node-&gt;slots[offset]) {<BR>&nbsp;&nbsp;&nbsp;/* Hole detected */<BR>&nbsp;&nbsp;&nbsp;if (flags &amp; RADIX_TREE_ITER_CONTIG)<BR>&nbsp;&nbsp;&nbsp;&nbsp;return NULL;</P>
<P>&nbsp;&nbsp;&nbsp;if (flags &amp; RADIX_TREE_ITER_TAGGED)<BR>&nbsp;&nbsp;&nbsp;&nbsp;offset = radix_tree_find_next_bit(<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;node-&gt;tags[tag],<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RADIX_TREE_MAP_SIZE,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;offset + 1);<BR>&nbsp;&nbsp;&nbsp;else<BR>&nbsp;&nbsp;&nbsp;&nbsp;while (++offset&nbsp;&lt; RADIX_TREE_MAP_SIZE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;if (node-&gt;slots[offset])<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;&nbsp;&nbsp;&nbsp;}<BR>&nbsp;&nbsp;&nbsp;index &amp;= ~((RADIX_TREE_MAP_SIZE &lt;&lt; shift) - 1);<BR>&nbsp;&nbsp;&nbsp;index += offset &lt;&lt; shift;<BR>&nbsp;&nbsp;&nbsp;/* Overflow after ~0UL */<BR>&nbsp;&nbsp;&nbsp;if (!index)<BR>&nbsp;&nbsp;&nbsp;&nbsp;return NULL;<BR>&nbsp;&nbsp;&nbsp;if (offset == RADIX_TREE_MAP_SIZE)<BR>&nbsp;&nbsp;&nbsp;&nbsp;goto restart;<BR>&nbsp;&nbsp;}</P>
<P>&nbsp;&nbsp;/* This is leaf-node */<BR>&nbsp;&nbsp;if (!shift)<BR>&nbsp;&nbsp;&nbsp;break;</P>
<P>&nbsp;&nbsp;node = rcu_dereference_raw(node-&gt;slots[offset]);<BR>&nbsp;&nbsp;if (node == NULL)<BR>&nbsp;&nbsp;&nbsp;goto restart;<BR>&nbsp;&nbsp;shift -= RADIX_TREE_MAP_SHIFT;<BR>&nbsp;&nbsp;offset = (index &gt;&gt; shift) &amp; RADIX_TREE_MAP_MASK;<BR>&nbsp;}</P>
<P>&nbsp;/* Update the iterator state */<BR>&nbsp;iter-&gt;index = index;<BR>&nbsp;iter-&gt;next_index = (index | RADIX_TREE_MAP_MASK) + 1;</P>
<P>&nbsp;/* Construct iter-&gt;tags bit-mask from node-&gt;tags[tag] array */<BR>&nbsp;if (flags &amp; RADIX_TREE_ITER_TAGGED) {<BR>&nbsp;&nbsp;unsigned tag_long, tag_bit;</P>
<P>&nbsp;&nbsp;tag_long = offset / BITS_PER_LONG;<BR>&nbsp;&nbsp;tag_bit&nbsp; = offset % BITS_PER_LONG;<BR>&nbsp;&nbsp;iter-&gt;tags = node-&gt;tags[tag][tag_long] &gt;&gt; tag_bit;<BR>&nbsp;&nbsp;/* This never happens if RADIX_TREE_TAG_LONGS == 1 */<BR>&nbsp;&nbsp;if (tag_long &lt; RADIX_TREE_TAG_LONGS - 1) {<BR>&nbsp;&nbsp;&nbsp;/* Pick tags from next element */<BR>&nbsp;&nbsp;&nbsp;if (tag_bit)<BR>&nbsp;&nbsp;&nbsp;&nbsp;iter-&gt;tags |= node-&gt;tags[tag][tag_long + 1] &lt;&lt;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;(BITS_PER_LONG - tag_bit);<BR>&nbsp;&nbsp;&nbsp;/* Clip chunk size, here only BITS_PER_LONG tags */<BR>&nbsp;&nbsp;&nbsp;iter-&gt;next_index = index + BITS_PER_LONG;<BR>&nbsp;&nbsp;}<BR>&nbsp;}</P>
<P>&nbsp;return node-&gt;slots + offset;<BR>}<BR>EXPORT_SYMBOL(radix_tree_next_chunk);</P>
<P>/**<BR>&nbsp;* radix_tree_range_tag_if_tagged - for each item in given range set given<BR>&nbsp;*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tag if item has another tag set<BR>&nbsp;* @root:&nbsp;&nbsp;radix tree root<BR>&nbsp;* @first_indexp:&nbsp;pointer to a starting index of a range to scan<BR>&nbsp;* @last_index:&nbsp;&nbsp;last index of a range to scan<BR>&nbsp;* @nr_to_tag:&nbsp;&nbsp;maximum number items to tag<BR>&nbsp;* @iftag:&nbsp;&nbsp;tag index to test<BR>&nbsp;* @settag:&nbsp;&nbsp;tag index to set if tested tag is set<BR>&nbsp;*<BR>&nbsp;* This function scans range of radix tree from first_index to last_index<BR>&nbsp;* (inclusive).&nbsp; For each item in the range if iftag is set, the function sets<BR>&nbsp;* also settag. The function stops either after tagging nr_to_tag items or<BR>&nbsp;* after reaching last_index.<BR>&nbsp;*<BR>&nbsp;* The tags must be set from the leaf level only and propagated back up the<BR>&nbsp;* path to the root. We must do this so that we resolve the full path before<BR>&nbsp;* setting any tags on intermediate nodes. If we set tags as we descend, then<BR>&nbsp;* we can get to the leaf node and find that the index that has the iftag<BR>&nbsp;* set is outside the range we are scanning. This reults in dangling tags and<BR>&nbsp;* can lead to problems with later tag operations (e.g. livelocks on lookups).<BR>&nbsp;*<BR>&nbsp;* The function returns number of leaves where the tag was set and sets<BR>&nbsp;* *first_indexp to the first unscanned index.<BR>&nbsp;* WARNING! *first_indexp can wrap if last_index is ULONG_MAX. Caller must<BR>&nbsp;* be prepared to handle that.<BR>&nbsp;*/<BR>unsigned long radix_tree_range_tag_if_tagged(struct radix_tree_root *root,<BR>&nbsp;&nbsp;unsigned long *first_indexp, unsigned long last_index,<BR>&nbsp;&nbsp;unsigned long nr_to_tag,<BR>&nbsp;&nbsp;unsigned int iftag, unsigned int settag)<BR>{<BR>&nbsp;unsigned int height = root-&gt;height;<BR>&nbsp;struct radix_tree_node *node = NULL;<BR>&nbsp;struct radix_tree_node *slot;<BR>&nbsp;unsigned int shift;<BR>&nbsp;unsigned long tagged = 0;<BR>&nbsp;unsigned long index = *first_indexp;</P>
<P>&nbsp;last_index = min(last_index, radix_tree_maxindex(height));<BR>&nbsp;if (index &gt; last_index)<BR>&nbsp;&nbsp;return 0;<BR>&nbsp;if (!nr_to_tag)<BR>&nbsp;&nbsp;return 0;<BR>&nbsp;if (!root_tag_get(root, iftag)) {<BR>&nbsp;&nbsp;*first_indexp = last_index + 1;<BR>&nbsp;&nbsp;return 0;<BR>&nbsp;}<BR>&nbsp;if (height == 0) {<BR>&nbsp;&nbsp;*first_indexp = last_index + 1;<BR>&nbsp;&nbsp;root_tag_set(root, settag);<BR>&nbsp;&nbsp;return 1;<BR>&nbsp;}</P>
<P>&nbsp;shift = (height - 1) * RADIX_TREE_MAP_SHIFT;<BR>&nbsp;slot = indirect_to_ptr(root-&gt;rnode);</P>
<P>&nbsp;for (;;) {<BR>&nbsp;&nbsp;unsigned long upindex;<BR>&nbsp;&nbsp;int offset;</P>
<P>&nbsp;&nbsp;offset = (index &gt;&gt; shift) &amp; RADIX_TREE_MAP_MASK;<BR>&nbsp;&nbsp;if (!slot-&gt;slots[offset])<BR>&nbsp;&nbsp;&nbsp;goto next;<BR>&nbsp;&nbsp;if (!tag_get(slot, iftag, offset))<BR>&nbsp;&nbsp;&nbsp;goto next;<BR>&nbsp;&nbsp;if (shift) {<BR>&nbsp;&nbsp;&nbsp;/* Go down one level */<BR>&nbsp;&nbsp;&nbsp;shift -= RADIX_TREE_MAP_SHIFT;<BR>&nbsp;&nbsp;&nbsp;node = slot;<BR>&nbsp;&nbsp;&nbsp;slot = slot-&gt;slots[offset];<BR>&nbsp;&nbsp;&nbsp;continue;<BR>&nbsp;&nbsp;}</P>
<P>&nbsp;&nbsp;/* tag the leaf */<BR>&nbsp;&nbsp;tagged++;<BR>&nbsp;&nbsp;tag_set(slot, settag, offset);</P>
<P>&nbsp;&nbsp;/* walk back up the path tagging interior nodes */<BR>&nbsp;&nbsp;upindex = index;<BR>&nbsp;&nbsp;while (node) {<BR>&nbsp;&nbsp;&nbsp;upindex &gt;&gt;= RADIX_TREE_MAP_SHIFT;<BR>&nbsp;&nbsp;&nbsp;offset = upindex &amp; RADIX_TREE_MAP_MASK;</P>
<P>&nbsp;&nbsp;&nbsp;/* stop if we find a node with the tag already set */<BR>&nbsp;&nbsp;&nbsp;if (tag_get(node, settag, offset))<BR>&nbsp;&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;&nbsp;&nbsp;tag_set(node, settag, offset);<BR>&nbsp;&nbsp;&nbsp;node = node-&gt;parent;<BR>&nbsp;&nbsp;}</P>
<P>&nbsp;&nbsp;/*<BR>&nbsp;&nbsp; * Small optimization: now clear that node pointer.<BR>&nbsp;&nbsp; * Since all of this slot's ancestors now have the tag set<BR>&nbsp;&nbsp; * from setting it above, we have no further need to walk<BR>&nbsp;&nbsp; * back up the tree setting tags, until we update slot to<BR>&nbsp;&nbsp; * point to another radix_tree_node.<BR>&nbsp;&nbsp; */<BR>&nbsp;&nbsp;node = NULL;</P>
<P>next:<BR>&nbsp;&nbsp;/* Go to next item at level determined by 'shift' */<BR>&nbsp;&nbsp;index = ((index &gt;&gt; shift) + 1) &lt;&lt; shift;<BR>&nbsp;&nbsp;/* Overflow can happen when last_index is ~0UL... */<BR>&nbsp;&nbsp;if (index &gt; last_index || !index)<BR>&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;&nbsp;if (tagged &gt;= nr_to_tag)<BR>&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;&nbsp;while (((index &gt;&gt; shift) &amp; RADIX_TREE_MAP_MASK) == 0) {<BR>&nbsp;&nbsp;&nbsp;/*<BR>&nbsp;&nbsp;&nbsp; * We've fully scanned this node. Go up. Because<BR>&nbsp;&nbsp;&nbsp; * last_index is guaranteed to be in the tree, what<BR>&nbsp;&nbsp;&nbsp; * we do below cannot wander astray.<BR>&nbsp;&nbsp;&nbsp; */<BR>&nbsp;&nbsp;&nbsp;slot = slot-&gt;parent;<BR>&nbsp;&nbsp;&nbsp;shift += RADIX_TREE_MAP_SHIFT;<BR>&nbsp;&nbsp;}<BR>&nbsp;}<BR>&nbsp;/*<BR>&nbsp; * We need not to tag the root tag if there is no tag which is set with<BR>&nbsp; * settag within the range from *first_indexp to last_index.<BR>&nbsp; */<BR>&nbsp;if (tagged &gt; 0)<BR>&nbsp;&nbsp;root_tag_set(root, settag);<BR>&nbsp;*first_indexp = index;</P>
<P>&nbsp;return tagged;<BR>}<BR>EXPORT_SYMBOL(radix_tree_range_tag_if_tagged);</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_gang_lookup - perform multiple lookup on a radix tree<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@results:&nbsp;where the results of the lookup are placed<BR>&nbsp;*&nbsp;@first_index:&nbsp;start the lookup from this key<BR>&nbsp;*&nbsp;@max_items:&nbsp;place up to this many items at *results<BR>&nbsp;*<BR>&nbsp;*&nbsp;Performs an index-ascending scan of the tree for present items.&nbsp; Places<BR>&nbsp;*&nbsp;them at <A href="mailto:*@results">*@results</A> and returns the number of items which were placed at<BR>&nbsp;*&nbsp;<A href="mailto:*@results">*@results</A>.<BR>&nbsp;*<BR>&nbsp;*&nbsp;The implementation is naive.<BR>&nbsp;*<BR>&nbsp;*&nbsp;Like radix_tree_lookup, radix_tree_gang_lookup may be called under<BR>&nbsp;*&nbsp;rcu_read_lock. In this case, rather than the returned results being<BR>&nbsp;*&nbsp;an atomic snapshot of the tree at a single point in time, the semantics<BR>&nbsp;*&nbsp;of an RCU protected gang lookup are as though multiple radix_tree_lookups<BR>&nbsp;*&nbsp;have been issued in individual locks, and results stored in 'results'.<BR>&nbsp;*/<BR>unsigned int<BR>radix_tree_gang_lookup(struct radix_tree_root *root, void **results,<BR>&nbsp;&nbsp;&nbsp;unsigned long first_index, unsigned int max_items)<BR>{<BR>&nbsp;struct radix_tree_iter iter;<BR>&nbsp;void **slot;<BR>&nbsp;unsigned int ret = 0;</P>
<P>&nbsp;if (unlikely(!max_items))<BR>&nbsp;&nbsp;return 0;</P>
<P>&nbsp;radix_tree_for_each_slot(slot, root, &amp;iter, first_index) {<BR>&nbsp;&nbsp;results[ret] = indirect_to_ptr(rcu_dereference_raw(*slot));<BR>&nbsp;&nbsp;if (!results[ret])<BR>&nbsp;&nbsp;&nbsp;continue;<BR>&nbsp;&nbsp;if (++ret == max_items)<BR>&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;}</P>
<P>&nbsp;return ret;<BR>}<BR>EXPORT_SYMBOL(radix_tree_gang_lookup);</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_gang_lookup_slot - perform multiple slot lookup on radix tree<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@results:&nbsp;where the results of the lookup are placed<BR>&nbsp;*&nbsp;@indices:&nbsp;where their indices should be placed (but usually NULL)<BR>&nbsp;*&nbsp;@first_index:&nbsp;start the lookup from this key<BR>&nbsp;*&nbsp;@max_items:&nbsp;place up to this many items at *results<BR>&nbsp;*<BR>&nbsp;*&nbsp;Performs an index-ascending scan of the tree for present items.&nbsp; Places<BR>&nbsp;*&nbsp;their slots at <A href="mailto:*@results">*@results</A> and returns the number of items which were<BR>&nbsp;*&nbsp;placed at <A href="mailto:*@results">*@results</A>.<BR>&nbsp;*<BR>&nbsp;*&nbsp;The implementation is naive.<BR>&nbsp;*<BR>&nbsp;*&nbsp;Like radix_tree_gang_lookup as far as RCU and locking goes. Slots must<BR>&nbsp;*&nbsp;be dereferenced with radix_tree_deref_slot, and if using only RCU<BR>&nbsp;*&nbsp;protection, radix_tree_deref_slot may fail requiring a retry.<BR>&nbsp;*/<BR>unsigned int<BR>radix_tree_gang_lookup_slot(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;void ***results, unsigned long *indices,<BR>&nbsp;&nbsp;&nbsp;unsigned long first_index, unsigned int max_items)<BR>{<BR>&nbsp;struct radix_tree_iter iter;<BR>&nbsp;void **slot;<BR>&nbsp;unsigned int ret = 0;</P>
<P>&nbsp;if (unlikely(!max_items))<BR>&nbsp;&nbsp;return 0;</P>
<P>&nbsp;radix_tree_for_each_slot(slot, root, &amp;iter, first_index) {<BR>&nbsp;&nbsp;results[ret] = slot;<BR>&nbsp;&nbsp;if (indices)<BR>&nbsp;&nbsp;&nbsp;indices[ret] = iter.index;<BR>&nbsp;&nbsp;if (++ret == max_items)<BR>&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;}</P>
<P>&nbsp;return ret;<BR>}<BR>EXPORT_SYMBOL(radix_tree_gang_lookup_slot);</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_gang_lookup_tag - perform multiple lookup on a radix tree<BR>&nbsp;*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; based on a tag<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@results:&nbsp;where the results of the lookup are placed<BR>&nbsp;*&nbsp;@first_index:&nbsp;start the lookup from this key<BR>&nbsp;*&nbsp;@max_items:&nbsp;place up to this many items at *results<BR>&nbsp;*&nbsp;@tag:&nbsp;&nbsp;the tag index (&lt; RADIX_TREE_MAX_TAGS)<BR>&nbsp;*<BR>&nbsp;*&nbsp;Performs an index-ascending scan of the tree for present items which<BR>&nbsp;*&nbsp;have the tag indexed by @tag set.&nbsp; Places the items at <A href="mailto:*@results">*@results</A> and<BR>&nbsp;*&nbsp;returns the number of items which were placed at <A href="mailto:*@results">*@results</A>.<BR>&nbsp;*/<BR>unsigned int<BR>radix_tree_gang_lookup_tag(struct radix_tree_root *root, void **results,<BR>&nbsp;&nbsp;unsigned long first_index, unsigned int max_items,<BR>&nbsp;&nbsp;unsigned int tag)<BR>{<BR>&nbsp;struct radix_tree_iter iter;<BR>&nbsp;void **slot;<BR>&nbsp;unsigned int ret = 0;</P>
<P>&nbsp;if (unlikely(!max_items))<BR>&nbsp;&nbsp;return 0;</P>
<P>&nbsp;radix_tree_for_each_tagged(slot, root, &amp;iter, first_index, tag) {<BR>&nbsp;&nbsp;results[ret] = indirect_to_ptr(rcu_dereference_raw(*slot));<BR>&nbsp;&nbsp;if (!results[ret])<BR>&nbsp;&nbsp;&nbsp;continue;<BR>&nbsp;&nbsp;if (++ret == max_items)<BR>&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;}</P>
<P>&nbsp;return ret;<BR>}<BR>EXPORT_SYMBOL(radix_tree_gang_lookup_tag);</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_gang_lookup_tag_slot - perform multiple slot lookup on a<BR>&nbsp;*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; radix tree based on a tag<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@results:&nbsp;where the results of the lookup are placed<BR>&nbsp;*&nbsp;@first_index:&nbsp;start the lookup from this key<BR>&nbsp;*&nbsp;@max_items:&nbsp;place up to this many items at *results<BR>&nbsp;*&nbsp;@tag:&nbsp;&nbsp;the tag index (&lt; RADIX_TREE_MAX_TAGS)<BR>&nbsp;*<BR>&nbsp;*&nbsp;Performs an index-ascending scan of the tree for present items which<BR>&nbsp;*&nbsp;have the tag indexed by @tag set.&nbsp; Places the slots at <A href="mailto:*@results">*@results</A> and<BR>&nbsp;*&nbsp;returns the number of slots which were placed at <A href="mailto:*@results">*@results</A>.<BR>&nbsp;*/<BR>unsigned int<BR>radix_tree_gang_lookup_tag_slot(struct radix_tree_root *root, void ***results,<BR>&nbsp;&nbsp;unsigned long first_index, unsigned int max_items,<BR>&nbsp;&nbsp;unsigned int tag)<BR>{<BR>&nbsp;struct radix_tree_iter iter;<BR>&nbsp;void **slot;<BR>&nbsp;unsigned int ret = 0;</P>
<P>&nbsp;if (unlikely(!max_items))<BR>&nbsp;&nbsp;return 0;</P>
<P>&nbsp;radix_tree_for_each_tagged(slot, root, &amp;iter, first_index, tag) {<BR>&nbsp;&nbsp;results[ret] = slot;<BR>&nbsp;&nbsp;if (++ret == max_items)<BR>&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;}</P>
<P>&nbsp;return ret;<BR>}<BR>EXPORT_SYMBOL(radix_tree_gang_lookup_tag_slot);</P>
<P>#if defined(CONFIG_SHMEM) &amp;&amp; defined(CONFIG_SWAP)<BR>#include &lt;linux/sched.h&gt; /* for cond_resched() */</P>
<P>/*<BR>&nbsp;* This linear search is at present only useful to shmem_unuse_inode().<BR>&nbsp;*/<BR>static unsigned long __locate(struct radix_tree_node *slot, void *item,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; unsigned long index, unsigned long *found_index)<BR>{<BR>&nbsp;unsigned int shift, height;<BR>&nbsp;unsigned long i;</P>
<P>&nbsp;height = slot-&gt;path &amp; RADIX_TREE_HEIGHT_MASK;<BR>&nbsp;shift = (height-1) * RADIX_TREE_MAP_SHIFT;</P>
<P>&nbsp;for ( ; height &gt; 1; height--) {<BR>&nbsp;&nbsp;i = (index &gt;&gt; shift) &amp; RADIX_TREE_MAP_MASK;<BR>&nbsp;&nbsp;for (;;) {<BR>&nbsp;&nbsp;&nbsp;if (slot-&gt;slots[i] != NULL)<BR>&nbsp;&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;&nbsp;&nbsp;index &amp;= ~((1UL &lt;&lt; shift) - 1);<BR>&nbsp;&nbsp;&nbsp;index += 1UL &lt;&lt; shift;<BR>&nbsp;&nbsp;&nbsp;if (index == 0)<BR>&nbsp;&nbsp;&nbsp;&nbsp;goto out;&nbsp;/* 32-bit wraparound */<BR>&nbsp;&nbsp;&nbsp;i++;<BR>&nbsp;&nbsp;&nbsp;if (i == RADIX_TREE_MAP_SIZE)<BR>&nbsp;&nbsp;&nbsp;&nbsp;goto out;<BR>&nbsp;&nbsp;}</P>
<P>&nbsp;&nbsp;shift -= RADIX_TREE_MAP_SHIFT;<BR>&nbsp;&nbsp;slot = rcu_dereference_raw(slot-&gt;slots[i]);<BR>&nbsp;&nbsp;if (slot == NULL)<BR>&nbsp;&nbsp;&nbsp;goto out;<BR>&nbsp;}</P>
<P>&nbsp;/* Bottom level: check items */<BR>&nbsp;for (i = 0; i &lt; RADIX_TREE_MAP_SIZE; i++) {<BR>&nbsp;&nbsp;if (slot-&gt;slots[i] == item) {<BR>&nbsp;&nbsp;&nbsp;*found_index = index + i;<BR>&nbsp;&nbsp;&nbsp;index = 0;<BR>&nbsp;&nbsp;&nbsp;goto out;<BR>&nbsp;&nbsp;}<BR>&nbsp;}<BR>&nbsp;index += RADIX_TREE_MAP_SIZE;<BR>out:<BR>&nbsp;return index;<BR>}</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_locate_item - search through radix tree for item<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@item:&nbsp;&nbsp;item to be found<BR>&nbsp;*<BR>&nbsp;*&nbsp;Returns index where item was found, or -1 if not found.<BR>&nbsp;*&nbsp;Caller must hold no lock (since this time-consuming function needs<BR>&nbsp;*&nbsp;to be preemptible), and must check afterwards if item is still there.<BR>&nbsp;*/<BR>unsigned long radix_tree_locate_item(struct radix_tree_root *root, void *item)<BR>{<BR>&nbsp;struct radix_tree_node *node;<BR>&nbsp;unsigned long max_index;<BR>&nbsp;unsigned long cur_index = 0;<BR>&nbsp;unsigned long found_index = -1;</P>
<P>&nbsp;do {<BR>&nbsp;&nbsp;rcu_read_lock();<BR>&nbsp;&nbsp;node = rcu_dereference_raw(root-&gt;rnode);<BR>&nbsp;&nbsp;if (!radix_tree_is_indirect_ptr(node)) {<BR>&nbsp;&nbsp;&nbsp;rcu_read_unlock();<BR>&nbsp;&nbsp;&nbsp;if (node == item)<BR>&nbsp;&nbsp;&nbsp;&nbsp;found_index = 0;<BR>&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;&nbsp;}</P>
<P>&nbsp;&nbsp;node = indirect_to_ptr(node);<BR>&nbsp;&nbsp;max_index = radix_tree_maxindex(node-&gt;path &amp;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RADIX_TREE_HEIGHT_MASK);<BR>&nbsp;&nbsp;if (cur_index &gt; max_index) {<BR>&nbsp;&nbsp;&nbsp;rcu_read_unlock();<BR>&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;&nbsp;}</P>
<P>&nbsp;&nbsp;cur_index = __locate(node, item, cur_index, &amp;found_index);<BR>&nbsp;&nbsp;rcu_read_unlock();<BR>&nbsp;&nbsp;cond_resched();<BR>&nbsp;} while (cur_index != 0 &amp;&amp; cur_index &lt;= max_index);</P>
<P>&nbsp;return found_index;<BR>}<BR>#else<BR>unsigned long radix_tree_locate_item(struct radix_tree_root *root, void *item)<BR>{<BR>&nbsp;return -1;<BR>}<BR>#endif /* CONFIG_SHMEM &amp;&amp; CONFIG_SWAP */</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_shrink&nbsp;&nbsp;&nbsp; -&nbsp;&nbsp;&nbsp; shrink height of a radix tree to minimal<BR>&nbsp;*&nbsp;@root&nbsp;&nbsp;radix tree root<BR>&nbsp;*/<BR>static inline void radix_tree_shrink(struct radix_tree_root *root)<BR>{<BR>&nbsp;/* try to shrink tree height */<BR>&nbsp;while (root-&gt;height &gt; 0) {<BR>&nbsp;&nbsp;struct radix_tree_node *to_free = root-&gt;rnode;<BR>&nbsp;&nbsp;struct radix_tree_node *slot;</P>
<P>&nbsp;&nbsp;BUG_ON(!radix_tree_is_indirect_ptr(to_free));<BR>&nbsp;&nbsp;to_free = indirect_to_ptr(to_free);</P>
<P>&nbsp;&nbsp;/*<BR>&nbsp;&nbsp; * The candidate node has more than one child, or its child<BR>&nbsp;&nbsp; * is not at the leftmost slot, we cannot shrink.<BR>&nbsp;&nbsp; */<BR>&nbsp;&nbsp;if (to_free-&gt;count != 1)<BR>&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;&nbsp;if (!to_free-&gt;slots[0])<BR>&nbsp;&nbsp;&nbsp;break;</P>
<P>&nbsp;&nbsp;/*<BR>&nbsp;&nbsp; * We don't need rcu_assign_pointer(), since we are simply<BR>&nbsp;&nbsp; * moving the node from one part of the tree to another: if it<BR>&nbsp;&nbsp; * was safe to dereference the old pointer to it<BR>&nbsp;&nbsp; * (to_free-&gt;slots[0]), it will be safe to dereference the new<BR>&nbsp;&nbsp; * one (root-&gt;rnode) as far as dependent read barriers go.<BR>&nbsp;&nbsp; */<BR>&nbsp;&nbsp;slot = to_free-&gt;slots[0];<BR>&nbsp;&nbsp;if (root-&gt;height &gt; 1) {<BR>&nbsp;&nbsp;&nbsp;slot-&gt;parent = NULL;<BR>&nbsp;&nbsp;&nbsp;slot = ptr_to_indirect(slot);<BR>&nbsp;&nbsp;}<BR>&nbsp;&nbsp;root-&gt;rnode = slot;<BR>&nbsp;&nbsp;root-&gt;height--;</P>
<P>&nbsp;&nbsp;/*<BR>&nbsp;&nbsp; * We have a dilemma here. The node's slot[0] must not be<BR>&nbsp;&nbsp; * NULLed in case there are concurrent lookups expecting to<BR>&nbsp;&nbsp; * find the item. However if this was a bottom-level node,<BR>&nbsp;&nbsp; * then it may be subject to the slot pointer being visible<BR>&nbsp;&nbsp; * to callers dereferencing it. If item corresponding to<BR>&nbsp;&nbsp; * slot[0] is subsequently deleted, these callers would expect<BR>&nbsp;&nbsp; * their slot to become empty sooner or later.<BR>&nbsp;&nbsp; *<BR>&nbsp;&nbsp; * For example, lockless pagecache will look up a slot, deref<BR>&nbsp;&nbsp; * the page pointer, and if the page is 0 refcount it means it<BR>&nbsp;&nbsp; * was concurrently deleted from pagecache so try the deref<BR>&nbsp;&nbsp; * again. Fortunately there is already a requirement for logic<BR>&nbsp;&nbsp; * to retry the entire slot lookup -- the indirect pointer<BR>&nbsp;&nbsp; * problem (replacing direct root node with an indirect pointer<BR>&nbsp;&nbsp; * also results in a stale slot). So tag the slot as indirect<BR>&nbsp;&nbsp; * to force callers to retry.<BR>&nbsp;&nbsp; */<BR>&nbsp;&nbsp;if (root-&gt;height == 0)<BR>&nbsp;&nbsp;&nbsp;*((unsigned long *)&amp;to_free-&gt;slots[0]) |=<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RADIX_TREE_INDIRECT_PTR;</P>
<P>&nbsp;&nbsp;radix_tree_node_free(to_free);<BR>&nbsp;}<BR>}</P>
<P>/**<BR>&nbsp;*&nbsp;__radix_tree_delete_node&nbsp;&nbsp;&nbsp; -&nbsp;&nbsp;&nbsp; try to free node after clearing a slot<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@node:&nbsp;&nbsp;node containing @index<BR>&nbsp;*<BR>&nbsp;*&nbsp;After clearing the slot at @index in @node from radix tree<BR>&nbsp;*&nbsp;rooted at @root, call this function to attempt freeing the<BR>&nbsp;*&nbsp;node and shrinking the tree.<BR>&nbsp;*<BR>&nbsp;*&nbsp;Returns %true if @node was freed, %false otherwise.<BR>&nbsp;*/<BR>bool __radix_tree_delete_node(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; struct radix_tree_node *node)<BR>{<BR>&nbsp;bool deleted = false;</P>
<P>&nbsp;do {<BR>&nbsp;&nbsp;struct radix_tree_node *parent;</P>
<P>&nbsp;&nbsp;if (node-&gt;count) {<BR>&nbsp;&nbsp;&nbsp;if (node == indirect_to_ptr(root-&gt;rnode)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;radix_tree_shrink(root);<BR>&nbsp;&nbsp;&nbsp;&nbsp;if (root-&gt;height == 0)<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;deleted = true;<BR>&nbsp;&nbsp;&nbsp;}<BR>&nbsp;&nbsp;&nbsp;return deleted;<BR>&nbsp;&nbsp;}</P>
<P>&nbsp;&nbsp;parent = node-&gt;parent;<BR>&nbsp;&nbsp;if (parent) {<BR>&nbsp;&nbsp;&nbsp;unsigned int offset;</P>
<P>&nbsp;&nbsp;&nbsp;offset = node-&gt;path &gt;&gt; RADIX_TREE_HEIGHT_SHIFT;<BR>&nbsp;&nbsp;&nbsp;parent-&gt;slots[offset] = NULL;<BR>&nbsp;&nbsp;&nbsp;parent-&gt;count--;<BR>&nbsp;&nbsp;} else {<BR>&nbsp;&nbsp;&nbsp;root_tag_clear_all(root);<BR>&nbsp;&nbsp;&nbsp;root-&gt;height = 0;<BR>&nbsp;&nbsp;&nbsp;root-&gt;rnode = NULL;<BR>&nbsp;&nbsp;}</P>
<P>&nbsp;&nbsp;radix_tree_node_free(node);<BR>&nbsp;&nbsp;deleted = true;</P>
<P>&nbsp;&nbsp;node = parent;<BR>&nbsp;} while (node);</P>
<P>&nbsp;return deleted;<BR>}</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_delete_item&nbsp;&nbsp;&nbsp; -&nbsp;&nbsp;&nbsp; delete an item from a radix tree<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@index:&nbsp;&nbsp;index key<BR>&nbsp;*&nbsp;@item:&nbsp;&nbsp;expected item<BR>&nbsp;*<BR>&nbsp;*&nbsp;Remove @item at @index from the radix tree rooted at @root.<BR>&nbsp;*<BR>&nbsp;*&nbsp;Returns the address of the deleted item, or NULL if it was not present<BR>&nbsp;*&nbsp;or the entry at the given @index was not @item.<BR>&nbsp;*/<BR>void *radix_tree_delete_item(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; unsigned long index, void *item)<BR>{<BR>&nbsp;struct radix_tree_node *node;<BR>&nbsp;unsigned int offset;<BR>&nbsp;void **slot;<BR>&nbsp;void *entry;<BR>&nbsp;int tag;</P>
<P>&nbsp;entry = __radix_tree_lookup(root, index, &amp;node, &amp;slot);<BR>&nbsp;if (!entry)<BR>&nbsp;&nbsp;return NULL;</P>
<P>&nbsp;if (item &amp;&amp; entry != item)<BR>&nbsp;&nbsp;return NULL;</P>
<P>&nbsp;if (!node) {<BR>&nbsp;&nbsp;root_tag_clear_all(root);<BR>&nbsp;&nbsp;root-&gt;rnode = NULL;<BR>&nbsp;&nbsp;return entry;<BR>&nbsp;}</P>
<P>&nbsp;offset = index &amp; RADIX_TREE_MAP_MASK;</P>
<P>&nbsp;/*<BR>&nbsp; * Clear all tags associated with the item to be deleted.<BR>&nbsp; * This way of doing it would be inefficient, but seldom is any set.<BR>&nbsp; */<BR>&nbsp;for (tag = 0; tag &lt; RADIX_TREE_MAX_TAGS; tag++) {<BR>&nbsp;&nbsp;if (tag_get(node, tag, offset))<BR>&nbsp;&nbsp;&nbsp;radix_tree_tag_clear(root, index, tag);<BR>&nbsp;}</P>
<P>&nbsp;node-&gt;slots[offset] = NULL;<BR>&nbsp;node-&gt;count--;</P>
<P>&nbsp;__radix_tree_delete_node(root, node);</P>
<P>&nbsp;return entry;<BR>}<BR>EXPORT_SYMBOL(radix_tree_delete_item);</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_delete&nbsp;&nbsp;&nbsp; -&nbsp;&nbsp;&nbsp; delete an item from a radix tree<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@index:&nbsp;&nbsp;index key<BR>&nbsp;*<BR>&nbsp;*&nbsp;Remove the item at @index from the radix tree rooted at @root.<BR>&nbsp;*<BR>&nbsp;*&nbsp;Returns the address of the deleted item, or NULL if it was not present.<BR>&nbsp;*/<BR>void *radix_tree_delete(struct radix_tree_root *root, unsigned long index)<BR>{<BR>&nbsp;return radix_tree_delete_item(root, index, NULL);<BR>}<BR>EXPORT_SYMBOL(radix_tree_delete);</P>
<P>/**<BR>&nbsp;*&nbsp;radix_tree_tagged - test whether any items in the tree are tagged<BR>&nbsp;*&nbsp;@root:&nbsp;&nbsp;radix tree root<BR>&nbsp;*&nbsp;@tag:&nbsp;&nbsp;tag to test<BR>&nbsp;*/<BR>int radix_tree_tagged(struct radix_tree_root *root, unsigned int tag)<BR>{<BR>&nbsp;return root_tag_get(root, tag);<BR>}<BR>EXPORT_SYMBOL(radix_tree_tagged);</P>
<P>static void<BR>radix_tree_node_ctor(void *arg)<BR>{<BR>&nbsp;struct radix_tree_node *node = arg;</P>
<P>&nbsp;memset(node, 0, sizeof(*node));<BR>&nbsp;INIT_LIST_HEAD(&amp;node-&gt;private_list);<BR>}</P>
<P>static __init unsigned long __maxindex(unsigned int height)<BR>{<BR>&nbsp;unsigned int width = height * RADIX_TREE_MAP_SHIFT;<BR>&nbsp;int shift = RADIX_TREE_INDEX_BITS - width;</P>
<P>&nbsp;if (shift &lt; 0)<BR>&nbsp;&nbsp;return ~0UL;<BR>&nbsp;if (shift &gt;= BITS_PER_LONG)<BR>&nbsp;&nbsp;return 0UL;<BR>&nbsp;return ~0UL &gt;&gt; shift;<BR>}</P>
<P>static __init void radix_tree_init_maxindex(void)<BR>{<BR>&nbsp;unsigned int i;</P>
<P>&nbsp;for (i = 0; i &lt; ARRAY_SIZE(height_to_maxindex); i++)<BR>&nbsp;&nbsp;height_to_maxindex[i] = __maxindex(i);<BR>}</P>
<P>static int radix_tree_callback(struct notifier_block *nfb,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; unsigned long action,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; void *hcpu)<BR>{<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int cpu = (long)hcpu;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; struct radix_tree_preload *rtp;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; struct radix_tree_node *node;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* Free per-cpu pool of perloaded nodes */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (action == CPU_DEAD || action == CPU_DEAD_FROZEN) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rtp = &amp;per_cpu(radix_tree_preloads, cpu);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; while (rtp-&gt;nr) {<BR>&nbsp;&nbsp;&nbsp;node = rtp-&gt;nodes;<BR>&nbsp;&nbsp;&nbsp;rtp-&gt;nodes = node-&gt;private_data;<BR>&nbsp;&nbsp;&nbsp;kmem_cache_free(radix_tree_node_cachep, node);<BR>&nbsp;&nbsp;&nbsp;rtp-&gt;nr--;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return NOTIFY_OK;<BR>}</P>
<P>void __init radix_tree_init(void)<BR>{<BR>&nbsp;radix_tree_node_cachep = kmem_cache_create("radix_tree_node",<BR>&nbsp;&nbsp;&nbsp;sizeof(struct radix_tree_node), 0,<BR>&nbsp;&nbsp;&nbsp;SLAB_PANIC | SLAB_RECLAIM_ACCOUNT,<BR>&nbsp;&nbsp;&nbsp;radix_tree_node_ctor);<BR>&nbsp;radix_tree_init_maxindex();<BR>&nbsp;hotcpu_notifier(radix_tree_callback, 0);<BR>}