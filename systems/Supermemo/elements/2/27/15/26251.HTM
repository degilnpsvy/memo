# include/linux/radix-tree.h
<P></P>
<P>/*<BR>&nbsp;* Copyright (C) 2001 Momchil Velikov<BR>&nbsp;* Portions Copyright (C) 2001 Christoph Hellwig<BR>&nbsp;* Copyright (C) 2006 Nick Piggin<BR>&nbsp;* Copyright (C) 2012 Konstantin Khlebnikov<BR>&nbsp;*<BR>&nbsp;* This program is free software; you can redistribute it and/or<BR>&nbsp;* modify it under the terms of the GNU General Public License as<BR>&nbsp;* published by the Free Software Foundation; either version 2, or (at<BR>&nbsp;* your option) any later version.<BR>&nbsp;* <BR>&nbsp;* This program is distributed in the hope that it will be useful, but<BR>&nbsp;* WITHOUT ANY WARRANTY; without even the implied warranty of<BR>&nbsp;* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.&nbsp; See the GNU<BR>&nbsp;* General Public License for more details.<BR>&nbsp;* <BR>&nbsp;* You should have received a copy of the GNU General Public License<BR>&nbsp;* along with this program; if not, write to the Free Software<BR>&nbsp;* Foundation, Inc., 675 Mass Ave, Cambridge, MA 02139, USA.<BR>&nbsp;*/<BR>#ifndef _LINUX_RADIX_TREE_H<BR>#define _LINUX_RADIX_TREE_H</P>
<P></P>
<P>#include &lt;linux/preempt.h&gt;<BR>#include &lt;linux/types.h&gt;<BR>#include &lt;linux/bug.h&gt;<BR>#include &lt;linux/kernel.h&gt;<BR>#include &lt;linux/rcupdate.h&gt;</P>
<P>/*<BR>&nbsp;* An indirect pointer (root-&gt;rnode pointing to a radix_tree_node, rather<BR>&nbsp;* than a data item) is signalled by the low bit set in the root-&gt;rnode<BR>&nbsp;* pointer.<BR>&nbsp;*<BR>&nbsp;* In this case root-&gt;height is &gt; 0, but the indirect pointer tests are<BR>&nbsp;* needed for RCU lookups (because root-&gt;height is unreliable). The only<BR>&nbsp;* time callers need worry about this is when doing a lookup_slot under<BR>&nbsp;* RCU.<BR>&nbsp;*<BR>&nbsp;* Indirect pointer in fact is also used to tag the last pointer of a node<BR>&nbsp;* when it is shrunk, before we rcu free the node. See shrink code for<BR>&nbsp;* details.<BR>&nbsp;*/<BR>#define RADIX_TREE_INDIRECT_PTR&nbsp;&nbsp;1<BR>/*<BR>&nbsp;* A common use of the radix tree is to store pointers to struct pages;<BR>&nbsp;* but shmem/tmpfs needs also to store swap entries in the same tree:<BR>&nbsp;* those are marked as exceptional entries to distinguish them.<BR>&nbsp;* EXCEPTIONAL_ENTRY tests the bit, EXCEPTIONAL_SHIFT shifts content past it.<BR>&nbsp;*/<BR>#define RADIX_TREE_EXCEPTIONAL_ENTRY&nbsp;2<BR>#define RADIX_TREE_EXCEPTIONAL_SHIFT&nbsp;2</P>
<P>static inline int radix_tree_is_indirect_ptr(void *ptr)<BR>{<BR>&nbsp;return (int)((unsigned long)ptr &amp; RADIX_TREE_INDIRECT_PTR);<BR>}</P>
<P>/*** radix-tree API starts here ***/</P>
<P>#define RADIX_TREE_MAX_TAGS 3</P>
<P>#ifdef __KERNEL__<BR>#define RADIX_TREE_MAP_SHIFT&nbsp;(CONFIG_BASE_SMALL ? 4 : 6)<BR>#else<BR>#define RADIX_TREE_MAP_SHIFT&nbsp;3&nbsp;/* For more stressful testing */<BR>#endif</P>
<P>#define RADIX_TREE_MAP_SIZE&nbsp;(1UL &lt;&lt; RADIX_TREE_MAP_SHIFT)<BR>#define RADIX_TREE_MAP_MASK&nbsp;(RADIX_TREE_MAP_SIZE-1)</P>
<P>#define RADIX_TREE_TAG_LONGS&nbsp;\<BR>&nbsp;((RADIX_TREE_MAP_SIZE + BITS_PER_LONG - 1) / BITS_PER_LONG)</P>
<P>#define RADIX_TREE_INDEX_BITS&nbsp; (8 /* CHAR_BIT */ * sizeof(unsigned long))<BR>#define RADIX_TREE_MAX_PATH (DIV_ROUND_UP(RADIX_TREE_INDEX_BITS, \<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RADIX_TREE_MAP_SHIFT))</P>
<P>/* Height component in node-&gt;path */<BR>#define RADIX_TREE_HEIGHT_SHIFT&nbsp;(RADIX_TREE_MAX_PATH + 1)<BR>#define RADIX_TREE_HEIGHT_MASK&nbsp;((1UL &lt;&lt; RADIX_TREE_HEIGHT_SHIFT) - 1)</P>
<P>/* Internally used bits of node-&gt;count */<BR>#define RADIX_TREE_COUNT_SHIFT&nbsp;(RADIX_TREE_MAP_SHIFT + 1)<BR>#define RADIX_TREE_COUNT_MASK&nbsp;((1UL &lt;&lt; RADIX_TREE_COUNT_SHIFT) - 1)</P>
<P>struct radix_tree_node {<BR>&nbsp;unsigned int&nbsp;path;&nbsp;/* Offset in parent &amp; height from the bottom */<BR>&nbsp;unsigned int&nbsp;count;<BR>&nbsp;union {<BR>&nbsp;&nbsp;struct {<BR>&nbsp;&nbsp;&nbsp;/* Used when ascending tree */<BR>&nbsp;&nbsp;&nbsp;struct radix_tree_node *parent;<BR>&nbsp;&nbsp;&nbsp;/* For tree user */<BR>&nbsp;&nbsp;&nbsp;void *private_data;<BR>&nbsp;&nbsp;};<BR>&nbsp;&nbsp;/* Used when freeing node */<BR>&nbsp;&nbsp;struct rcu_head&nbsp;rcu_head;<BR>&nbsp;};<BR>&nbsp;/* For tree user */<BR>&nbsp;struct list_head private_list;<BR>&nbsp;void __rcu&nbsp;*slots[RADIX_TREE_MAP_SIZE];<BR>&nbsp;unsigned long&nbsp;tags[RADIX_TREE_MAX_TAGS][RADIX_TREE_TAG_LONGS];<BR>};</P>
<P>/* root tags are stored in gfp_mask, shifted by __GFP_BITS_SHIFT */<BR>struct radix_tree_root {<BR>&nbsp;unsigned int&nbsp;&nbsp;height;<BR>&nbsp;gfp_t&nbsp;&nbsp;&nbsp;gfp_mask;<BR>&nbsp;struct radix_tree_node&nbsp;__rcu *rnode;<BR>};</P>
<P>#define RADIX_TREE_INIT(mask)&nbsp;{&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;.height = 0,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;.gfp_mask = (mask),&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;.rnode = NULL,&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>}</P>
<P>#define RADIX_TREE(name, mask) \<BR>&nbsp;struct radix_tree_root name = RADIX_TREE_INIT(mask)</P>
<P>#define INIT_RADIX_TREE(root, mask)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>do {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;(root)-&gt;height = 0;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;(root)-&gt;gfp_mask = (mask);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;(root)-&gt;rnode = NULL;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>} while (0)</P>
<P>/**<BR>&nbsp;* Radix-tree synchronization<BR>&nbsp;*<BR>&nbsp;* The radix-tree API requires that users provide all synchronisation (with<BR>&nbsp;* specific exceptions, noted below).<BR>&nbsp;*<BR>&nbsp;* Synchronization of access to the data items being stored in the tree, and<BR>&nbsp;* management of their lifetimes must be completely managed by API users.<BR>&nbsp;*<BR>&nbsp;* For API usage, in general,<BR>&nbsp;* - any function _modifying_ the tree or tags (inserting or deleting<BR>&nbsp;*&nbsp;&nbsp; items, setting or clearing tags) must exclude other modifications, and<BR>&nbsp;*&nbsp;&nbsp; exclude any functions reading the tree.<BR>&nbsp;* - any function _reading_ the tree or tags (looking up items or tags,<BR>&nbsp;*&nbsp;&nbsp; gang lookups) must exclude modifications to the tree, but may occur<BR>&nbsp;*&nbsp;&nbsp; concurrently with other readers.<BR>&nbsp;*<BR>&nbsp;* The notable exceptions to this rule are the following functions:<BR>&nbsp;* __radix_tree_lookup<BR>&nbsp;* radix_tree_lookup<BR>&nbsp;* radix_tree_lookup_slot<BR>&nbsp;* radix_tree_tag_get<BR>&nbsp;* radix_tree_gang_lookup<BR>&nbsp;* radix_tree_gang_lookup_slot<BR>&nbsp;* radix_tree_gang_lookup_tag<BR>&nbsp;* radix_tree_gang_lookup_tag_slot<BR>&nbsp;* radix_tree_tagged<BR>&nbsp;*<BR>&nbsp;* The first 7 functions are able to be called locklessly, using RCU. The<BR>&nbsp;* caller must ensure calls to these functions are made within rcu_read_lock()<BR>&nbsp;* regions. Other readers (lock-free or otherwise) and modifications may be<BR>&nbsp;* running concurrently.<BR>&nbsp;*<BR>&nbsp;* It is still required that the caller manage the synchronization and lifetimes<BR>&nbsp;* of the items. So if RCU lock-free lookups are used, typically this would mean<BR>&nbsp;* that the items have their own locks, or are amenable to lock-free access; and<BR>&nbsp;* that the items are freed by RCU (or only freed after having been deleted from<BR>&nbsp;* the radix tree *and* a synchronize_rcu() grace period).<BR>&nbsp;*<BR>&nbsp;* (Note, rcu_assign_pointer and rcu_dereference are not needed to control<BR>&nbsp;* access to data items when inserting into or looking up from the radix tree)<BR>&nbsp;*<BR>&nbsp;* Note that the value returned by radix_tree_tag_get() may not be relied upon<BR>&nbsp;* if only the RCU read lock is held.&nbsp; Functions to set/clear tags and to<BR>&nbsp;* delete nodes running concurrently with it may affect its result such that<BR>&nbsp;* two consecutive reads in the same locked section may return different<BR>&nbsp;* values.&nbsp; If reliability is required, modification functions must also be<BR>&nbsp;* excluded from concurrency.<BR>&nbsp;*<BR>&nbsp;* radix_tree_tagged is able to be called without locking or RCU.<BR>&nbsp;*/</P>
<P>/**<BR>&nbsp;* radix_tree_deref_slot&nbsp;- dereference a slot<BR>&nbsp;* @pslot:&nbsp;pointer to slot, returned by radix_tree_lookup_slot<BR>&nbsp;* Returns:&nbsp;item that was stored in that slot with any direct pointer flag<BR>&nbsp;*&nbsp;&nbsp;removed.<BR>&nbsp;*<BR>&nbsp;* For use with radix_tree_lookup_slot().&nbsp; Caller must hold tree at least read<BR>&nbsp;* locked across slot lookup and dereference. Not required if write lock is<BR>&nbsp;* held (ie. items cannot be concurrently inserted).<BR>&nbsp;*<BR>&nbsp;* radix_tree_deref_retry must be used to confirm validity of the pointer if<BR>&nbsp;* only the read lock is held.<BR>&nbsp;*/<BR>static inline void *radix_tree_deref_slot(void **pslot)<BR>{<BR>&nbsp;return rcu_dereference(*pslot);<BR>}</P>
<P>/**<BR>&nbsp;* radix_tree_deref_slot_protected&nbsp;- dereference a slot without RCU lock but with tree lock held<BR>&nbsp;* @pslot:&nbsp;pointer to slot, returned by radix_tree_lookup_slot<BR>&nbsp;* Returns:&nbsp;item that was stored in that slot with any direct pointer flag<BR>&nbsp;*&nbsp;&nbsp;removed.<BR>&nbsp;*<BR>&nbsp;* Similar to radix_tree_deref_slot but only used during migration when a pages<BR>&nbsp;* mapping is being moved. The caller does not hold the RCU read lock but it<BR>&nbsp;* must hold the tree lock to prevent parallel updates.<BR>&nbsp;*/<BR>static inline void *radix_tree_deref_slot_protected(void **pslot,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;spinlock_t *treelock)<BR>{<BR>&nbsp;return rcu_dereference_protected(*pslot, lockdep_is_held(treelock));<BR>}</P>
<P>/**<BR>&nbsp;* radix_tree_deref_retry&nbsp;- check radix_tree_deref_slot<BR>&nbsp;* @arg:&nbsp;pointer returned by radix_tree_deref_slot<BR>&nbsp;* Returns:&nbsp;0 if retry is not required, otherwise retry is required<BR>&nbsp;*<BR>&nbsp;* radix_tree_deref_retry must be used with radix_tree_deref_slot.<BR>&nbsp;*/<BR>static inline int radix_tree_deref_retry(void *arg)<BR>{<BR>&nbsp;return unlikely((unsigned long)arg &amp; RADIX_TREE_INDIRECT_PTR);<BR>}</P>
<P>/**<BR>&nbsp;* radix_tree_exceptional_entry&nbsp;- radix_tree_deref_slot gave exceptional entry?<BR>&nbsp;* @arg:&nbsp;value returned by radix_tree_deref_slot<BR>&nbsp;* Returns:&nbsp;0 if well-aligned pointer, non-0 if exceptional entry.<BR>&nbsp;*/<BR>static inline int radix_tree_exceptional_entry(void *arg)<BR>{<BR>&nbsp;/* Not unlikely because radix_tree_exception often tested first */<BR>&nbsp;return (unsigned long)arg &amp; RADIX_TREE_EXCEPTIONAL_ENTRY;<BR>}</P>
<P>/**<BR>&nbsp;* radix_tree_exception&nbsp;- radix_tree_deref_slot returned either exception?<BR>&nbsp;* @arg:&nbsp;value returned by radix_tree_deref_slot<BR>&nbsp;* Returns:&nbsp;0 if well-aligned pointer, non-0 if either kind of exception.<BR>&nbsp;*/<BR>static inline int radix_tree_exception(void *arg)<BR>{<BR>&nbsp;return unlikely((unsigned long)arg &amp;<BR>&nbsp;&nbsp;(RADIX_TREE_INDIRECT_PTR | RADIX_TREE_EXCEPTIONAL_ENTRY));<BR>}</P>
<P>/**<BR>&nbsp;* radix_tree_replace_slot&nbsp;- replace item in a slot<BR>&nbsp;* @pslot:&nbsp;pointer to slot, returned by radix_tree_lookup_slot<BR>&nbsp;* @item:&nbsp;new item to store in the slot.<BR>&nbsp;*<BR>&nbsp;* For use with radix_tree_lookup_slot().&nbsp; Caller must hold tree write locked<BR>&nbsp;* across slot lookup and replacement.<BR>&nbsp;*/<BR>static inline void radix_tree_replace_slot(void **pslot, void *item)<BR>{<BR>&nbsp;BUG_ON(radix_tree_is_indirect_ptr(item));<BR>&nbsp;rcu_assign_pointer(*pslot, item);<BR>}</P>
<P>int __radix_tree_create(struct radix_tree_root *root, unsigned long index,<BR>&nbsp;&nbsp;&nbsp;struct radix_tree_node **nodep, void ***slotp);<BR>int radix_tree_insert(struct radix_tree_root *, unsigned long, void *);<BR>void *__radix_tree_lookup(struct radix_tree_root *root, unsigned long index,<BR>&nbsp;&nbsp;&nbsp;&nbsp; struct radix_tree_node **nodep, void ***slotp);<BR>void *radix_tree_lookup(struct radix_tree_root *, unsigned long);<BR>void **radix_tree_lookup_slot(struct radix_tree_root *, unsigned long);<BR>bool __radix_tree_delete_node(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; struct radix_tree_node *node);<BR>void *radix_tree_delete_item(struct radix_tree_root *, unsigned long, void *);<BR>void *radix_tree_delete(struct radix_tree_root *, unsigned long);<BR>unsigned int<BR>radix_tree_gang_lookup(struct radix_tree_root *root, void **results,<BR>&nbsp;&nbsp;&nbsp;unsigned long first_index, unsigned int max_items);<BR>unsigned int radix_tree_gang_lookup_slot(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;void ***results, unsigned long *indices,<BR>&nbsp;&nbsp;&nbsp;unsigned long first_index, unsigned int max_items);<BR>int radix_tree_preload(gfp_t gfp_mask);<BR>int radix_tree_maybe_preload(gfp_t gfp_mask);<BR>void radix_tree_init(void);<BR>void *radix_tree_tag_set(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;unsigned long index, unsigned int tag);<BR>void *radix_tree_tag_clear(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;unsigned long index, unsigned int tag);<BR>int radix_tree_tag_get(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;unsigned long index, unsigned int tag);<BR>unsigned int<BR>radix_tree_gang_lookup_tag(struct radix_tree_root *root, void **results,<BR>&nbsp;&nbsp;unsigned long first_index, unsigned int max_items,<BR>&nbsp;&nbsp;unsigned int tag);<BR>unsigned int<BR>radix_tree_gang_lookup_tag_slot(struct radix_tree_root *root, void ***results,<BR>&nbsp;&nbsp;unsigned long first_index, unsigned int max_items,<BR>&nbsp;&nbsp;unsigned int tag);<BR>unsigned long radix_tree_range_tag_if_tagged(struct radix_tree_root *root,<BR>&nbsp;&nbsp;unsigned long *first_indexp, unsigned long last_index,<BR>&nbsp;&nbsp;unsigned long nr_to_tag,<BR>&nbsp;&nbsp;unsigned int fromtag, unsigned int totag);<BR>int radix_tree_tagged(struct radix_tree_root *root, unsigned int tag);<BR>unsigned long radix_tree_locate_item(struct radix_tree_root *root, void *item);</P>
<P>static inline void radix_tree_preload_end(void)<BR>{<BR>&nbsp;preempt_enable();<BR>}</P>
<P>/**<BR>&nbsp;* struct radix_tree_iter - radix tree iterator state<BR>&nbsp;*<BR>&nbsp;* @index:&nbsp;index of current slot<BR>&nbsp;* @next_index:&nbsp;next-to-last index for this chunk<BR>&nbsp;* @tags:&nbsp;bit-mask for tag-iterating<BR>&nbsp;*<BR>&nbsp;* This radix tree iterator works in terms of "chunks" of slots.&nbsp; A chunk is a<BR>&nbsp;* subinterval of slots contained within one radix tree leaf node.&nbsp; It is<BR>&nbsp;* described by a pointer to its first slot and a struct radix_tree_iter<BR>&nbsp;* which holds the chunk's position in the tree and its size.&nbsp; For tagged<BR>&nbsp;* iteration radix_tree_iter also holds the slots' bit-mask for one chosen<BR>&nbsp;* radix tree tag.<BR>&nbsp;*/<BR>struct radix_tree_iter {<BR>&nbsp;unsigned long&nbsp;index;<BR>&nbsp;unsigned long&nbsp;next_index;<BR>&nbsp;unsigned long&nbsp;tags;<BR>};</P>
<P>#define RADIX_TREE_ITER_TAG_MASK&nbsp;0x00FF&nbsp;/* tag index in lower byte */<BR>#define RADIX_TREE_ITER_TAGGED&nbsp;&nbsp;0x0100&nbsp;/* lookup tagged slots */<BR>#define RADIX_TREE_ITER_CONTIG&nbsp;&nbsp;0x0200&nbsp;/* stop at first hole */</P>
<P>/**<BR>&nbsp;* radix_tree_iter_init - initialize radix tree iterator<BR>&nbsp;*<BR>&nbsp;* @iter:&nbsp;pointer to iterator state<BR>&nbsp;* @start:&nbsp;iteration starting index<BR>&nbsp;* Returns:&nbsp;NULL<BR>&nbsp;*/<BR>static __always_inline void **<BR>radix_tree_iter_init(struct radix_tree_iter *iter, unsigned long start)<BR>{<BR>&nbsp;/*<BR>&nbsp; * Leave iter-&gt;tags uninitialized. radix_tree_next_chunk() will fill it<BR>&nbsp; * in the case of a successful tagged chunk lookup.&nbsp; If the lookup was<BR>&nbsp; * unsuccessful or non-tagged then nobody cares about -&gt;tags.<BR>&nbsp; *<BR>&nbsp; * Set index to zero to bypass next_index overflow protection.<BR>&nbsp; * See the comment in radix_tree_next_chunk() for details.<BR>&nbsp; */<BR>&nbsp;iter-&gt;index = 0;<BR>&nbsp;iter-&gt;next_index = start;<BR>&nbsp;return NULL;<BR>}</P>
<P>/**<BR>&nbsp;* radix_tree_next_chunk - find next chunk of slots for iteration<BR>&nbsp;*<BR>&nbsp;* @root:&nbsp;radix tree root<BR>&nbsp;* @iter:&nbsp;iterator state<BR>&nbsp;* @flags:&nbsp;RADIX_TREE_ITER_* flags and tag index<BR>&nbsp;* Returns:&nbsp;pointer to chunk first slot, or NULL if there no more left<BR>&nbsp;*<BR>&nbsp;* This function looks up the next chunk in the radix tree starting from<BR>&nbsp;* @iter-&gt;next_index.&nbsp; It returns a pointer to the chunk's first slot.<BR>&nbsp;* Also it fills @iter with data about chunk: position in the tree (index),<BR>&nbsp;* its end (next_index), and constructs a bit mask for tagged iterating (tags).<BR>&nbsp;*/<BR>void **radix_tree_next_chunk(struct radix_tree_root *root,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; struct radix_tree_iter *iter, unsigned flags);</P>
<P>/**<BR>&nbsp;* radix_tree_chunk_size - get current chunk size<BR>&nbsp;*<BR>&nbsp;* @iter:&nbsp;pointer to radix tree iterator<BR>&nbsp;* Returns:&nbsp;current chunk size<BR>&nbsp;*/<BR>static __always_inline unsigned<BR>radix_tree_chunk_size(struct radix_tree_iter *iter)<BR>{<BR>&nbsp;return iter-&gt;next_index - iter-&gt;index;<BR>}</P>
<P>/**<BR>&nbsp;* radix_tree_next_slot - find next slot in chunk<BR>&nbsp;*<BR>&nbsp;* @slot:&nbsp;pointer to current slot<BR>&nbsp;* @iter:&nbsp;pointer to interator state<BR>&nbsp;* @flags:&nbsp;RADIX_TREE_ITER_*, should be constant<BR>&nbsp;* Returns:&nbsp;pointer to next slot, or NULL if there no more left<BR>&nbsp;*<BR>&nbsp;* This function updates @iter-&gt;index in the case of a successful lookup.<BR>&nbsp;* For tagged lookup it also eats @iter-&gt;tags.<BR>&nbsp;*/<BR>static __always_inline void **<BR>radix_tree_next_slot(void **slot, struct radix_tree_iter *iter, unsigned flags)<BR>{<BR>&nbsp;if (flags &amp; RADIX_TREE_ITER_TAGGED) {<BR>&nbsp;&nbsp;iter-&gt;tags &gt;&gt;= 1;<BR>&nbsp;&nbsp;if (likely(iter-&gt;tags &amp; 1ul)) {<BR>&nbsp;&nbsp;&nbsp;iter-&gt;index++;<BR>&nbsp;&nbsp;&nbsp;return slot + 1;<BR>&nbsp;&nbsp;}<BR>&nbsp;&nbsp;if (!(flags &amp; RADIX_TREE_ITER_CONTIG) &amp;&amp; likely(iter-&gt;tags)) {<BR>&nbsp;&nbsp;&nbsp;unsigned offset = __ffs(iter-&gt;tags);</P>
<P>&nbsp;&nbsp;&nbsp;iter-&gt;tags &gt;&gt;= offset;<BR>&nbsp;&nbsp;&nbsp;iter-&gt;index += offset + 1;<BR>&nbsp;&nbsp;&nbsp;return slot + offset + 1;<BR>&nbsp;&nbsp;}<BR>&nbsp;} else {<BR>&nbsp;&nbsp;unsigned size = radix_tree_chunk_size(iter) - 1;</P>
<P>&nbsp;&nbsp;while (size--) {<BR>&nbsp;&nbsp;&nbsp;slot++;<BR>&nbsp;&nbsp;&nbsp;iter-&gt;index++;<BR>&nbsp;&nbsp;&nbsp;if (likely(*slot))<BR>&nbsp;&nbsp;&nbsp;&nbsp;return slot;<BR>&nbsp;&nbsp;&nbsp;if (flags &amp; RADIX_TREE_ITER_CONTIG) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;/* forbid switching to the next chunk */<BR>&nbsp;&nbsp;&nbsp;&nbsp;iter-&gt;next_index = 0;<BR>&nbsp;&nbsp;&nbsp;&nbsp;break;<BR>&nbsp;&nbsp;&nbsp;}<BR>&nbsp;&nbsp;}<BR>&nbsp;}<BR>&nbsp;return NULL;<BR>}</P>
<P>/**<BR>&nbsp;* radix_tree_for_each_chunk - iterate over chunks<BR>&nbsp;*<BR>&nbsp;* @slot:&nbsp;the void** variable for pointer to chunk first slot<BR>&nbsp;* @root:&nbsp;the struct radix_tree_root pointer<BR>&nbsp;* @iter:&nbsp;the struct radix_tree_iter pointer<BR>&nbsp;* @start:&nbsp;iteration starting index<BR>&nbsp;* @flags:&nbsp;RADIX_TREE_ITER_* and tag index<BR>&nbsp;*<BR>&nbsp;* Locks can be released and reacquired between iterations.<BR>&nbsp;*/<BR>#define radix_tree_for_each_chunk(slot, root, iter, start, flags)&nbsp;\<BR>&nbsp;for (slot = radix_tree_iter_init(iter, start) ;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (slot = radix_tree_next_chunk(root, iter, flags)) ;)</P>
<P>/**<BR>&nbsp;* radix_tree_for_each_chunk_slot - iterate over slots in one chunk<BR>&nbsp;*<BR>&nbsp;* @slot:&nbsp;the void** variable, at the beginning points to chunk first slot<BR>&nbsp;* @iter:&nbsp;the struct radix_tree_iter pointer<BR>&nbsp;* @flags:&nbsp;RADIX_TREE_ITER_*, should be constant<BR>&nbsp;*<BR>&nbsp;* This macro is designed to be nested inside radix_tree_for_each_chunk().<BR>&nbsp;* @slot points to the radix tree slot, @iter-&gt;index contains its index.<BR>&nbsp;*/<BR>#define radix_tree_for_each_chunk_slot(slot, iter, flags)&nbsp;&nbsp;\<BR>&nbsp;for (; slot ; slot = radix_tree_next_slot(slot, iter, flags))</P>
<P>/**<BR>&nbsp;* radix_tree_for_each_slot - iterate over non-empty slots<BR>&nbsp;*<BR>&nbsp;* @slot:&nbsp;the void** variable for pointer to slot<BR>&nbsp;* @root:&nbsp;the struct radix_tree_root pointer<BR>&nbsp;* @iter:&nbsp;the struct radix_tree_iter pointer<BR>&nbsp;* @start:&nbsp;iteration starting index<BR>&nbsp;*<BR>&nbsp;* @slot points to radix tree slot, @iter-&gt;index contains its index.<BR>&nbsp;*/<BR>#define radix_tree_for_each_slot(slot, root, iter, start)&nbsp;&nbsp;\<BR>&nbsp;for (slot = radix_tree_iter_init(iter, start) ;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; slot || (slot = radix_tree_next_chunk(root, iter, 0)) ;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; slot = radix_tree_next_slot(slot, iter, 0))</P>
<P>/**<BR>&nbsp;* radix_tree_for_each_contig - iterate over contiguous slots<BR>&nbsp;*<BR>&nbsp;* @slot:&nbsp;the void** variable for pointer to slot<BR>&nbsp;* @root:&nbsp;the struct radix_tree_root pointer<BR>&nbsp;* @iter:&nbsp;the struct radix_tree_iter pointer<BR>&nbsp;* @start:&nbsp;iteration starting index<BR>&nbsp;*<BR>&nbsp;* @slot points to radix tree slot, @iter-&gt;index contains its index.<BR>&nbsp;*/<BR>#define radix_tree_for_each_contig(slot, root, iter, start)&nbsp;&nbsp;\<BR>&nbsp;for (slot = radix_tree_iter_init(iter, start) ;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; slot || (slot = radix_tree_next_chunk(root, iter,&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;RADIX_TREE_ITER_CONTIG)) ;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; slot = radix_tree_next_slot(slot, iter,&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;RADIX_TREE_ITER_CONTIG))</P>
<P>/**<BR>&nbsp;* radix_tree_for_each_tagged - iterate over tagged slots<BR>&nbsp;*<BR>&nbsp;* @slot:&nbsp;the void** variable for pointer to slot<BR>&nbsp;* @root:&nbsp;the struct radix_tree_root pointer<BR>&nbsp;* @iter:&nbsp;the struct radix_tree_iter pointer<BR>&nbsp;* @start:&nbsp;iteration starting index<BR>&nbsp;* @tag:&nbsp;tag index<BR>&nbsp;*<BR>&nbsp;* @slot points to radix tree slot, @iter-&gt;index contains its index.<BR>&nbsp;*/<BR>#define radix_tree_for_each_tagged(slot, root, iter, start, tag)&nbsp;\<BR>&nbsp;for (slot = radix_tree_iter_init(iter, start) ;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; slot || (slot = radix_tree_next_chunk(root, iter,&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RADIX_TREE_ITER_TAGGED | tag)) ;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; slot = radix_tree_next_slot(slot, iter,&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;RADIX_TREE_ITER_TAGGED))</P>
<P>#endif /* _LINUX_RADIX_TREE_H */