include/linux/mutex.h 
<P></P>
<P>/*<BR>&nbsp;* Mutexes: blocking mutual exclusion locks<BR>&nbsp;*<BR>&nbsp;* started by Ingo Molnar:<BR>&nbsp;*<BR>&nbsp;*&nbsp; Copyright (C) 2004, 2005, 2006 Red Hat, Inc., Ingo Molnar &lt;<A href="mailto:mingo@redhat.com">mingo@redhat.com</A>&gt;<BR>&nbsp;*<BR>&nbsp;* This file contains the main data structure and API definitions.<BR>&nbsp;*/<BR>#ifndef __LINUX_MUTEX_H<BR>#define __LINUX_MUTEX_H</P>
<P></P>
<P>#include &lt;asm/current.h&gt;<BR>#include &lt;linux/list.h&gt;<BR>#include &lt;linux/spinlock_types.h&gt;<BR>#include &lt;linux/linkage.h&gt;<BR>#include &lt;linux/lockdep.h&gt;<BR>#include &lt;linux/atomic.h&gt;<BR>#include &lt;asm/processor.h&gt;<BR>#include &lt;linux/osq_lock.h&gt;</P>
<P><FONT class=extract>/*<BR>&nbsp;* Simple, straightforward mutexes with strict semantics:<BR>&nbsp;*<BR>&nbsp;* - only one task can hold the mutex at a time<BR>&nbsp;* - only the owner can unlock the mutex<BR>&nbsp;* - multiple unlocks are not permitted<BR>&nbsp;* - recursive locking is not permitted<BR>&nbsp;* - a mutex object must be initialized via the API<BR>&nbsp;* - a mutex object must not be initialized via memset or copying<BR>&nbsp;* - task may not exit with mutex held<BR>&nbsp;* - memory areas where held locks reside must not be freed<BR>&nbsp;* - held mutexes must not be reinitialized<BR>&nbsp;* - mutexes may not be used in hardware or software interrupt<BR>&nbsp;*&nbsp;&nbsp; contexts such as tasklets and timers<BR>&nbsp;*<BR>&nbsp;* These semantics are fully enforced when DEBUG_MUTEXES is<BR>&nbsp;* enabled. Furthermore, besides enforcing the above rules, the mutex<BR>&nbsp;* debugging code also implements a number of additional features<BR>&nbsp;* that make lock debugging easier and faster:<BR>&nbsp;*<BR>&nbsp;* - uses symbolic names of mutexes, whenever they are printed in debug output<BR>&nbsp;* - point-of-acquire tracking, symbolic lookup of function names<BR>&nbsp;* - list of all locks held in the system, printout of them<BR>&nbsp;* - owner tracking<BR>&nbsp;* - detects self-recursing locks and prints out all relevant info<BR>&nbsp;* - detects multi-task circular deadlocks and prints out all affected<BR>&nbsp;*&nbsp;&nbsp; locks and tasks (and only those tasks)<BR>&nbsp;*/<BR>struct mutex {<BR>&nbsp;/* 1: unlocked, 0: locked, negative: locked, possible waiters */<BR>&nbsp;atomic_t&nbsp;&nbsp;count;<BR>&nbsp;spinlock_t&nbsp;&nbsp;wait_lock;<BR>&nbsp;struct list_head&nbsp;wait_list;<BR>#if defined(CONFIG_DEBUG_MUTEXES) || defined(CONFIG_MUTEX_SPIN_ON_OWNER)<BR>&nbsp;struct task_struct&nbsp;*owner;<BR>#endif<BR>#ifdef CONFIG_MUTEX_SPIN_ON_OWNER<BR>&nbsp;struct optimistic_spin_queue osq; /* Spinner MCS lock */<BR>#endif<BR>#ifdef CONFIG_DEBUG_MUTEXES<BR>&nbsp;void&nbsp;&nbsp;&nbsp;*magic;<BR>#endif<BR>#ifdef CONFIG_DEBUG_LOCK_ALLOC<BR>&nbsp;struct lockdep_map&nbsp;dep_map;<BR>#endif<BR>};</FONT></P>
<P>/*<BR>&nbsp;* This is the control structure for tasks blocked on mutex,<BR>&nbsp;* which resides on the blocked task's kernel stack:<BR>&nbsp;*/<BR>struct mutex_waiter {<BR>&nbsp;struct list_head&nbsp;list;<BR>&nbsp;struct task_struct&nbsp;*task;<BR>#ifdef CONFIG_DEBUG_MUTEXES<BR>&nbsp;void&nbsp;&nbsp;&nbsp;*magic;<BR>#endif<BR>};</P>
<P>#ifdef CONFIG_DEBUG_MUTEXES<BR># include &lt;linux/mutex-debug.h&gt;<BR>#else<BR># define __DEBUG_MUTEX_INITIALIZER(lockname)<BR>/**<BR>&nbsp;* mutex_init - initialize the mutex<BR>&nbsp;* @mutex: the mutex to be initialized<BR>&nbsp;*<BR>&nbsp;* Initialize the mutex to unlocked state.<BR>&nbsp;*<BR>&nbsp;* It is not allowed to initialize an already locked mutex.<BR>&nbsp;*/<BR># define mutex_init(mutex) \<BR>do {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;static struct lock_class_key __key;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;__mutex_init((mutex), #mutex, &amp;__key);&nbsp;&nbsp;\<BR>} while (0)<BR>static inline void mutex_destroy(struct mutex *lock) {}<BR>#endif</P>
<P>#ifdef CONFIG_DEBUG_LOCK_ALLOC<BR># define __DEP_MAP_MUTEX_INITIALIZER(lockname) \<BR>&nbsp;&nbsp;, .dep_map = { .name = #lockname }<BR>#else<BR># define __DEP_MAP_MUTEX_INITIALIZER(lockname)<BR>#endif</P>
<P>#define __MUTEX_INITIALIZER(lockname) \<BR>&nbsp;&nbsp;{ .count = ATOMIC_INIT(1) \<BR>&nbsp;&nbsp;, .wait_lock = __SPIN_LOCK_UNLOCKED(lockname.wait_lock) \<BR>&nbsp;&nbsp;, .wait_list = LIST_HEAD_INIT(lockname.wait_list) \<BR>&nbsp;&nbsp;__DEBUG_MUTEX_INITIALIZER(lockname) \<BR>&nbsp;&nbsp;__DEP_MAP_MUTEX_INITIALIZER(lockname) }</P>
<P>#define DEFINE_MUTEX(mutexname) \<BR>&nbsp;struct mutex mutexname = __MUTEX_INITIALIZER(mutexname)</P>
<P>extern void __mutex_init(struct mutex *lock, const char *name,<BR>&nbsp;&nbsp;&nbsp; struct lock_class_key *key);</P>
<P>/**<BR>&nbsp;* mutex_is_locked - is the mutex locked<BR>&nbsp;* @lock: the mutex to be queried<BR>&nbsp;*<BR>&nbsp;* Returns 1 if the mutex is locked, 0 if unlocked.<BR>&nbsp;*/<BR>static inline int mutex_is_locked(struct mutex *lock)<BR>{<BR>&nbsp;return atomic_read(&amp;lock-&gt;count) != 1;<BR>}</P>
<P>/*<BR>&nbsp;* See kernel/locking/mutex.c for detailed documentation of these APIs.<BR>&nbsp;* Also see Documentation/locking/mutex-design.txt.<BR>&nbsp;*/<BR>#ifdef CONFIG_DEBUG_LOCK_ALLOC<BR>extern void mutex_lock_nested(struct mutex *lock, unsigned int subclass);<BR>extern void _mutex_lock_nest_lock(struct mutex *lock, struct lockdep_map *nest_lock);</P>
<P>extern int __must_check mutex_lock_interruptible_nested(struct mutex *lock,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;unsigned int subclass);<BR>extern int __must_check mutex_lock_killable_nested(struct mutex *lock,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;unsigned int subclass);</P>
<P>#define mutex_lock(lock) mutex_lock_nested(lock, 0)<BR>#define mutex_lock_interruptible(lock) mutex_lock_interruptible_nested(lock, 0)<BR>#define mutex_lock_killable(lock) mutex_lock_killable_nested(lock, 0)</P>
<P>#define mutex_lock_nest_lock(lock, nest_lock)&nbsp;&nbsp;&nbsp;&nbsp;\<BR>do {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;typecheck(struct lockdep_map *, &amp;(nest_lock)-&gt;dep_map);&nbsp;\<BR>&nbsp;_mutex_lock_nest_lock(lock, &amp;(nest_lock)-&gt;dep_map);&nbsp;&nbsp;\<BR>} while (0)</P>
<P>#else<BR>extern void mutex_lock(struct mutex *lock);<BR>extern int __must_check mutex_lock_interruptible(struct mutex *lock);<BR>extern int __must_check mutex_lock_killable(struct mutex *lock);</P>
<P># define mutex_lock_nested(lock, subclass) mutex_lock(lock)<BR># define mutex_lock_interruptible_nested(lock, subclass) mutex_lock_interruptible(lock)<BR># define mutex_lock_killable_nested(lock, subclass) mutex_lock_killable(lock)<BR># define mutex_lock_nest_lock(lock, nest_lock) mutex_lock(lock)<BR>#endif</P>
<P>/*<BR>&nbsp;* NOTE: mutex_trylock() follows the spin_trylock() convention,<BR>&nbsp;*&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; not the down_trylock() convention!<BR>&nbsp;*<BR>&nbsp;* Returns 1 if the mutex has been acquired successfully, and 0 on contention.<BR>&nbsp;*/<BR>extern int mutex_trylock(struct mutex *lock);<BR>extern void mutex_unlock(struct mutex *lock);</P>
<P>extern int atomic_dec_and_mutex_lock(atomic_t *cnt, struct mutex *lock);</P>
<P>#endif /* __LINUX_MUTEX_H */