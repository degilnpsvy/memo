include/linux/bitops.h
<P></P>
<P>#ifndef _LINUX_BITOPS_H<BR>#define _LINUX_BITOPS_H<BR>#include &lt;asm/types.h&gt;</P>
<P></P>
<P>#ifdef&nbsp;__KERNEL__<BR>#define BIT(nr)&nbsp;&nbsp;&nbsp;(1UL &lt;&lt; (nr))<BR>#define BIT_ULL(nr)&nbsp;&nbsp;(1ULL &lt;&lt; (nr))<BR>#define BIT_MASK(nr)&nbsp;&nbsp;(1UL &lt;&lt; ((nr) % BITS_PER_LONG))<BR>#define BIT_WORD(nr)&nbsp;&nbsp;((nr) / BITS_PER_LONG)<BR>#define BIT_ULL_MASK(nr)&nbsp;(1ULL &lt;&lt; ((nr) % BITS_PER_LONG_LONG))<BR>#define BIT_ULL_WORD(nr)&nbsp;((nr) / BITS_PER_LONG_LONG)<BR>#define BITS_PER_BYTE&nbsp;&nbsp;8<BR>#define BITS_TO_LONGS(nr)&nbsp;DIV_ROUND_UP(nr, BITS_PER_BYTE * sizeof(long))<BR>#endif</P>
<P>/*<BR>&nbsp;* Create a contiguous bitmask starting at bit position @l and ending at<BR>&nbsp;* position @h. For example<BR>&nbsp;* GENMASK_ULL(39, 21) gives us the 64bit vector 0x000000ffffe00000.<BR>&nbsp;*/<BR>#define GENMASK(h, l) \<BR>&nbsp;(((~0UL) &lt;&lt; (l)) &amp; (~0UL &gt;&gt; (BITS_PER_LONG - 1 - (h))))</P>
<P>#define GENMASK_ULL(h, l) \<BR>&nbsp;(((~0ULL) &lt;&lt; (l)) &amp; (~0ULL &gt;&gt; (BITS_PER_LONG_LONG - 1 - (h))))</P>
<P>extern unsigned int __sw_hweight8(unsigned int w);<BR>extern unsigned int __sw_hweight16(unsigned int w);<BR>extern unsigned int __sw_hweight32(unsigned int w);<BR>extern unsigned long __sw_hweight64(__u64 w);</P>
<P>/*<BR>&nbsp;* Include this here because some architectures need generic_ffs/fls in<BR>&nbsp;* scope<BR>&nbsp;*/<BR>#include &lt;asm/bitops.h&gt;</P>
<P>#define for_each_set_bit(bit, addr, size) \<BR>&nbsp;for ((bit) = find_first_bit((addr), (size));&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (bit) &lt; (size);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (bit) = find_next_bit((addr), (size), (bit) + 1))</P>
<P>/* same as for_each_set_bit() but use bit as value to start with */<BR>#define for_each_set_bit_from(bit, addr, size) \<BR>&nbsp;for ((bit) = find_next_bit((addr), (size), (bit));&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (bit) &lt; (size);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (bit) = find_next_bit((addr), (size), (bit) + 1))</P>
<P>#define for_each_clear_bit(bit, addr, size) \<BR>&nbsp;for ((bit) = find_first_zero_bit((addr), (size));&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (bit) &lt; (size);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (bit) = find_next_zero_bit((addr), (size), (bit) + 1))</P>
<P>/* same as for_each_clear_bit() but use bit as value to start with */<BR>#define for_each_clear_bit_from(bit, addr, size) \<BR>&nbsp;for ((bit) = find_next_zero_bit((addr), (size), (bit));&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (bit) &lt; (size);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (bit) = find_next_zero_bit((addr), (size), (bit) + 1))</P>
<P>static __inline__ int get_bitmask_order(unsigned int count)<BR>{<BR>&nbsp;int order;</P>
<P>&nbsp;order = fls(count);<BR>&nbsp;return order;&nbsp;/* We could be slightly more clever with -1 here... */<BR>}</P>
<P>static __inline__ int get_count_order(unsigned int count)<BR>{<BR>&nbsp;int order;</P>
<P>&nbsp;order = fls(count) - 1;<BR>&nbsp;if (count &amp; (count - 1))<BR>&nbsp;&nbsp;order++;<BR>&nbsp;return order;<BR>}</P>
<P>static inline unsigned long hweight_long(unsigned long w)<BR>{<BR>&nbsp;return sizeof(w) == 4 ? hweight32(w) : hweight64(w);<BR>}</P>
<P>/**<BR>&nbsp;* rol64 - rotate a 64-bit value left<BR>&nbsp;* @word: value to rotate<BR>&nbsp;* @shift: bits to roll<BR>&nbsp;*/<BR>static inline __u64 rol64(__u64 word, unsigned int shift)<BR>{<BR>&nbsp;return (word &lt;&lt; shift) | (word &gt;&gt; (64 - shift));<BR>}</P>
<P>/**<BR>&nbsp;* ror64 - rotate a 64-bit value right<BR>&nbsp;* @word: value to rotate<BR>&nbsp;* @shift: bits to roll<BR>&nbsp;*/<BR>static inline __u64 ror64(__u64 word, unsigned int shift)<BR>{<BR>&nbsp;return (word &gt;&gt; shift) | (word &lt;&lt; (64 - shift));<BR>}</P>
<P>/**<BR>&nbsp;* rol32 - rotate a 32-bit value left<BR>&nbsp;* @word: value to rotate<BR>&nbsp;* @shift: bits to roll<BR>&nbsp;*/<BR>static inline __u32 rol32(__u32 word, unsigned int shift)<BR>{<BR>&nbsp;return (word &lt;&lt; shift) | (word &gt;&gt; (32 - shift));<BR>}</P>
<P>/**<BR>&nbsp;* ror32 - rotate a 32-bit value right<BR>&nbsp;* @word: value to rotate<BR>&nbsp;* @shift: bits to roll<BR>&nbsp;*/<BR>static inline __u32 ror32(__u32 word, unsigned int shift)<BR>{<BR>&nbsp;return (word &gt;&gt; shift) | (word &lt;&lt; (32 - shift));<BR>}</P>
<P>/**<BR>&nbsp;* rol16 - rotate a 16-bit value left<BR>&nbsp;* @word: value to rotate<BR>&nbsp;* @shift: bits to roll<BR>&nbsp;*/<BR>static inline __u16 rol16(__u16 word, unsigned int shift)<BR>{<BR>&nbsp;return (word &lt;&lt; shift) | (word &gt;&gt; (16 - shift));<BR>}</P>
<P>/**<BR>&nbsp;* ror16 - rotate a 16-bit value right<BR>&nbsp;* @word: value to rotate<BR>&nbsp;* @shift: bits to roll<BR>&nbsp;*/<BR>static inline __u16 ror16(__u16 word, unsigned int shift)<BR>{<BR>&nbsp;return (word &gt;&gt; shift) | (word &lt;&lt; (16 - shift));<BR>}</P>
<P>/**<BR>&nbsp;* rol8 - rotate an 8-bit value left<BR>&nbsp;* @word: value to rotate<BR>&nbsp;* @shift: bits to roll<BR>&nbsp;*/<BR>static inline __u8 rol8(__u8 word, unsigned int shift)<BR>{<BR>&nbsp;return (word &lt;&lt; shift) | (word &gt;&gt; (8 - shift));<BR>}</P>
<P>/**<BR>&nbsp;* ror8 - rotate an 8-bit value right<BR>&nbsp;* @word: value to rotate<BR>&nbsp;* @shift: bits to roll<BR>&nbsp;*/<BR>static inline __u8 ror8(__u8 word, unsigned int shift)<BR>{<BR>&nbsp;return (word &gt;&gt; shift) | (word &lt;&lt; (8 - shift));<BR>}</P>
<P>/**<BR>&nbsp;* sign_extend32 - sign extend a 32-bit value using specified bit as sign-bit<BR>&nbsp;* @value: value to sign extend<BR>&nbsp;* @index: 0 based bit index (0&lt;=index&lt;32) to sign bit<BR>&nbsp;*/<BR>static inline __s32 sign_extend32(__u32 value, int index)<BR>{<BR>&nbsp;__u8 shift = 31 - index;<BR>&nbsp;return (__s32)(value &lt;&lt; shift) &gt;&gt; shift;<BR>}</P>
<P>static inline unsigned fls_long(unsigned long l)<BR>{<BR>&nbsp;if (sizeof(l) == 4)<BR>&nbsp;&nbsp;return fls(l);<BR>&nbsp;return fls64(l);<BR>}</P>
<P>/**<BR>&nbsp;* __ffs64 - find first set bit in a 64 bit word<BR>&nbsp;* @word: The 64 bit word<BR>&nbsp;*<BR>&nbsp;* On 64 bit arches this is a synomyn for __ffs<BR>&nbsp;* The result is not defined if no bits are set, so check that @word<BR>&nbsp;* is non-zero before calling this.<BR>&nbsp;*/<BR>static inline unsigned long __ffs64(u64 word)<BR>{<BR>#if BITS_PER_LONG == 32<BR>&nbsp;if (((u32)word) == 0UL)<BR>&nbsp;&nbsp;return __ffs((u32)(word &gt;&gt; 32)) + 32;<BR>#elif BITS_PER_LONG != 64<BR>#error BITS_PER_LONG not 32 or 64<BR>#endif<BR>&nbsp;return __ffs((unsigned long)word);<BR>}</P>
<P>#ifdef __KERNEL__</P>
<P>#ifndef set_mask_bits<BR>#define set_mask_bits(ptr, _mask, _bits)&nbsp;\<BR>({&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;const typeof(*ptr) mask = (_mask), bits = (_bits);&nbsp;\<BR>&nbsp;typeof(*ptr) old, new;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;do {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;old = ACCESS_ONCE(*ptr);&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;new = (old &amp; ~mask) | bits;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;} while (cmpxchg(ptr, old, new) != old);&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;new;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>})<BR>#endif</P>
<P>#ifndef find_last_bit<BR>/**<BR>&nbsp;* find_last_bit - find the last set bit in a memory region<BR>&nbsp;* @addr: The address to start the search at<BR>&nbsp;* @size: The number of bits to search<BR>&nbsp;*<BR>&nbsp;* Returns the bit number of the last set bit, or size.<BR>&nbsp;*/<BR>extern unsigned long find_last_bit(const unsigned long *addr,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; unsigned long size);<BR>#endif</P>
<P>#endif /* __KERNEL__ */<BR>#endif