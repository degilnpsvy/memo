Each worker-pool bound to an actual CPU implements concurrency<BR>management by hooking into the scheduler.&nbsp; The worker-pool is notified<BR>whenever an active worker wakes up or sleeps and keeps track of the<BR>number of the currently runnable workers.&nbsp; Generally, work items are<BR>not expected to hog a CPU and consume many cycles.&nbsp; That means<BR>maintaining just enough concurrency to prevent work processing from<BR>stalling should be optimal.&nbsp; As long as there are one or more runnable<BR>workers on the CPU, the worker-pool doesn't start execution of a new<BR>work, but, when the last running worker goes to sleep, it immediately<BR>schedules a new worker so that the CPU doesn't sit idle while there<BR>are pending work items.&nbsp; This allows using a minimal number of workers<BR>without losing execution bandwidth.
<P></P>
<P>Keeping idle workers around doesn't cost other than the memory space<BR>for kthreads, so cmwq holds onto idle ones for a while before killing<BR>them.</P>
<P>For unbound workqueues, the number of backing pools is dynamic.<BR>Unbound workqueue can be assigned custom attributes using<BR>apply_workqueue_attrs() and workqueue will automatically create<BR>backing worker pools matching the attributes.&nbsp; The responsibility of<BR>regulating concurrency level is on the users.&nbsp; There is also a flag to<BR>mark a bound wq to ignore the concurrency management.&nbsp; Please refer to<BR>the API section for details.