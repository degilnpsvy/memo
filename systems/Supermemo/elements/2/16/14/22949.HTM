# Documentation/preempt-locking.txt
<P></P>
<P>&nbsp;&nbsp;&nbsp; Proper Locking Under a Preemptible Kernel:<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Keeping Kernel Code Preempt-Safe<BR>&nbsp;&nbsp;&nbsp; Robert Love &lt;<A href="mailto:rml@tech9.net">rml@tech9.net</A>&gt;<BR>&nbsp;&nbsp;&nbsp;&nbsp; Last Updated: 28 Aug 2002</P>
<P></P>
<P><BR>INTRODUCTION</P>
<P><BR>A preemptible kernel creates new locking issues.&nbsp; The issues are the same as<BR>those under SMP: concurrency and reentrancy.&nbsp; Thankfully, the Linux preemptible<BR>kernel model leverages existing SMP locking mechanisms.&nbsp; Thus, the kernel<BR>requires explicit additional locking for very few additional situations.</P>
<P>This document is for all kernel hackers.&nbsp; Developing code in the kernel<BR>requires protecting these situations.<BR>&nbsp;</P>
<P>RULE #1: Per-CPU data structures need explicit protection</P>
<P><BR>Two similar problems arise. An example code snippet:</P>
<P>&nbsp;struct this_needs_locking tux[NR_CPUS];<BR>&nbsp;tux[smp_processor_id()] = some_value;<BR>&nbsp;/* task is preempted here... */<BR>&nbsp;something = tux[smp_processor_id()];</P>
<P>First, since the data is per-CPU, it may not have explicit SMP locking, but<BR>require it otherwise.&nbsp; Second, when a preempted task is finally rescheduled,<BR>the previous value of smp_processor_id may not equal the current.&nbsp; You must<BR>protect these situations by disabling preemption around them.</P>
<P>You can also use put_cpu() and get_cpu(), which will disable preemption.</P>
<P><BR>RULE #2: CPU state must be protected.</P>
<P><BR>Under preemption, the state of the CPU must be protected.&nbsp; This is arch-<BR>dependent, but includes CPU structures and state not preserved over a context<BR>switch.&nbsp; For example, on x86, entering and exiting FPU mode is now a critical<BR>section that must occur while preemption is disabled.&nbsp; Think what would happen<BR>if the kernel is executing a floating-point instruction and is then preempted.<BR>Remember, the kernel does not save FPU state except for user tasks.&nbsp; Therefore,<BR>upon preemption, the FPU registers will be sold to the lowest bidder.&nbsp; Thus,<BR>preemption must be disabled around such regions.</P>
<P>Note, some FPU functions are already explicitly preempt safe.&nbsp; For example,<BR>kernel_fpu_begin and kernel_fpu_end will disable and enable preemption.<BR>However, math_state_restore must be called with preemption disabled.</P>
<P><BR>RULE #3: Lock acquire and release must be performed by same task</P>
<P><BR>A lock acquired in one task must be released by the same task.&nbsp; This<BR>means you can't do oddball things like acquire a lock and go off to<BR>play while another task releases it.&nbsp; If you want to do something<BR>like this, acquire and release the task in the same code path and<BR>have the caller wait on an event by the other task.</P>
<P><BR>SOLUTION</P>
<P><BR>Data protection under preemption is achieved by disabling preemption for the<BR>duration of the critical region.</P>
<P>preempt_enable()&nbsp;&nbsp;decrement the preempt counter<BR>preempt_disable()&nbsp;&nbsp;increment the preempt counter<BR>preempt_enable_no_resched()&nbsp;decrement, but do not immediately preempt<BR>preempt_check_resched()&nbsp;&nbsp;if needed, reschedule<BR>preempt_count()&nbsp;&nbsp;&nbsp;return the preempt counter</P>
<P>The functions are nestable.&nbsp; In other words, you can call preempt_disable<BR>n-times in a code path, and preemption will not be reenabled until the n-th<BR>call to preempt_enable.&nbsp; The preempt statements define to nothing if<BR>preemption is not enabled.</P>
<P>Note that you do not need to explicitly prevent preemption if you are holding<BR>any locks or interrupts are disabled, since preemption is implicitly disabled<BR>in those cases.</P>
<P>But keep in mind that 'irqs disabled' is a fundamentally unsafe way of<BR>disabling preemption - any spin_unlock() decreasing the preemption count<BR>to 0 might trigger a reschedule. A simple printk() might trigger a reschedule.<BR>So use this implicit preemption-disabling property only if you know that the<BR>affected codepath does not do any of this. Best policy is to use this only for<BR>small, atomic code that you wrote and which calls no complex functions.</P>
<P>Example:</P>
<P>&nbsp;cpucache_t *cc; /* this is per-CPU */<BR>&nbsp;preempt_disable();<BR>&nbsp;cc = cc_data(searchp);<BR>&nbsp;if (cc &amp;&amp; cc-&gt;avail) {<BR>&nbsp;&nbsp;__free_block(searchp, cc_entry(cc), cc-&gt;avail);<BR>&nbsp;&nbsp;cc-&gt;avail = 0;<BR>&nbsp;}<BR>&nbsp;preempt_enable();<BR>&nbsp;return 0;</P>
<P>Notice how the preemption statements must encompass every reference of the<BR>critical variables.&nbsp; Another example:</P>
<P>&nbsp;int buf[NR_CPUS];<BR>&nbsp;set_cpu_val(buf);<BR>&nbsp;if (buf[smp_processor_id()] == -1) printf(KERN_INFO "wee!\n");<BR>&nbsp;spin_lock(&amp;buf_lock);<BR>&nbsp;/* ... */</P>
<P>This code is not preempt-safe, but see how easily we can fix it by simply<BR>moving the spin_lock up two lines.</P>
<P><BR>PREVENTING PREEMPTION USING INTERRUPT DISABLING</P>
<P><BR>It is possible to prevent a preemption event using local_irq_disable and<BR>local_irq_save.&nbsp; Note, when doing so, you must be very careful to not cause<BR>an event that would set need_resched and result in a preemption check.&nbsp; When<BR>in doubt, rely on locking or explicit preemption disabling.</P>
<P>Note in 2.5 interrupt disabling is now only per-CPU (e.g. local).</P>
<P>An additional concern is proper usage of local_irq_disable and local_irq_save.<BR>These may be used to protect from preemption, however, on exit, if preemption<BR>may be enabled, a test to see if preemption is required should be done.&nbsp; If<BR>these are called from the spin_lock and read/write lock macros, the right thing<BR>is done.&nbsp; They may also be called within a spin-lock protected region, however,<BR>if they are ever called outside of this context, a test for preemption should<BR>be made. Do note that calls from interrupt context or bottom half/ tasklets<BR>are also protected by preemption locks and so may use the versions which do<BR>not check preemption.