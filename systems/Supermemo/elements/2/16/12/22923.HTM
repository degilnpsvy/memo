# Documentation/scheduler/sched-rt-group.txt
<P></P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;Real-Time group scheduling<BR>&nbsp;&nbsp;&nbsp;&nbsp;--------------------------</P>
<P></P>
<P>CONTENTS<BR>========</P>
<P>0. WARNING<BR>1. Overview<BR>&nbsp; 1.1 The problem<BR>&nbsp; 1.2 The solution<BR>2. The interface<BR>&nbsp; 2.1 System-wide settings<BR>&nbsp; 2.2 Default behaviour<BR>&nbsp; 2.3 Basis for grouping tasks<BR>3. Future plans</P>
<P><BR>0. WARNING<BR>==========</P>
<P>&nbsp;Fiddling with these settings can result in an unstable system, the knobs are<BR>&nbsp;root only and assumes root knows what he is doing.</P>
<P>Most notable:</P>
<P>&nbsp;* very small values in sched_rt_period_us can result in an unstable<BR>&nbsp;&nbsp; system when the period is smaller than either the available hrtimer<BR>&nbsp;&nbsp; resolution, or the time it takes to handle the budget refresh itself.</P>
<P>&nbsp;* very small values in sched_rt_runtime_us can result in an unstable<BR>&nbsp;&nbsp; system when the runtime is so small the system has difficulty making<BR>&nbsp;&nbsp; forward progress (NOTE: the migration thread and kstopmachine both<BR>&nbsp;&nbsp; are real-time processes).</P>
<P>1. Overview<BR>===========</P>
<P><BR>1.1 The problem<BR>---------------</P>
<P>Realtime scheduling is all about determinism, a group has to be able to rely on<BR>the amount of bandwidth (eg. CPU time) being constant. In order to schedule<BR>multiple groups of realtime tasks, each group must be assigned a fixed portion<BR>of the CPU time available.&nbsp; Without a minimum guarantee a realtime group can<BR>obviously fall short. A fuzzy upper limit is of no use since it cannot be<BR>relied upon. Which leaves us with just the single fixed portion.</P>
<P>1.2 The solution<BR>----------------</P>
<P>CPU time is divided by means of specifying how much time can be spent running<BR>in a given period. We allocate this "run time" for each realtime group which<BR>the other realtime groups will not be permitted to use.</P>
<P>Any time not allocated to a realtime group will be used to run normal priority<BR>tasks (SCHED_OTHER). Any allocated run time not used will also be picked up by<BR>SCHED_OTHER.</P>
<P>Let's consider an example: a frame fixed realtime renderer must deliver 25<BR>frames a second, which yields a period of 0.04s per frame. Now say it will also<BR>have to play some music and respond to input, leaving it with around 80% CPU<BR>time dedicated for the graphics. We can then give this group a run time of 0.8<BR>* 0.04s = 0.032s.</P>
<P>This way the graphics group will have a 0.04s period with a 0.032s run time<BR>limit. Now if the audio thread needs to refill the DMA buffer every 0.005s, but<BR>needs only about 3% CPU time to do so, it can do with a 0.03 * 0.005s =<BR>0.00015s. So this group can be scheduled with a period of 0.005s and a run time<BR>of 0.00015s.</P>
<P>The remaining CPU time will be used for user input and other tasks. Because<BR>realtime tasks have explicitly allocated the CPU time they need to perform<BR>their tasks, buffer underruns in the graphics or audio can be eliminated.</P>
<P>NOTE: the above example is not fully implemented yet. We still<BR>lack an EDF scheduler to make non-uniform periods usable.</P>
<P><BR>2. The Interface<BR>================</P>
<P><BR>2.1 System wide settings<BR>------------------------</P>
<P>The system wide settings are configured under the /proc virtual file system:</P>
<P>/proc/sys/kernel/sched_rt_period_us:<BR>&nbsp; The scheduling period that is equivalent to 100% CPU bandwidth</P>
<P>/proc/sys/kernel/sched_rt_runtime_us:<BR>&nbsp; A global limit on how much time realtime scheduling may use.&nbsp; Even without<BR>&nbsp; CONFIG_RT_GROUP_SCHED enabled, this will limit time reserved to realtime<BR>&nbsp; processes. With CONFIG_RT_GROUP_SCHED it signifies the total bandwidth<BR>&nbsp; available to all realtime groups.</P>
<P>&nbsp; * Time is specified in us because the interface is s32. This gives an<BR>&nbsp;&nbsp;&nbsp; operating range from 1us to about 35 minutes.<BR>&nbsp; * sched_rt_period_us takes values from 1 to INT_MAX.<BR>&nbsp; * sched_rt_runtime_us takes values from -1 to (INT_MAX - 1).<BR>&nbsp; * A run time of -1 specifies runtime == period, ie. no limit.</P>
<P><BR>2.2 Default behaviour<BR>---------------------</P>
<P>The default values for sched_rt_period_us (1000000 or 1s) and<BR>sched_rt_runtime_us (950000 or 0.95s).&nbsp; This gives 0.05s to be used by<BR>SCHED_OTHER (non-RT tasks). These defaults were chosen so that a run-away<BR>realtime tasks will not lock up the machine but leave a little time to recover<BR>it.&nbsp; By setting runtime to -1 you'd get the old behaviour back.</P>
<P>By default all bandwidth is assigned to the root group and new groups get the<BR>period from /proc/sys/kernel/sched_rt_period_us and a run time of 0. If you<BR>want to assign bandwidth to another group, reduce the root group's bandwidth<BR>and assign some or all of the difference to another group.</P>
<P>Realtime group scheduling means you have to assign a portion of total CPU<BR>bandwidth to the group before it will accept realtime tasks. Therefore you will<BR>not be able to run realtime tasks as any user other than root until you have<BR>done that, even if the user has the rights to run processes with realtime<BR>priority!</P>
<P><BR>2.3 Basis for grouping tasks<BR>----------------------------</P>
<P>Enabling CONFIG_RT_GROUP_SCHED lets you explicitly allocate real<BR>CPU bandwidth to task groups.</P>
<P>This uses the cgroup virtual file system and "&lt;cgroup&gt;/cpu.rt_runtime_us"<BR>to control the CPU time reserved for each control group.</P>
<P>For more information on working with control groups, you should read<BR>Documentation/cgroups/cgroups.txt as well.</P>
<P>Group settings are checked against the following limits in order to keep the<BR>configuration schedulable:</P>
<P>&nbsp;&nbsp; \Sum_{i} runtime_{i} / global_period &lt;= global_runtime / global_period</P>
<P>For now, this can be simplified to just the following (but see Future plans):</P>
<P>&nbsp;&nbsp; \Sum_{i} runtime_{i} &lt;= global_runtime</P>
<P><BR>3. Future plans<BR>===============</P>
<P>There is work in progress to make the scheduling period for each group<BR>("&lt;cgroup&gt;/cpu.rt_period_us") configurable as well.</P>
<P>The constraint on the period is that a subgroup must have a smaller or<BR>equal period to its parent. But realistically its not very useful _yet_<BR>as its prone to starvation without deadline scheduling.</P>
<P>Consider two sibling groups A and B; both have 50% bandwidth, but A's<BR>period is twice the length of B's.</P>
<P>* group A: period=100000us, runtime=10000us<BR>&nbsp;- this runs for 0.01s once every 0.1s</P>
<P>* group B: period= 50000us, runtime=10000us<BR>&nbsp;- this runs for 0.01s twice every 0.1s (or once every 0.05 sec).</P>
<P>This means that currently a while (1) loop in A will run for the full period of<BR>B and can starve B's tasks (assuming they are of lower priority) for a whole<BR>period.</P>
<P>The next project will be SCHED_EDF (Earliest Deadline First scheduling) to bring<BR>full deadline scheduling to the linux kernel. Deadline scheduling the above<BR>groups and treating end of the period as a deadline will ensure that they both<BR>get their allocated time.</P>
<P>Implementing SCHED_EDF might take a while to complete. Priority Inheritance is<BR>the biggest challenge as the current linux PI infrastructure is geared towards<BR>the limited static priority levels 0-99. With deadline scheduling you need to<BR>do deadline inheritance (since priority is inversely proportional to the<BR>deadline delta (deadline - now)).</P>
<P>This means the whole PI machinery will have to be reworked - and that is one of<BR>the most complex pieces of code we have.