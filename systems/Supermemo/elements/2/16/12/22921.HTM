# Documentation/scheduler/sched-domains.txt 
<P></P>
<P>Each CPU has a "base" scheduling domain (struct sched_domain). The domain<BR>hierarchy is built from these base domains via the -&gt;parent pointer. -&gt;parent<BR>MUST be NULL terminated, and domain structures should be per-CPU as they are<BR>locklessly updated.</P>
<P></P>
<P>Each scheduling domain spans a number of CPUs (stored in the -&gt;span field).<BR>A domain's span MUST be a superset of it child's span (this restriction could<BR>be relaxed if the need arises), and a base domain for CPU i MUST span at least<BR>i. The top domain for each CPU will generally span all CPUs in the system<BR>although strictly it doesn't have to, but this could lead to a case where some<BR>CPUs will never be given tasks to run unless the CPUs allowed mask is<BR>explicitly set. A sched domain's span means "balance process load among these<BR>CPUs".</P>
<P>Each scheduling domain must have one or more CPU groups (struct sched_group)<BR>which are organised as a circular one way linked list from the -&gt;groups<BR>pointer. The union of cpumasks of these groups MUST be the same as the<BR>domain's span. The intersection of cpumasks from any two of these groups<BR>MUST be the empty set. The group pointed to by the -&gt;groups pointer MUST<BR>contain the CPU to which the domain belongs. Groups may be shared among<BR>CPUs as they contain read only data after they have been set up.</P>
<P>Balancing within a sched domain occurs between groups. That is, each group<BR>is treated as one entity. The load of a group is defined as the sum of the<BR>load of each of its member CPUs, and only when the load of a group becomes<BR>out of balance are tasks moved between groups.</P>
<P>In kernel/sched.c, trigger_load_balance() is run periodically on each CPU<BR>through scheduler_tick(). It raises a softirq after the next regularly scheduled<BR>rebalancing event for the current runqueue has arrived. The actual load<BR>balancing workhorse, run_rebalance_domains()-&gt;rebalance_domains(), is then run<BR>in softirq context (SCHED_SOFTIRQ).</P>
<P>The latter function takes two arguments: the current CPU and whether it was idle<BR>at the time the scheduler_tick() happened and iterates over all sched domains<BR>our CPU is on, starting from its base domain and going up the -&gt;parent chain.<BR>While doing that, it checks to see if the current domain has exhausted its<BR>rebalance interval. If so, it runs load_balance() on that domain. It then checks<BR>the parent sched_domain (if it exists), and the parent of the parent and so<BR>forth.</P>
<P>Initially, load_balance() finds the busiest group in the current sched domain.<BR>If it succeeds, it looks for the busiest runqueue of all the CPUs' runqueues in<BR>that group. If it manages to find such a runqueue, it locks both our initial<BR>CPU's runqueue and the newly found busiest one and starts moving tasks from it<BR>to our runqueue. The exact number of tasks amounts to an imbalance previously<BR>computed while iterating over this sched domain's groups.</P>
<P>*** Implementing sched domains ***<BR>The "base" domain will "span" the first level of the hierarchy. In the case<BR>of SMT, you'll span all siblings of the physical CPU, with each group being<BR>a single virtual CPU.</P>
<P>In SMP, the parent of the base domain will span all physical CPUs in the<BR>node. Each group being a single physical CPU. Then with NUMA, the parent<BR>of the SMP domain will span the entire machine, with each group having the<BR>cpumask of a node. Or, you could do multi-level NUMA or Opteron, for example,<BR>might have just one domain covering its one NUMA level.</P>
<P>The implementor should read comments in include/linux/sched.h:<BR>struct sched_domain fields, SD_FLAG_*, SD_*_INIT to get an idea of<BR>the specifics and what to tune.</P>
<P>Architectures may retain the regular override the default SD_*_INIT flags<BR>while using the generic domain builder in kernel/sched.c if they wish to<BR>retain the traditional SMT-&gt;SMP-&gt;NUMA topology (or some subset of that). This<BR>can be done by #define'ing ARCH_HASH_SCHED_TUNE.</P>
<P>Alternatively, the architecture may completely override the generic domain<BR>builder by #define'ing ARCH_HASH_SCHED_DOMAIN, and exporting your<BR>arch_init_sched_domains function. This function will attach domains to all<BR>CPUs using cpu_attach_domain.</P>
<P>The sched-domains debugging infrastructure can be enabled by enabling<BR>CONFIG_SCHED_DEBUG. This enables an error checking parse of the sched domains<BR>which should catch most possible errors (described above). It also prints out<BR>the domain structure in a visual format.