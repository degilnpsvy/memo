# qemu:translate-all.c 
<P></P>
<P>/*<BR>&nbsp;*&nbsp; Host code generation<BR>&nbsp;*<BR>&nbsp;*&nbsp; Copyright (c) 2003 Fabrice Bellard<BR>&nbsp;*<BR>&nbsp;* This library is free software; you can redistribute it and/or<BR>&nbsp;* modify it under the terms of the GNU Lesser General Public<BR>&nbsp;* License as published by the Free Software Foundation; either<BR>&nbsp;* version 2 of the License, or (at your option) any later version.<BR>&nbsp;*<BR>&nbsp;* This library is distributed in the hope that it will be useful,<BR>&nbsp;* but WITHOUT ANY WARRANTY; without even the implied warranty of<BR>&nbsp;* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.&nbsp; See the GNU<BR>&nbsp;* Lesser General Public License for more details.<BR>&nbsp;*<BR>&nbsp;* You should have received a copy of the GNU Lesser General Public<BR>&nbsp;* License along with this library; if not, see &lt;<A href="http://www.gnu.org/licenses/">http://www.gnu.org/licenses/</A>&gt;.<BR>&nbsp;*/<BR>#ifdef _WIN32<BR>#include &lt;windows.h&gt;<BR>#else<BR>#include &lt;sys/mman.h&gt;<BR>#endif<BR>#include "qemu/osdep.h"</P>
<P></P>
<P><BR>#include "qemu-common.h"<BR>#define NO_CPU_IO_DEFS<BR>#include "cpu.h"<BR>#include "trace.h"<BR>#include "disas/disas.h"<BR>#include "tcg.h"<BR>#if defined(CONFIG_USER_ONLY)<BR>#include "qemu.h"<BR>#if defined(__FreeBSD__) || defined(__FreeBSD_kernel__)<BR>#include &lt;sys/param.h&gt;<BR>#if __FreeBSD_version &gt;= 700104<BR>#define HAVE_KINFO_GETVMMAP<BR>#define sigqueue sigqueue_freebsd&nbsp; /* avoid redefinition */<BR>#include &lt;sys/proc.h&gt;<BR>#include &lt;machine/profile.h&gt;<BR>#define _KERNEL<BR>#include &lt;sys/user.h&gt;<BR>#undef _KERNEL<BR>#undef sigqueue<BR>#include &lt;libutil.h&gt;<BR>#endif<BR>#endif<BR>#else<BR>#include "exec/address-spaces.h"<BR>#endif</P>
<P>#include "exec/cputlb.h"<BR>#include "exec/tb-hash.h"<BR>#include "translate-all.h"<BR>#include "qemu/bitmap.h"<BR>#include "qemu/timer.h"<BR>#include "exec/log.h"</P>
<P>//#define DEBUG_TB_INVALIDATE<BR>//#define DEBUG_FLUSH<BR>/* make various TB consistency checks */<BR>//#define DEBUG_TB_CHECK</P>
<P>#if !defined(CONFIG_USER_ONLY)<BR>/* TB consistency checks only implemented for usermode emulation.&nbsp; */<BR>#undef DEBUG_TB_CHECK<BR>#endif</P>
<P>#define SMC_BITMAP_USE_THRESHOLD 10</P>
<P><FONT class=extract>typedef struct PageDesc {<BR>&nbsp;&nbsp;&nbsp; /* list of TBs intersecting this ram page */<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *first_tb;<BR>&nbsp;&nbsp;&nbsp; /* in order to optimize self modifying code, we count the number<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; of lookups we do to a given page to use a bitmap */<BR>&nbsp;&nbsp;&nbsp; unsigned int code_write_count;<BR>&nbsp;&nbsp;&nbsp; unsigned long *code_bitmap;<BR>#if defined(CONFIG_USER_ONLY)<BR>&nbsp;&nbsp;&nbsp; unsigned long flags;<BR>#endif<BR>} PageDesc;</FONT></P>
<P>/* In system mode we want L1_MAP to be based on ram offsets,<BR>&nbsp;&nbsp; while in user mode we want it to be based on virtual addresses.&nbsp; */<BR>#if !defined(CONFIG_USER_ONLY)<BR>#if HOST_LONG_BITS &lt; TARGET_PHYS_ADDR_SPACE_BITS<BR># define L1_MAP_ADDR_SPACE_BITS&nbsp; HOST_LONG_BITS<BR>#else<BR># define L1_MAP_ADDR_SPACE_BITS&nbsp; TARGET_PHYS_ADDR_SPACE_BITS<BR>#endif<BR>#else<BR># define L1_MAP_ADDR_SPACE_BITS&nbsp; TARGET_VIRT_ADDR_SPACE_BITS<BR>#endif</P>
<P>/* Size of the L2 (and L3, etc) page tables.&nbsp; */<BR>#define V_L2_BITS 10<BR>#define V_L2_SIZE (1 &lt;&lt; V_L2_BITS)</P>
<P>/* The bits remaining after N lower levels of page tables.&nbsp; */<BR>#define V_L1_BITS_REM \<BR>&nbsp;&nbsp;&nbsp; ((L1_MAP_ADDR_SPACE_BITS - TARGET_PAGE_BITS) % V_L2_BITS)</P>
<P>#if V_L1_BITS_REM &lt; 4<BR>#define V_L1_BITS&nbsp; (V_L1_BITS_REM + V_L2_BITS)<BR>#else<BR>#define V_L1_BITS&nbsp; V_L1_BITS_REM<BR>#endif</P>
<P>#define V_L1_SIZE&nbsp; ((target_ulong)1 &lt;&lt; V_L1_BITS)</P>
<P>#define V_L1_SHIFT (L1_MAP_ADDR_SPACE_BITS - TARGET_PAGE_BITS - V_L1_BITS)</P>
<P><FONT class=extract>uintptr_t qemu_host_page_size;<BR>intptr_t qemu_host_page_mask;</FONT></P>
<P>/* The bottom level has pointers to PageDesc */<BR>static void *l1_map[V_L1_SIZE];</P>
<P><FONT class=extract>/* code generation context */<BR>TCGContext tcg_ctx;</FONT></P>
<P>/* translation block context */<BR>#ifdef CONFIG_USER_ONLY<BR>__thread int have_tb_lock;<BR>#endif</P>
<P>void tb_lock(void)<BR>{<BR>#ifdef CONFIG_USER_ONLY<BR>&nbsp;&nbsp;&nbsp; assert(!have_tb_lock);<BR>&nbsp;&nbsp;&nbsp; qemu_mutex_lock(&amp;tcg_ctx.tb_ctx.tb_lock);<BR>&nbsp;&nbsp;&nbsp; have_tb_lock++;<BR>#endif<BR>}</P>
<P>void tb_unlock(void)<BR>{<BR>#ifdef CONFIG_USER_ONLY<BR>&nbsp;&nbsp;&nbsp; assert(have_tb_lock);<BR>&nbsp;&nbsp;&nbsp; have_tb_lock--;<BR>&nbsp;&nbsp;&nbsp; qemu_mutex_unlock(&amp;tcg_ctx.tb_ctx.tb_lock);<BR>#endif<BR>}</P>
<P>void tb_lock_reset(void)<BR>{<BR>#ifdef CONFIG_USER_ONLY<BR>&nbsp;&nbsp;&nbsp; if (have_tb_lock) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; qemu_mutex_unlock(&amp;tcg_ctx.tb_ctx.tb_lock);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; have_tb_lock = 0;<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif<BR>}</P>
<P>static void tb_link_page(TranslationBlock *tb, tb_page_addr_t phys_pc,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_page_addr_t phys_page2);<BR>static TranslationBlock *tb_find_pc(uintptr_t tc_ptr);</P>
<P><FONT class=extract>void cpu_gen_init(void)<BR>{<BR>&nbsp;&nbsp;&nbsp; tcg_context_init(&amp;tcg_ctx); <BR>}</FONT></P>
<P>/* Encode VAL as a signed leb128 sequence at P.<BR>&nbsp;&nbsp; Return P incremented past the encoded value.&nbsp; */<BR>static uint8_t *encode_sleb128(uint8_t *p, target_long val)<BR>{<BR>&nbsp;&nbsp;&nbsp; int more, byte;</P>
<P>&nbsp;&nbsp;&nbsp; do {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; byte = val &amp; 0x7f;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; val &gt;&gt;= 7;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; more = !((val == 0 &amp;&amp; (byte &amp; 0x40) == 0)<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; || (val == -1 &amp;&amp; (byte &amp; 0x40) != 0));<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (more) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; byte |= 0x80;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *p++ = byte;<BR>&nbsp;&nbsp;&nbsp; } while (more);</P>
<P>&nbsp;&nbsp;&nbsp; return p;<BR>}</P>
<P>/* Decode a signed leb128 sequence at *PP; increment *PP past the<BR>&nbsp;&nbsp; decoded value.&nbsp; Return the decoded value.&nbsp; */<BR>static target_long decode_sleb128(uint8_t **pp)<BR>{<BR>&nbsp;&nbsp;&nbsp; uint8_t *p = *pp;<BR>&nbsp;&nbsp;&nbsp; target_long val = 0;<BR>&nbsp;&nbsp;&nbsp; int byte, shift = 0;</P>
<P>&nbsp;&nbsp;&nbsp; do {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; byte = *p++;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; val |= (target_ulong)(byte &amp; 0x7f) &lt;&lt; shift;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; shift += 7;<BR>&nbsp;&nbsp;&nbsp; } while (byte &amp; 0x80);<BR>&nbsp;&nbsp;&nbsp; if (shift &lt; TARGET_LONG_BITS &amp;&amp; (byte &amp; 0x40)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; val |= -(target_ulong)1 &lt;&lt; shift;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; *pp = p;<BR>&nbsp;&nbsp;&nbsp; return val;<BR>}</P>
<P>/* Encode the data collected about the instructions while compiling TB.<BR>&nbsp;&nbsp; Place the data at BLOCK, and return the number of bytes consumed.</P>
<P>&nbsp;&nbsp; The logical table consisits of TARGET_INSN_START_WORDS target_ulong's,<BR>&nbsp;&nbsp; which come from the target's insn_start data, followed by a uintptr_t<BR>&nbsp;&nbsp; which comes from the host pc of the end of the code implementing the insn.</P>
<P>&nbsp;&nbsp; Each line of the table is encoded as sleb128 deltas from the previous<BR>&nbsp;&nbsp; line.&nbsp; The seed for the first line is { tb-&gt;pc, 0..., tb-&gt;tc_ptr }.<BR>&nbsp;&nbsp; That is, the first column is seeded with the guest pc, the last column<BR>&nbsp;&nbsp; with the host pc, and the middle columns with zeros.&nbsp; */</P>
<P>static int encode_search(TranslationBlock *tb, uint8_t *block)<BR>{<BR>&nbsp;&nbsp;&nbsp; uint8_t *highwater = tcg_ctx.code_gen_highwater;<BR>&nbsp;&nbsp;&nbsp; uint8_t *p = block;<BR>&nbsp;&nbsp;&nbsp; int i, j, n;</P>
<P>&nbsp;&nbsp;&nbsp; tb-&gt;tc_search = block;</P>
<P>&nbsp;&nbsp;&nbsp; for (i = 0, n = tb-&gt;icount; i &lt; n; ++i) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; target_ulong prev;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (j = 0; j &lt; TARGET_INSN_START_WORDS; ++j) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (i == 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; prev = (j == 0 ? tb-&gt;pc : 0);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } else {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; prev = tcg_ctx.gen_insn_data[i - 1][j];<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p = encode_sleb128(p, tcg_ctx.gen_insn_data[i][j] - prev);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; prev = (i == 0 ? 0 : tcg_ctx.gen_insn_end_off[i - 1]);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p = encode_sleb128(p, tcg_ctx.gen_insn_end_off[i] - prev);</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* Test for (pending) buffer overflow.&nbsp; The assumption is that any<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; one row beginning below the high water mark cannot overrun<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; the buffer completely.&nbsp; Thus we can test for overflow after<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; encoding a row without having to check during encoding.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (unlikely(p &gt; highwater)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return -1;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; return p - block;<BR>}</P>
<P>/* The cpu state corresponding to 'searched_pc' is restored.&nbsp; */<BR>static int cpu_restore_state_from_tb(CPUState *cpu, TranslationBlock *tb,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; uintptr_t searched_pc)<BR>{<BR>&nbsp;&nbsp;&nbsp; target_ulong data[TARGET_INSN_START_WORDS] = { tb-&gt;pc };<BR>&nbsp;&nbsp;&nbsp; uintptr_t host_pc = (uintptr_t)tb-&gt;tc_ptr;<BR>&nbsp;&nbsp;&nbsp; CPUArchState *env = cpu-&gt;env_ptr;<BR>&nbsp;&nbsp;&nbsp; uint8_t *p = tb-&gt;tc_search;<BR>&nbsp;&nbsp;&nbsp; int i, j, num_insns = tb-&gt;icount;<BR>#ifdef CONFIG_PROFILER<BR>&nbsp;&nbsp;&nbsp; int64_t ti = profile_getclock();<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; if (searched_pc &lt; host_pc) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return -1;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; /* Reconstruct the stored insn data while looking for the point at<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; which the end of the insn exceeds the searched_pc.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; for (i = 0; i &lt; num_insns; ++i) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (j = 0; j &lt; TARGET_INSN_START_WORDS; ++j) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; data[j] += decode_sleb128(&amp;p);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; host_pc += decode_sleb128(&amp;p);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (host_pc &gt; searched_pc) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; goto found;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; return -1;</P>
<P>&nbsp;found:<BR>&nbsp;&nbsp;&nbsp; if (tb-&gt;cflags &amp; CF_USE_ICOUNT) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; assert(use_icount);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* Reset the cycle counter to the start of the block.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu-&gt;icount_decr.u16.low += num_insns;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* Clear the IO flag.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu-&gt;can_do_io = 0;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; cpu-&gt;icount_decr.u16.low -= i;<BR>&nbsp;&nbsp;&nbsp; restore_state_to_opc(env, tb, data);</P>
<P>#ifdef CONFIG_PROFILER<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.restore_time += profile_getclock() - ti;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.restore_count++;<BR>#endif<BR>&nbsp;&nbsp;&nbsp; return 0;<BR>}</P>
<P>bool cpu_restore_state(CPUState *cpu, uintptr_t retaddr)<BR>{<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb;</P>
<P>&nbsp;&nbsp;&nbsp; tb = tb_find_pc(retaddr);<BR>&nbsp;&nbsp;&nbsp; if (tb) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_restore_state_from_tb(cpu, tb, retaddr);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (tb-&gt;cflags &amp; CF_NOCACHE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* one-shot translation, invalidate it immediately */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu-&gt;current_tb = NULL;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_phys_invalidate(tb, -1);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_free(tb);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return true;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; return false;<BR>}</P>
<P>void page_size_init(void)<BR>{<BR>&nbsp;&nbsp;&nbsp; /* NOTE: we can always suppose that qemu_host_page_size &gt;=<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; TARGET_PAGE_SIZE */<BR>&nbsp;&nbsp;&nbsp; qemu_real_host_page_size = getpagesize();<BR>&nbsp;&nbsp;&nbsp; qemu_real_host_page_mask = -(intptr_t)qemu_real_host_page_size;<BR>&nbsp;&nbsp;&nbsp; if (qemu_host_page_size == 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; qemu_host_page_size = qemu_real_host_page_size;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; if (qemu_host_page_size &lt; TARGET_PAGE_SIZE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; qemu_host_page_size = TARGET_PAGE_SIZE;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; qemu_host_page_mask = -(intptr_t)qemu_host_page_size;<BR>}</P>
<P>static void page_init(void)<BR>{<BR>&nbsp;&nbsp;&nbsp; page_size_init();<BR>#if defined(CONFIG_BSD) &amp;&amp; defined(CONFIG_USER_ONLY)<BR>&nbsp;&nbsp;&nbsp; {<BR>#ifdef HAVE_KINFO_GETVMMAP<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; struct kinfo_vmentry *freep;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int i, cnt;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; freep = kinfo_getvmmap(getpid(), &amp;cnt);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (freep) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mmap_lock();<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (i = 0; i &lt; cnt; i++) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; unsigned long startaddr, endaddr;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; startaddr = freep[i].kve_start;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; endaddr = freep[i].kve_end;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (h2g_valid(startaddr)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; startaddr = h2g(startaddr) &amp; TARGET_PAGE_MASK;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (h2g_valid(endaddr)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; endaddr = h2g(endaddr);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; page_set_flags(startaddr, endaddr, PAGE_RESERVED);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } else {<BR>#if TARGET_ABI_BITS &lt;= L1_MAP_ADDR_SPACE_BITS<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; endaddr = ~0ul;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; page_set_flags(startaddr, endaddr, PAGE_RESERVED);<BR>#endif<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; free(freep);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mmap_unlock();<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>#else<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; FILE *f;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; last_brk = (unsigned long)sbrk(0);</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; f = fopen("/compat/linux/proc/self/maps", "r");<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (f) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mmap_lock();</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; do {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; unsigned long startaddr, endaddr;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int n;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; n = fscanf(f, "%lx-%lx %*[^\n]\n", &amp;startaddr, &amp;endaddr);</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (n == 2 &amp;&amp; h2g_valid(startaddr)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; startaddr = h2g(startaddr) &amp; TARGET_PAGE_MASK;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (h2g_valid(endaddr)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; endaddr = h2g(endaddr);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } else {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; endaddr = ~0ul;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; page_set_flags(startaddr, endaddr, PAGE_RESERVED);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } while (!feof(f));</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fclose(f);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mmap_unlock();<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>#endif<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif<BR>}</P>
<P>/* If alloc=1:<BR>&nbsp;* Called with mmap_lock held for user-mode emulation.<BR>&nbsp;*/<BR>static PageDesc *page_find_alloc(tb_page_addr_t index, int alloc)<BR>{<BR>&nbsp;&nbsp;&nbsp; PageDesc *pd;<BR>&nbsp;&nbsp;&nbsp; void **lp;<BR>&nbsp;&nbsp;&nbsp; int i;</P>
<P>&nbsp;&nbsp;&nbsp; /* Level 1.&nbsp; Always allocated.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; lp = l1_map + ((index &gt;&gt; V_L1_SHIFT) &amp; (V_L1_SIZE - 1));</P>
<P>&nbsp;&nbsp;&nbsp; /* Level 2..N-1.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; for (i = V_L1_SHIFT / V_L2_BITS - 1; i &gt; 0; i--) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; void **p = atomic_rcu_read(lp);</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (p == NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!alloc) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return NULL;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p = g_new0(void *, V_L2_SIZE);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; atomic_rcu_set(lp, p);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; lp = p + ((index &gt;&gt; (i * V_L2_BITS)) &amp; (V_L2_SIZE - 1));<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; pd = atomic_rcu_read(lp);<BR>&nbsp;&nbsp;&nbsp; if (pd == NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!alloc) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return NULL;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pd = g_new0(PageDesc, V_L2_SIZE);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; atomic_rcu_set(lp, pd);<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; return pd + (index &amp; (V_L2_SIZE - 1));<BR>}</P>
<P>static inline PageDesc *page_find(tb_page_addr_t index)<BR>{<BR>&nbsp;&nbsp;&nbsp; return page_find_alloc(index, 0);<BR>}</P>
<P><FONT class=extract>#if defined(CONFIG_USER_ONLY)<BR>/* Currently it is not recommended to allocate big chunks of data in<BR>&nbsp;&nbsp; user mode. It will change when a dedicated libc will be used.&nbsp; */<BR>/* ??? 64-bit hosts ought to have no problem mmaping data outside the<BR>&nbsp;&nbsp; region in which the guest needs to run.&nbsp; Revisit this.&nbsp; */<BR>#define USE_STATIC_CODE_GEN_BUFFER<BR>#endif</FONT></P>
<P><FONT class=extract>/* Minimum size of the code gen buffer.&nbsp; This number is randomly chosen,<BR>&nbsp;&nbsp; but not so small that we can't have a fair number of TB's live.&nbsp; */<BR>#define MIN_CODE_GEN_BUFFER_SIZE&nbsp;&nbsp;&nbsp;&nbsp; (1024u * 1024)</FONT></P>
<P><FONT class=extract>/* Maximum size of the code gen buffer we'd like to use.&nbsp; Unless otherwise<BR>&nbsp;&nbsp; indicated, this is constrained by the range of direct branches on the<BR>&nbsp;&nbsp; host cpu, as used by the TCG implementation of goto_tb.&nbsp; */<BR>#if defined(__x86_64__)<BR># define MAX_CODE_GEN_BUFFER_SIZE&nbsp; (2ul * 1024 * 1024 * 1024)<BR>#elif defined(__sparc__)<BR># define MAX_CODE_GEN_BUFFER_SIZE&nbsp; (2ul * 1024 * 1024 * 1024)<BR>#elif defined(__powerpc64__)<BR># define MAX_CODE_GEN_BUFFER_SIZE&nbsp; (2ul * 1024 * 1024 * 1024)<BR>#elif defined(__aarch64__)<BR># define MAX_CODE_GEN_BUFFER_SIZE&nbsp; (128ul * 1024 * 1024)<BR>#elif defined(__arm__)<BR># define MAX_CODE_GEN_BUFFER_SIZE&nbsp; (16u * 1024 * 1024)<BR>#elif defined(__s390x__)<BR>&nbsp; /* We have a +- 4GB range on the branches; leave some slop.&nbsp; */<BR># define MAX_CODE_GEN_BUFFER_SIZE&nbsp; (3ul * 1024 * 1024 * 1024)<BR>#elif defined(__mips__)<BR>&nbsp; /* We have a 256MB branch region, but leave room to make sure the<BR>&nbsp;&nbsp;&nbsp;&nbsp; main executable is also within that region.&nbsp; */<BR># define MAX_CODE_GEN_BUFFER_SIZE&nbsp; (128ul * 1024 * 1024)<BR>#else<BR># define MAX_CODE_GEN_BUFFER_SIZE&nbsp; ((size_t)-1)<BR>#endif</FONT></P>
<P><FONT class=extract>#define DEFAULT_CODE_GEN_BUFFER_SIZE_1 (32u * 1024 * 1024)</FONT></P>
<P><FONT class=extract>#define DEFAULT_CODE_GEN_BUFFER_SIZE \<BR>&nbsp; (DEFAULT_CODE_GEN_BUFFER_SIZE_1 &lt; MAX_CODE_GEN_BUFFER_SIZE \<BR>&nbsp;&nbsp; ? DEFAULT_CODE_GEN_BUFFER_SIZE_1 : MAX_CODE_GEN_BUFFER_SIZE)</FONT></P>
<P><FONT class=extract>static inline size_t size_code_gen_buffer(size_t tb_size)<BR>{<BR>&nbsp;&nbsp;&nbsp; /* Size the buffer.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; if (tb_size == 0) {<BR>#ifdef USE_STATIC_CODE_GEN_BUFFER<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_size = DEFAULT_CODE_GEN_BUFFER_SIZE;<BR>#else<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* ??? Needs adjustments.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* ??? If we relax the requirement that CONFIG_USER_ONLY use the<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; static buffer, we could size this on RESERVED_VA, on the text<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; segment size of the executable, or continue to use the default.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_size = (unsigned long)(ram_size / 4);<BR>#endif<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; if (tb_size &lt; MIN_CODE_GEN_BUFFER_SIZE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_size = MIN_CODE_GEN_BUFFER_SIZE;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; if (tb_size &gt; MAX_CODE_GEN_BUFFER_SIZE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_size = MAX_CODE_GEN_BUFFER_SIZE;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_buffer_size = tb_size;<BR>&nbsp;&nbsp;&nbsp; return tb_size;<BR>}</FONT></P>
<P>#ifdef __mips__<BR>/* In order to use J and JAL within the code_gen_buffer, we require<BR>&nbsp;&nbsp; that the buffer not cross a 256MB boundary.&nbsp; */<BR>static inline bool cross_256mb(void *addr, size_t size)<BR>{<BR>&nbsp;&nbsp;&nbsp; return ((uintptr_t)addr ^ ((uintptr_t)addr + size)) &amp; 0xf0000000;<BR>}</P>
<P>/* We weren't able to allocate a buffer without crossing that boundary,<BR>&nbsp;&nbsp; so make do with the larger portion of the buffer that doesn't cross.<BR>&nbsp;&nbsp; Returns the new base of the buffer, and adjusts code_gen_buffer_size.&nbsp; */<BR>static inline void *split_cross_256mb(void *buf1, size_t size1)<BR>{<BR>&nbsp;&nbsp;&nbsp; void *buf2 = (void *)(((uintptr_t)buf1 + size1) &amp; 0xf0000000);<BR>&nbsp;&nbsp;&nbsp; size_t size2 = buf1 + size1 - buf2;</P>
<P>&nbsp;&nbsp;&nbsp; size1 = buf2 - buf1;<BR>&nbsp;&nbsp;&nbsp; if (size1 &lt; size2) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; size1 = size2;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; buf1 = buf2;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_buffer_size = size1;<BR>&nbsp;&nbsp;&nbsp; return buf1;<BR>}<BR>#endif</P>
<P>#ifdef USE_STATIC_CODE_GEN_BUFFER<BR>static uint8_t static_code_gen_buffer[DEFAULT_CODE_GEN_BUFFER_SIZE]<BR>&nbsp;&nbsp;&nbsp; __attribute__((aligned(CODE_GEN_ALIGN)));</P>
<P># ifdef _WIN32<BR>static inline void do_protect(void *addr, long size, int prot)<BR>{<BR>&nbsp;&nbsp;&nbsp; DWORD old_protect;<BR>&nbsp;&nbsp;&nbsp; VirtualProtect(addr, size, prot, &amp;old_protect);<BR>}</P>
<P>static inline void map_exec(void *addr, long size)<BR>{<BR>&nbsp;&nbsp;&nbsp; do_protect(addr, size, PAGE_EXECUTE_READWRITE);<BR>}</P>
<P>static inline void map_none(void *addr, long size)<BR>{<BR>&nbsp;&nbsp;&nbsp; do_protect(addr, size, PAGE_NOACCESS);<BR>}<BR># else<BR>static inline void do_protect(void *addr, long size, int prot)<BR>{<BR>&nbsp;&nbsp;&nbsp; uintptr_t start, end;</P>
<P>&nbsp;&nbsp;&nbsp; start = (uintptr_t)addr;<BR>&nbsp;&nbsp;&nbsp; start &amp;= qemu_real_host_page_mask;</P>
<P>&nbsp;&nbsp;&nbsp; end = (uintptr_t)addr + size;<BR>&nbsp;&nbsp;&nbsp; end = ROUND_UP(end, qemu_real_host_page_size);</P>
<P>&nbsp;&nbsp;&nbsp; mprotect((void *)start, end - start, prot);<BR>}</P>
<P>static inline void map_exec(void *addr, long size)<BR>{<BR>&nbsp;&nbsp;&nbsp; do_protect(addr, size, PROT_READ | PROT_WRITE | PROT_EXEC);<BR>}</P>
<P>static inline void map_none(void *addr, long size)<BR>{<BR>&nbsp;&nbsp;&nbsp; do_protect(addr, size, PROT_NONE);<BR>}<BR># endif /* WIN32 */</P>
<P>static inline void *alloc_code_gen_buffer(void)<BR>{<BR>&nbsp;&nbsp;&nbsp; void *buf = static_code_gen_buffer;<BR>&nbsp;&nbsp;&nbsp; size_t full_size, size;</P>
<P>&nbsp;&nbsp;&nbsp; /* The size of the buffer, rounded down to end on a page boundary.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; full_size = (((uintptr_t)buf + sizeof(static_code_gen_buffer))<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &amp; qemu_real_host_page_mask) - (uintptr_t)buf;</P>
<P>&nbsp;&nbsp;&nbsp; /* Reserve a guard page.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; size = full_size - qemu_real_host_page_size;</P>
<P>&nbsp;&nbsp;&nbsp; /* Honor a command-line option limiting the size of the buffer.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; if (size &gt; tcg_ctx.code_gen_buffer_size) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; size = (((uintptr_t)buf + tcg_ctx.code_gen_buffer_size)<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &amp; qemu_real_host_page_mask) - (uintptr_t)buf;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_buffer_size = size;</P>
<P>#ifdef __mips__<BR>&nbsp;&nbsp;&nbsp; if (cross_256mb(buf, size)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; buf = split_cross_256mb(buf, size);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; size = tcg_ctx.code_gen_buffer_size;<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; map_exec(buf, size);<BR>&nbsp;&nbsp;&nbsp; map_none(buf + size, qemu_real_host_page_size);<BR>&nbsp;&nbsp;&nbsp; qemu_madvise(buf, size, QEMU_MADV_HUGEPAGE);</P>
<P>&nbsp;&nbsp;&nbsp; return buf;<BR>}<BR>#elif defined(_WIN32)<BR>static inline void *alloc_code_gen_buffer(void)<BR>{<BR>&nbsp;&nbsp;&nbsp; size_t size = tcg_ctx.code_gen_buffer_size;<BR>&nbsp;&nbsp;&nbsp; void *buf1, *buf2;</P>
<P>&nbsp;&nbsp;&nbsp; /* Perform the allocation in two steps, so that the guard page<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; is reserved but uncommitted.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; buf1 = VirtualAlloc(NULL, size + qemu_real_host_page_size,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MEM_RESERVE, PAGE_NOACCESS);<BR>&nbsp;&nbsp;&nbsp; if (buf1 != NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; buf2 = VirtualAlloc(buf1, size, MEM_COMMIT, PAGE_EXECUTE_READWRITE);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; assert(buf1 == buf2);<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; return buf1;<BR>}<BR>#else<BR>static inline void *alloc_code_gen_buffer(void)<BR>{<BR>&nbsp;&nbsp;&nbsp; int flags = MAP_PRIVATE | MAP_ANONYMOUS;<BR>&nbsp;&nbsp;&nbsp; uintptr_t start = 0;<BR>&nbsp;&nbsp;&nbsp; size_t size = tcg_ctx.code_gen_buffer_size;<BR>&nbsp;&nbsp;&nbsp; void *buf;</P>
<P>&nbsp;&nbsp;&nbsp; /* Constrain the position of the buffer based on the host cpu.<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Note that these addresses are chosen in concert with the<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addresses assigned in the relevant linker script file.&nbsp; */<BR># if defined(__PIE__) || defined(__PIC__)<BR>&nbsp;&nbsp;&nbsp; /* Don't bother setting a preferred location if we're building<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a position-independent executable.&nbsp; We're more likely to get<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; an address near the main executable if we let the kernel<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; choose the address.&nbsp; */<BR># elif defined(__x86_64__) &amp;&amp; defined(MAP_32BIT)<BR>&nbsp;&nbsp;&nbsp; /* Force the memory down into low memory with the executable.<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Leave the choice of exact location with the kernel.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; flags |= MAP_32BIT;<BR>&nbsp;&nbsp;&nbsp; /* Cannot expect to map more than 800MB in low memory.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; if (size &gt; 800u * 1024 * 1024) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_buffer_size = size = 800u * 1024 * 1024;<BR>&nbsp;&nbsp;&nbsp; }<BR># elif defined(__sparc__)<BR>&nbsp;&nbsp;&nbsp; start = 0x40000000ul;<BR># elif defined(__s390x__)<BR>&nbsp;&nbsp;&nbsp; start = 0x90000000ul;<BR># elif defined(__mips__)<BR>#&nbsp; if _MIPS_SIM == _ABI64<BR>&nbsp;&nbsp;&nbsp; start = 0x128000000ul;<BR>#&nbsp; else<BR>&nbsp;&nbsp;&nbsp; start = 0x08000000ul;<BR>#&nbsp; endif<BR># endif</P>
<P>&nbsp;&nbsp;&nbsp; buf = mmap((void *)start, size + qemu_real_host_page_size,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PROT_NONE, flags, -1, 0);<BR>&nbsp;&nbsp;&nbsp; if (buf == MAP_FAILED) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return NULL;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>#ifdef __mips__<BR>&nbsp;&nbsp;&nbsp; if (cross_256mb(buf, size)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* Try again, with the original still mapped, to avoid re-acquiring<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; that 256mb crossing.&nbsp; This time don't specify an address.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; size_t size2;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; void *buf2 = mmap(NULL, size + qemu_real_host_page_size,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PROT_NONE, flags, -1, 0);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; switch (buf2 != MAP_FAILED) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; case 1:<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!cross_256mb(buf2, size)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* Success!&nbsp; Use the new buffer.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; munmap(buf, size);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* Failure.&nbsp; Work with what we had.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; munmap(buf2, size);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* fallthru */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; default:<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* Split the original buffer.&nbsp; Free the smaller half.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; buf2 = split_cross_256mb(buf, size);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; size2 = tcg_ctx.code_gen_buffer_size;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (buf == buf2) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; munmap(buf + size2 + qemu_real_host_page_size, size - size2);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } else {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; munmap(buf, size - size2);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; size = size2;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; buf = buf2;<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; /* Make the final buffer accessible.&nbsp; The guard page at the end<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; will remain inaccessible with PROT_NONE.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; mprotect(buf, size, PROT_WRITE | PROT_READ | PROT_EXEC);</P>
<P>&nbsp;&nbsp;&nbsp; /* Request large pages for the buffer.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; qemu_madvise(buf, size, QEMU_MADV_HUGEPAGE);</P>
<P>&nbsp;&nbsp;&nbsp; return buf;<BR>}<BR>#endif /* USE_STATIC_CODE_GEN_BUFFER, WIN32, POSIX */</P>
<P><FONT class=extract>static inline void code_gen_alloc(size_t tb_size)<BR>{<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_buffer_size = size_code_gen_buffer(tb_size);<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_buffer = alloc_code_gen_buffer();<BR>&nbsp;&nbsp;&nbsp; if (tcg_ctx.code_gen_buffer == NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fprintf(stderr, "Could not allocate dynamic translator buffer\n");<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exit(1);<BR>&nbsp;&nbsp;&nbsp; }</FONT></P>
<P><FONT class=extract>&nbsp;&nbsp;&nbsp; /* Estimate a good size for the number of TBs we can support.&nbsp; We<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; still haven't deducted the prologue from the buffer size here,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; but that's minimal and won't affect the estimate much.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_max_blocks<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; = tcg_ctx.code_gen_buffer_size / CODE_GEN_AVG_BLOCK_SIZE;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.tbs = g_new(TranslationBlock, tcg_ctx.code_gen_max_blocks);</FONT></P>
<P><FONT class=extract>&nbsp;&nbsp;&nbsp; qemu_mutex_init(&amp;tcg_ctx.tb_ctx.tb_lock);<BR>}</FONT></P>
<P><FONT class=extract>/* Must be called before using the QEMU cpus. 'tb_size' is the size<BR>&nbsp;&nbsp; (in bytes) allocated to the translation buffer. Zero means default<BR>&nbsp;&nbsp; size. */<BR>void tcg_exec_init(unsigned long tb_size)<BR>{<BR>&nbsp;&nbsp;&nbsp; cpu_gen_init();<BR>&nbsp;&nbsp;&nbsp; page_init();<BR>&nbsp;&nbsp;&nbsp; code_gen_alloc(tb_size);<BR>#if defined(CONFIG_SOFTMMU)<BR>&nbsp;&nbsp;&nbsp; /* There's no guest base to take into account, so go ahead and<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; initialize the prologue now.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; tcg_prologue_init(&amp;tcg_ctx);<BR>#endif<BR>}</FONT></P>
<P>bool tcg_enabled(void)<BR>{<BR>&nbsp;&nbsp;&nbsp; return tcg_ctx.code_gen_buffer != NULL;<BR>}</P>
<P>/* Allocate a new translation block. Flush the translation buffer if<BR>&nbsp;&nbsp; too many translation blocks or too much generated code. */<BR>static TranslationBlock *tb_alloc(target_ulong pc)<BR>{<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb;</P>
<P>&nbsp;&nbsp;&nbsp; if (tcg_ctx.tb_ctx.nb_tbs &gt;= tcg_ctx.code_gen_max_blocks) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return NULL;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; tb = &amp;tcg_ctx.tb_ctx.tbs[tcg_ctx.tb_ctx.nb_tbs++];<BR>&nbsp;&nbsp;&nbsp; tb-&gt;pc = pc;<BR>&nbsp;&nbsp;&nbsp; tb-&gt;cflags = 0;<BR>&nbsp;&nbsp;&nbsp; return tb;<BR>}</P>
<P>void tb_free(TranslationBlock *tb)<BR>{<BR>&nbsp;&nbsp;&nbsp; /* In practice this is mostly used for single use temporary TB<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Ignore the hard cases and just back up if this TB happens to<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; be the last one generated.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; if (tcg_ctx.tb_ctx.nb_tbs &gt; 0 &amp;&amp;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb == &amp;tcg_ctx.tb_ctx.tbs[tcg_ctx.tb_ctx.nb_tbs - 1]) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_ptr = tb-&gt;tc_ptr;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs--;<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>static inline void invalidate_page_bitmap(PageDesc *p)<BR>{<BR>&nbsp;&nbsp;&nbsp; g_free(p-&gt;code_bitmap);<BR>&nbsp;&nbsp;&nbsp; p-&gt;code_bitmap = NULL;<BR>&nbsp;&nbsp;&nbsp; p-&gt;code_write_count = 0;<BR>}</P>
<P>/* Set to NULL all the 'first_tb' fields in all PageDescs. */<BR>static void page_flush_tb_1(int level, void **lp)<BR>{<BR>&nbsp;&nbsp;&nbsp; int i;</P>
<P>&nbsp;&nbsp;&nbsp; if (*lp == NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; if (level == 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PageDesc *pd = *lp;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (i = 0; i &lt; V_L2_SIZE; ++i) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pd[i].first_tb = NULL;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; invalidate_page_bitmap(pd + i);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; } else {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; void **pp = *lp;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (i = 0; i &lt; V_L2_SIZE; ++i) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; page_flush_tb_1(level - 1, pp + i);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>static void page_flush_tb(void)<BR>{<BR>&nbsp;&nbsp;&nbsp; int i;</P>
<P>&nbsp;&nbsp;&nbsp; for (i = 0; i &lt; V_L1_SIZE; i++) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; page_flush_tb_1(V_L1_SHIFT / V_L2_BITS - 1, l1_map + i);<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>/* flush all the translation blocks */<BR>/* XXX: tb_flush is currently not thread safe */<BR>void tb_flush(CPUState *cpu)<BR>{<BR>#if defined(DEBUG_FLUSH)<BR>&nbsp;&nbsp;&nbsp; printf("qemu: flush code_size=%ld nb_tbs=%d avg_tb_size=%ld\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (unsigned long)(tcg_ctx.code_gen_ptr - tcg_ctx.code_gen_buffer),<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs, tcg_ctx.tb_ctx.nb_tbs &gt; 0 ?<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ((unsigned long)(tcg_ctx.code_gen_ptr - tcg_ctx.code_gen_buffer)) /<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs : 0);<BR>#endif<BR>&nbsp;&nbsp;&nbsp; if ((unsigned long)(tcg_ctx.code_gen_ptr - tcg_ctx.code_gen_buffer)<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &gt; tcg_ctx.code_gen_buffer_size) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_abort(cpu, "Internal error: code buffer overflow\n");<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs = 0;</P>
<P>&nbsp;&nbsp;&nbsp; CPU_FOREACH(cpu) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; memset(cpu-&gt;tb_jmp_cache, 0, sizeof(cpu-&gt;tb_jmp_cache));<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; memset(tcg_ctx.tb_ctx.tb_phys_hash, 0, sizeof(tcg_ctx.tb_ctx.tb_phys_hash));<BR>&nbsp;&nbsp;&nbsp; page_flush_tb();</P>
<P>&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_ptr = tcg_ctx.code_gen_buffer;<BR>&nbsp;&nbsp;&nbsp; /* XXX: flush processor icache at this point if cache flush is<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; expensive */<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.tb_flush_count++;<BR>}</P>
<P>#ifdef DEBUG_TB_CHECK</P>
<P>static void tb_invalidate_check(target_ulong address)<BR>{<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb;<BR>&nbsp;&nbsp;&nbsp; int i;</P>
<P>&nbsp;&nbsp;&nbsp; address &amp;= TARGET_PAGE_MASK;<BR>&nbsp;&nbsp;&nbsp; for (i = 0; i &lt; CODE_GEN_PHYS_HASH_SIZE; i++) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (tb = tb_ctx.tb_phys_hash[i]; tb != NULL; tb = tb-&gt;phys_hash_next) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!(address + TARGET_PAGE_SIZE &lt;= tb-&gt;pc ||<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; address &gt;= tb-&gt;pc + tb-&gt;size)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printf("ERROR invalidate: address=" TARGET_FMT_lx<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; " PC=%08lx size=%04x\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; address, (long)tb-&gt;pc, tb-&gt;size);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>/* verify that all the pages have correct rights for code */<BR>static void tb_page_check(void)<BR>{<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb;<BR>&nbsp;&nbsp;&nbsp; int i, flags1, flags2;</P>
<P>&nbsp;&nbsp;&nbsp; for (i = 0; i &lt; CODE_GEN_PHYS_HASH_SIZE; i++) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (tb = tcg_ctx.tb_ctx.tb_phys_hash[i]; tb != NULL;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb = tb-&gt;phys_hash_next) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; flags1 = page_get_flags(tb-&gt;pc);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; flags2 = page_get_flags(tb-&gt;pc + tb-&gt;size - 1);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if ((flags1 &amp; PAGE_WRITE) || (flags2 &amp; PAGE_WRITE)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printf("ERROR page flags: PC=%08lx size=%04x f1=%x f2=%x\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (long)tb-&gt;pc, tb-&gt;size, flags1, flags2);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>#endif</P>
<P>static inline void tb_hash_remove(TranslationBlock **ptb, TranslationBlock *tb)<BR>{<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb1;</P>
<P>&nbsp;&nbsp;&nbsp; for (;;) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb1 = *ptb;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (tb1 == tb) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *ptb = tb1-&gt;phys_hash_next;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ptb = &amp;tb1-&gt;phys_hash_next;<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>static inline void tb_page_remove(TranslationBlock **ptb, TranslationBlock *tb)<BR>{<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb1;<BR>&nbsp;&nbsp;&nbsp; unsigned int n1;</P>
<P>&nbsp;&nbsp;&nbsp; for (;;) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb1 = *ptb;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; n1 = (uintptr_t)tb1 &amp; 3;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb1 = (TranslationBlock *)((uintptr_t)tb1 &amp; ~3);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (tb1 == tb) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *ptb = tb1-&gt;page_next[n1];<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ptb = &amp;tb1-&gt;page_next[n1];<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>static inline void tb_jmp_remove(TranslationBlock *tb, int n)<BR>{<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb1, **ptb;<BR>&nbsp;&nbsp;&nbsp; unsigned int n1;</P>
<P>&nbsp;&nbsp;&nbsp; ptb = &amp;tb-&gt;jmp_next[n];<BR>&nbsp;&nbsp;&nbsp; tb1 = *ptb;<BR>&nbsp;&nbsp;&nbsp; if (tb1) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* find tb(n) in circular list */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (;;) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb1 = *ptb;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; n1 = (uintptr_t)tb1 &amp; 3;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb1 = (TranslationBlock *)((uintptr_t)tb1 &amp; ~3);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (n1 == n &amp;&amp; tb1 == tb) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (n1 == 2) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ptb = &amp;tb1-&gt;jmp_first;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } else {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ptb = &amp;tb1-&gt;jmp_next[n1];<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* now we can suppress tb(n) from the list */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; *ptb = tb-&gt;jmp_next[n];</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb-&gt;jmp_next[n] = NULL;<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>/* reset the jump entry 'n' of a TB so that it is not chained to<BR>&nbsp;&nbsp; another TB */<BR>static inline void tb_reset_jump(TranslationBlock *tb, int n)<BR>{<BR>&nbsp;&nbsp;&nbsp; tb_set_jmp_target(tb, n, (uintptr_t)(tb-&gt;tc_ptr + tb-&gt;tb_next_offset[n]));<BR>}</P>
<P>/* invalidate one TB */<BR>void tb_phys_invalidate(TranslationBlock *tb, tb_page_addr_t page_addr)<BR>{<BR>&nbsp;&nbsp;&nbsp; CPUState *cpu;<BR>&nbsp;&nbsp;&nbsp; PageDesc *p;<BR>&nbsp;&nbsp;&nbsp; unsigned int h, n1;<BR>&nbsp;&nbsp;&nbsp; tb_page_addr_t phys_pc;<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb1, *tb2;</P>
<P>&nbsp;&nbsp;&nbsp; /* remove the TB from the hash list */<BR>&nbsp;&nbsp;&nbsp; phys_pc = tb-&gt;page_addr[0] + (tb-&gt;pc &amp; ~TARGET_PAGE_MASK);<BR>&nbsp;&nbsp;&nbsp; h = tb_phys_hash_func(phys_pc);<BR>&nbsp;&nbsp;&nbsp; tb_hash_remove(&amp;tcg_ctx.tb_ctx.tb_phys_hash[h], tb);</P>
<P>&nbsp;&nbsp;&nbsp; /* remove the TB from the page list */<BR>&nbsp;&nbsp;&nbsp; if (tb-&gt;page_addr[0] != page_addr) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p = page_find(tb-&gt;page_addr[0] &gt;&gt; TARGET_PAGE_BITS);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_page_remove(&amp;p-&gt;first_tb, tb);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; invalidate_page_bitmap(p);<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; if (tb-&gt;page_addr[1] != -1 &amp;&amp; tb-&gt;page_addr[1] != page_addr) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p = page_find(tb-&gt;page_addr[1] &gt;&gt; TARGET_PAGE_BITS);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_page_remove(&amp;p-&gt;first_tb, tb);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; invalidate_page_bitmap(p);<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.tb_invalidated_flag = 1;</P>
<P>&nbsp;&nbsp;&nbsp; /* remove the TB from the hash list */<BR>&nbsp;&nbsp;&nbsp; h = tb_jmp_cache_hash_func(tb-&gt;pc);<BR>&nbsp;&nbsp;&nbsp; CPU_FOREACH(cpu) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (cpu-&gt;tb_jmp_cache[h] == tb) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu-&gt;tb_jmp_cache[h] = NULL;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; /* suppress this TB from the two jump lists */<BR>&nbsp;&nbsp;&nbsp; tb_jmp_remove(tb, 0);<BR>&nbsp;&nbsp;&nbsp; tb_jmp_remove(tb, 1);</P>
<P>&nbsp;&nbsp;&nbsp; /* suppress any remaining jumps to this TB */<BR>&nbsp;&nbsp;&nbsp; tb1 = tb-&gt;jmp_first;<BR>&nbsp;&nbsp;&nbsp; for (;;) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; n1 = (uintptr_t)tb1 &amp; 3;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (n1 == 2) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; break;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb1 = (TranslationBlock *)((uintptr_t)tb1 &amp; ~3);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb2 = tb1-&gt;jmp_next[n1];<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_reset_jump(tb1, n1);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb1-&gt;jmp_next[n1] = NULL;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb1 = tb2;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; tb-&gt;jmp_first = (TranslationBlock *)((uintptr_t)tb | 2); /* fail safe */</P>
<P>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.tb_phys_invalidate_count++;<BR>}</P>
<P>static void build_page_bitmap(PageDesc *p)<BR>{<BR>&nbsp;&nbsp;&nbsp; int n, tb_start, tb_end;<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb;</P>
<P>&nbsp;&nbsp;&nbsp; p-&gt;code_bitmap = bitmap_new(TARGET_PAGE_SIZE);</P>
<P>&nbsp;&nbsp;&nbsp; tb = p-&gt;first_tb;<BR>&nbsp;&nbsp;&nbsp; while (tb != NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; n = (uintptr_t)tb &amp; 3;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb = (TranslationBlock *)((uintptr_t)tb &amp; ~3);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* NOTE: this is subtle as a TB may span two physical pages */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (n == 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* NOTE: tb_end may be after the end of the page, but<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; it is not a problem */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_start = tb-&gt;pc &amp; ~TARGET_PAGE_MASK;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_end = tb_start + tb-&gt;size;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (tb_end &gt; TARGET_PAGE_SIZE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_end = TARGET_PAGE_SIZE;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } else {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_start = 0;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_end = ((tb-&gt;pc + tb-&gt;size) &amp; ~TARGET_PAGE_MASK);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; bitmap_set(p-&gt;code_bitmap, tb_start, tb_end - tb_start);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb = tb-&gt;page_next[n];<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>/* Called with mmap_lock held for user mode emulation.&nbsp; */<BR>TranslationBlock *tb_gen_code(CPUState *cpu,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; target_ulong pc, target_ulong cs_base,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int flags, int cflags)<BR>{<BR>&nbsp;&nbsp;&nbsp; CPUArchState *env = cpu-&gt;env_ptr;<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb;<BR>&nbsp;&nbsp;&nbsp; tb_page_addr_t phys_pc, phys_page2;<BR>&nbsp;&nbsp;&nbsp; target_ulong virt_page2;<BR>&nbsp;&nbsp;&nbsp; tcg_insn_unit *gen_code_buf;<BR>&nbsp;&nbsp;&nbsp; int gen_code_size, search_size;<BR>#ifdef CONFIG_PROFILER<BR>&nbsp;&nbsp;&nbsp; int64_t ti;<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; phys_pc = get_page_addr_code(env, pc);<BR>&nbsp;&nbsp;&nbsp; if (use_icount &amp;&amp; !(cflags &amp; CF_IGNORE_ICOUNT)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cflags |= CF_USE_ICOUNT;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; tb = tb_alloc(pc);<BR>&nbsp;&nbsp;&nbsp; if (unlikely(!tb)) {<BR>&nbsp;buffer_overflow:<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* flush must be done */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_flush(cpu);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* cannot fail at this point */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb = tb_alloc(pc);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; assert(tb != NULL);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* Don't forget to invalidate previous TB info.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.tb_invalidated_flag = 1;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; gen_code_buf = tcg_ctx.code_gen_ptr;<BR>&nbsp;&nbsp;&nbsp; tb-&gt;tc_ptr = gen_code_buf;<BR>&nbsp;&nbsp;&nbsp; tb-&gt;cs_base = cs_base;<BR>&nbsp;&nbsp;&nbsp; tb-&gt;flags = flags;<BR>&nbsp;&nbsp;&nbsp; tb-&gt;cflags = cflags;</P>
<P>#ifdef CONFIG_PROFILER<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_count1++; /* includes aborted translations because of<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exceptions */<BR>&nbsp;&nbsp;&nbsp; ti = profile_getclock();<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; tcg_func_start(&amp;tcg_ctx);</P>
<P>&nbsp;&nbsp;&nbsp; gen_intermediate_code(env, tb);</P>
<P>&nbsp;&nbsp;&nbsp; trace_translate_block(tb, tb-&gt;pc, tb-&gt;tc_ptr);</P>
<P>&nbsp;&nbsp;&nbsp; /* generate machine code */<BR>&nbsp;&nbsp;&nbsp; tb-&gt;tb_next_offset[0] = 0xffff;<BR>&nbsp;&nbsp;&nbsp; tb-&gt;tb_next_offset[1] = 0xffff;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_next_offset = tb-&gt;tb_next_offset;<BR>#ifdef USE_DIRECT_JUMP<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_jmp_offset = tb-&gt;tb_jmp_offset;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_next = NULL;<BR>#else<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_jmp_offset = NULL;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_next = tb-&gt;tb_next;<BR>#endif</P>
<P>#ifdef CONFIG_PROFILER<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_count++;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.interm_time += profile_getclock() - ti;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_time -= profile_getclock();<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; /* ??? Overflow could be handled better here.&nbsp; In particular, we<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; don't need to re-do gen_intermediate_code, nor should we re-do<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; the tcg optimization currently hidden inside tcg_gen_code.&nbsp; All<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; that should be required is to flush the TBs, allocate a new TB,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; re-initialize it per above, and re-do the actual code generation.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; gen_code_size = tcg_gen_code(&amp;tcg_ctx, gen_code_buf);<BR>&nbsp;&nbsp;&nbsp; if (unlikely(gen_code_size &lt; 0)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; goto buffer_overflow;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; search_size = encode_search(tb, (void *)gen_code_buf + gen_code_size);<BR>&nbsp;&nbsp;&nbsp; if (unlikely(search_size &lt; 0)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; goto buffer_overflow;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>#ifdef CONFIG_PROFILER<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_time += profile_getclock();<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_in_len += tb-&gt;size;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_out_len += gen_code_size;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.search_out_len += search_size;<BR>#endif</P>
<P>#ifdef DEBUG_DISAS<BR>&nbsp;&nbsp;&nbsp; if (qemu_loglevel_mask(CPU_LOG_TB_OUT_ASM)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; qemu_log("OUT: [size=%d]\n", gen_code_size);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log_disas(tb-&gt;tc_ptr, gen_code_size);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; qemu_log("\n");<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; qemu_log_flush();<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_ptr = (void *)<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ROUND_UP((uintptr_t)gen_code_buf + gen_code_size + search_size,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CODE_GEN_ALIGN);</P>
<P>&nbsp;&nbsp;&nbsp; /* check next page if needed */<BR>&nbsp;&nbsp;&nbsp; virt_page2 = (pc + tb-&gt;size - 1) &amp; TARGET_PAGE_MASK;<BR>&nbsp;&nbsp;&nbsp; phys_page2 = -1;<BR>&nbsp;&nbsp;&nbsp; if ((pc &amp; TARGET_PAGE_MASK) != virt_page2) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; phys_page2 = get_page_addr_code(env, virt_page2);<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; tb_link_page(tb, phys_pc, phys_page2);<BR>&nbsp;&nbsp;&nbsp; return tb;<BR>}</P>
<P>/*<BR>&nbsp;* Invalidate all TBs which intersect with the target physical address range<BR>&nbsp;* [start;end[. NOTE: start and end may refer to *different* physical pages.<BR>&nbsp;* 'is_cpu_write_access' should be true if called from a real cpu write<BR>&nbsp;* access: the virtual CPU will exit the current TB if code is modified inside<BR>&nbsp;* this TB.<BR>&nbsp;*<BR>&nbsp;* Called with mmap_lock held for user-mode emulation<BR>&nbsp;*/<BR>void tb_invalidate_phys_range(tb_page_addr_t start, tb_page_addr_t end)<BR>{<BR>&nbsp;&nbsp;&nbsp; while (start &lt; end) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_invalidate_phys_page_range(start, end, 0);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; start &amp;= TARGET_PAGE_MASK;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; start += TARGET_PAGE_SIZE;<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>/*<BR>&nbsp;* Invalidate all TBs which intersect with the target physical address range<BR>&nbsp;* [start;end[. NOTE: start and end must refer to the *same* physical page.<BR>&nbsp;* 'is_cpu_write_access' should be true if called from a real cpu write<BR>&nbsp;* access: the virtual CPU will exit the current TB if code is modified inside<BR>&nbsp;* this TB.<BR>&nbsp;*<BR>&nbsp;* Called with mmap_lock held for user-mode emulation<BR>&nbsp;*/<BR>void tb_invalidate_phys_page_range(tb_page_addr_t start, tb_page_addr_t end,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int is_cpu_write_access)<BR>{<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb, *tb_next, *saved_tb;<BR>&nbsp;&nbsp;&nbsp; CPUState *cpu = current_cpu;<BR>#if defined(TARGET_HAS_PRECISE_SMC)<BR>&nbsp;&nbsp;&nbsp; CPUArchState *env = NULL;<BR>#endif<BR>&nbsp;&nbsp;&nbsp; tb_page_addr_t tb_start, tb_end;<BR>&nbsp;&nbsp;&nbsp; PageDesc *p;<BR>&nbsp;&nbsp;&nbsp; int n;<BR>#ifdef TARGET_HAS_PRECISE_SMC<BR>&nbsp;&nbsp;&nbsp; int current_tb_not_found = is_cpu_write_access;<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *current_tb = NULL;<BR>&nbsp;&nbsp;&nbsp; int current_tb_modified = 0;<BR>&nbsp;&nbsp;&nbsp; target_ulong current_pc = 0;<BR>&nbsp;&nbsp;&nbsp; target_ulong current_cs_base = 0;<BR>&nbsp;&nbsp;&nbsp; int current_flags = 0;<BR>#endif /* TARGET_HAS_PRECISE_SMC */</P>
<P>&nbsp;&nbsp;&nbsp; p = page_find(start &gt;&gt; TARGET_PAGE_BITS);<BR>&nbsp;&nbsp;&nbsp; if (!p) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return;<BR>&nbsp;&nbsp;&nbsp; }<BR>#if defined(TARGET_HAS_PRECISE_SMC)<BR>&nbsp;&nbsp;&nbsp; if (cpu != NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; env = cpu-&gt;env_ptr;<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; /* we remove all the TBs in the range [start, end[ */<BR>&nbsp;&nbsp;&nbsp; /* XXX: see if in some cases it could be faster to invalidate all<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; the code */<BR>&nbsp;&nbsp;&nbsp; tb = p-&gt;first_tb;<BR>&nbsp;&nbsp;&nbsp; while (tb != NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; n = (uintptr_t)tb &amp; 3;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb = (TranslationBlock *)((uintptr_t)tb &amp; ~3);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_next = tb-&gt;page_next[n];<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* NOTE: this is subtle as a TB may span two physical pages */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (n == 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* NOTE: tb_end may be after the end of the page, but<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; it is not a problem */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_start = tb-&gt;page_addr[0] + (tb-&gt;pc &amp; ~TARGET_PAGE_MASK);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_end = tb_start + tb-&gt;size;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } else {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_start = tb-&gt;page_addr[1];<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_end = tb_start + ((tb-&gt;pc + tb-&gt;size) &amp; ~TARGET_PAGE_MASK);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!(tb_end &lt;= start || tb_start &gt;= end)) {<BR>#ifdef TARGET_HAS_PRECISE_SMC<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (current_tb_not_found) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; current_tb_not_found = 0;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; current_tb = NULL;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (cpu-&gt;mem_io_pc) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* now we have a real cpu fault */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; current_tb = tb_find_pc(cpu-&gt;mem_io_pc);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (current_tb == tb &amp;&amp;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (current_tb-&gt;cflags &amp; CF_COUNT_MASK) != 1) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* If we are modifying the current TB, we must stop<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; its execution. We could be more precise by checking<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; that the modification is after the current PC, but it<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; would require a specialized function to partially<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; restore the CPU state */</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; current_tb_modified = 1;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_restore_state_from_tb(cpu, current_tb, cpu-&gt;mem_io_pc);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_get_tb_cpu_state(env, &amp;current_pc, &amp;current_cs_base,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &amp;current_flags);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>#endif /* TARGET_HAS_PRECISE_SMC */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* we need to do that to handle the case where a signal<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; occurs while doing tb_phys_invalidate() */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; saved_tb = NULL;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (cpu != NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; saved_tb = cpu-&gt;current_tb;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu-&gt;current_tb = NULL;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_phys_invalidate(tb, -1);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (cpu != NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu-&gt;current_tb = saved_tb;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (cpu-&gt;interrupt_request &amp;&amp; cpu-&gt;current_tb) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_interrupt(cpu, cpu-&gt;interrupt_request);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb = tb_next;<BR>&nbsp;&nbsp;&nbsp; }<BR>#if !defined(CONFIG_USER_ONLY)<BR>&nbsp;&nbsp;&nbsp; /* if no code remaining, no need to continue to use slow writes */<BR>&nbsp;&nbsp;&nbsp; if (!p-&gt;first_tb) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; invalidate_page_bitmap(p);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tlb_unprotect_code(start);<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif<BR>#ifdef TARGET_HAS_PRECISE_SMC<BR>&nbsp;&nbsp;&nbsp; if (current_tb_modified) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* we generate a block containing just the instruction<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; modifying the memory. It will ensure that it cannot modify<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; itself */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu-&gt;current_tb = NULL;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_gen_code(cpu, current_pc, current_cs_base, current_flags, 1);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_resume_from_signal(cpu, NULL);<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif<BR>}</P>
<P>/* len must be &lt;= 8 and start must be a multiple of len */<BR>void tb_invalidate_phys_page_fast(tb_page_addr_t start, int len)<BR>{<BR>&nbsp;&nbsp;&nbsp; PageDesc *p;</P>
<P>#if 0<BR>&nbsp;&nbsp;&nbsp; if (1) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; qemu_log("modifying code at 0x%x size=%d EIP=%x PC=%08x\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_single_env-&gt;mem_io_vaddr, len,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_single_env-&gt;eip,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_single_env-&gt;eip +<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (intptr_t)cpu_single_env-&gt;segs[R_CS].base);<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif<BR>&nbsp;&nbsp;&nbsp; p = page_find(start &gt;&gt; TARGET_PAGE_BITS);<BR>&nbsp;&nbsp;&nbsp; if (!p) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; if (!p-&gt;code_bitmap &amp;&amp;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ++p-&gt;code_write_count &gt;= SMC_BITMAP_USE_THRESHOLD) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* build code bitmap */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; build_page_bitmap(p);<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; if (p-&gt;code_bitmap) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; unsigned int nr;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; unsigned long b;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; nr = start &amp; ~TARGET_PAGE_MASK;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; b = p-&gt;code_bitmap[BIT_WORD(nr)] &gt;&gt; (nr &amp; (BITS_PER_LONG - 1));<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (b &amp; ((1 &lt;&lt; len) - 1)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; goto do_invalidate;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; } else {<BR>&nbsp;&nbsp;&nbsp; do_invalidate:<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_invalidate_phys_page_range(start, start + len, 1);<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>#if !defined(CONFIG_SOFTMMU)<BR>/* Called with mmap_lock held.&nbsp; */<BR>static void tb_invalidate_phys_page(tb_page_addr_t addr,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; uintptr_t pc, void *puc,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; bool locked)<BR>{<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb;<BR>&nbsp;&nbsp;&nbsp; PageDesc *p;<BR>&nbsp;&nbsp;&nbsp; int n;<BR>#ifdef TARGET_HAS_PRECISE_SMC<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *current_tb = NULL;<BR>&nbsp;&nbsp;&nbsp; CPUState *cpu = current_cpu;<BR>&nbsp;&nbsp;&nbsp; CPUArchState *env = NULL;<BR>&nbsp;&nbsp;&nbsp; int current_tb_modified = 0;<BR>&nbsp;&nbsp;&nbsp; target_ulong current_pc = 0;<BR>&nbsp;&nbsp;&nbsp; target_ulong current_cs_base = 0;<BR>&nbsp;&nbsp;&nbsp; int current_flags = 0;<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; addr &amp;= TARGET_PAGE_MASK;<BR>&nbsp;&nbsp;&nbsp; p = page_find(addr &gt;&gt; TARGET_PAGE_BITS);<BR>&nbsp;&nbsp;&nbsp; if (!p) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; tb = p-&gt;first_tb;<BR>#ifdef TARGET_HAS_PRECISE_SMC<BR>&nbsp;&nbsp;&nbsp; if (tb &amp;&amp; pc != 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; current_tb = tb_find_pc(pc);<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; if (cpu != NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; env = cpu-&gt;env_ptr;<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif<BR>&nbsp;&nbsp;&nbsp; while (tb != NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; n = (uintptr_t)tb &amp; 3;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb = (TranslationBlock *)((uintptr_t)tb &amp; ~3);<BR>#ifdef TARGET_HAS_PRECISE_SMC<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (current_tb == tb &amp;&amp;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (current_tb-&gt;cflags &amp; CF_COUNT_MASK) != 1) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* If we are modifying the current TB, we must stop<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; its execution. We could be more precise by checking<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; that the modification is after the current PC, but it<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; would require a specialized function to partially<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; restore the CPU state */</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; current_tb_modified = 1;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_restore_state_from_tb(cpu, current_tb, pc);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_get_tb_cpu_state(env, &amp;current_pc, &amp;current_cs_base,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &amp;current_flags);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>#endif /* TARGET_HAS_PRECISE_SMC */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_phys_invalidate(tb, addr);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb = tb-&gt;page_next[n];<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; p-&gt;first_tb = NULL;<BR>#ifdef TARGET_HAS_PRECISE_SMC<BR>&nbsp;&nbsp;&nbsp; if (current_tb_modified) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* we generate a block containing just the instruction<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; modifying the memory. It will ensure that it cannot modify<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; itself */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu-&gt;current_tb = NULL;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_gen_code(cpu, current_pc, current_cs_base, current_flags, 1);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (locked) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mmap_unlock();<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_resume_from_signal(cpu, puc);<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif<BR>}<BR>#endif</P>
<P>/* add the tb in the target page and protect it if necessary<BR>&nbsp;*<BR>&nbsp;* Called with mmap_lock held for user-mode emulation.<BR>&nbsp;*/<BR>static inline void tb_alloc_page(TranslationBlock *tb,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; unsigned int n, tb_page_addr_t page_addr)<BR>{<BR>&nbsp;&nbsp;&nbsp; PageDesc *p;<BR>#ifndef CONFIG_USER_ONLY<BR>&nbsp;&nbsp;&nbsp; bool page_already_protected;<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; tb-&gt;page_addr[n] = page_addr;<BR>&nbsp;&nbsp;&nbsp; p = page_find_alloc(page_addr &gt;&gt; TARGET_PAGE_BITS, 1);<BR>&nbsp;&nbsp;&nbsp; tb-&gt;page_next[n] = p-&gt;first_tb;<BR>#ifndef CONFIG_USER_ONLY<BR>&nbsp;&nbsp;&nbsp; page_already_protected = p-&gt;first_tb != NULL;<BR>#endif<BR>&nbsp;&nbsp;&nbsp; p-&gt;first_tb = (TranslationBlock *)((uintptr_t)tb | n);<BR>&nbsp;&nbsp;&nbsp; invalidate_page_bitmap(p);</P>
<P>#if defined(CONFIG_USER_ONLY)<BR>&nbsp;&nbsp;&nbsp; if (p-&gt;flags &amp; PAGE_WRITE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; target_ulong addr;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PageDesc *p2;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int prot;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* force the host page as non writable (writes will have a<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; page fault + mprotect overhead) */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; page_addr &amp;= qemu_host_page_mask;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; prot = 0;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (addr = page_addr; addr &lt; page_addr + qemu_host_page_size;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addr += TARGET_PAGE_SIZE) {</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p2 = page_find(addr &gt;&gt; TARGET_PAGE_BITS);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!p2) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; continue;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; prot |= p2-&gt;flags;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p2-&gt;flags &amp;= ~PAGE_WRITE;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mprotect(g2h(page_addr), qemu_host_page_size,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (prot &amp; PAGE_BITS) &amp; ~PAGE_WRITE);<BR>#ifdef DEBUG_TB_INVALIDATE<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; printf("protecting code page: 0x" TARGET_FMT_lx "\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; page_addr);<BR>#endif<BR>&nbsp;&nbsp;&nbsp; }<BR>#else<BR>&nbsp;&nbsp;&nbsp; /* if some code is already present, then the pages are already<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; protected. So we handle the case where only the first TB is<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; allocated in a physical page */<BR>&nbsp;&nbsp;&nbsp; if (!page_already_protected) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tlb_protect_code(page_addr);<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif<BR>}</P>
<P>/* add a new TB and link it to the physical page tables. phys_page2 is<BR>&nbsp;* (-1) to indicate that only one page contains the TB.<BR>&nbsp;*<BR>&nbsp;* Called with mmap_lock held for user-mode emulation.<BR>&nbsp;*/<BR>static void tb_link_page(TranslationBlock *tb, tb_page_addr_t phys_pc,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_page_addr_t phys_page2)<BR>{<BR>&nbsp;&nbsp;&nbsp; unsigned int h;<BR>&nbsp;&nbsp;&nbsp; TranslationBlock **ptb;</P>
<P>&nbsp;&nbsp;&nbsp; /* add in the physical hash table */<BR>&nbsp;&nbsp;&nbsp; h = tb_phys_hash_func(phys_pc);<BR>&nbsp;&nbsp;&nbsp; ptb = &amp;tcg_ctx.tb_ctx.tb_phys_hash[h];<BR>&nbsp;&nbsp;&nbsp; tb-&gt;phys_hash_next = *ptb;<BR>&nbsp;&nbsp;&nbsp; *ptb = tb;</P>
<P>&nbsp;&nbsp;&nbsp; /* add in the page list */<BR>&nbsp;&nbsp;&nbsp; tb_alloc_page(tb, 0, phys_pc &amp; TARGET_PAGE_MASK);<BR>&nbsp;&nbsp;&nbsp; if (phys_page2 != -1) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_alloc_page(tb, 1, phys_page2);<BR>&nbsp;&nbsp;&nbsp; } else {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb-&gt;page_addr[1] = -1;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; tb-&gt;jmp_first = (TranslationBlock *)((uintptr_t)tb | 2);<BR>&nbsp;&nbsp;&nbsp; tb-&gt;jmp_next[0] = NULL;<BR>&nbsp;&nbsp;&nbsp; tb-&gt;jmp_next[1] = NULL;</P>
<P>&nbsp;&nbsp;&nbsp; /* init original jump addresses */<BR>&nbsp;&nbsp;&nbsp; if (tb-&gt;tb_next_offset[0] != 0xffff) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_reset_jump(tb, 0);<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; if (tb-&gt;tb_next_offset[1] != 0xffff) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_reset_jump(tb, 1);<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>#ifdef DEBUG_TB_CHECK<BR>&nbsp;&nbsp;&nbsp; tb_page_check();<BR>#endif<BR>}</P>
<P>/* find the TB 'tb' such that tb[0].tc_ptr &lt;= tc_ptr &lt;<BR>&nbsp;&nbsp; tb[1].tc_ptr. Return NULL if not found */<BR>static TranslationBlock *tb_find_pc(uintptr_t tc_ptr)<BR>{<BR>&nbsp;&nbsp;&nbsp; int m_min, m_max, m;<BR>&nbsp;&nbsp;&nbsp; uintptr_t v;<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb;</P>
<P>&nbsp;&nbsp;&nbsp; if (tcg_ctx.tb_ctx.nb_tbs &lt;= 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return NULL;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; if (tc_ptr &lt; (uintptr_t)tcg_ctx.code_gen_buffer ||<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tc_ptr &gt;= (uintptr_t)tcg_ctx.code_gen_ptr) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return NULL;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; /* binary search (cf Knuth) */<BR>&nbsp;&nbsp;&nbsp; m_min = 0;<BR>&nbsp;&nbsp;&nbsp; m_max = tcg_ctx.tb_ctx.nb_tbs - 1;<BR>&nbsp;&nbsp;&nbsp; while (m_min &lt;= m_max) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; m = (m_min + m_max) &gt;&gt; 1;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb = &amp;tcg_ctx.tb_ctx.tbs[m];<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; v = (uintptr_t)tb-&gt;tc_ptr;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (v == tc_ptr) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return tb;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } else if (tc_ptr &lt; v) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; m_max = m - 1;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; } else {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; m_min = m + 1;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; return &amp;tcg_ctx.tb_ctx.tbs[m_max];<BR>}</P>
<P>#if !defined(CONFIG_USER_ONLY)<BR>void tb_invalidate_phys_addr(AddressSpace *as, hwaddr addr)<BR>{<BR>&nbsp;&nbsp;&nbsp; ram_addr_t ram_addr;<BR>&nbsp;&nbsp;&nbsp; MemoryRegion *mr;<BR>&nbsp;&nbsp;&nbsp; hwaddr l = 1;</P>
<P>&nbsp;&nbsp;&nbsp; rcu_read_lock();<BR>&nbsp;&nbsp;&nbsp; mr = address_space_translate(as, addr, &amp;addr, &amp;l, false);<BR>&nbsp;&nbsp;&nbsp; if (!(memory_region_is_ram(mr)<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; || memory_region_is_romd(mr))) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rcu_read_unlock();<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; ram_addr = (memory_region_get_ram_addr(mr) &amp; TARGET_PAGE_MASK)<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + addr;<BR>&nbsp;&nbsp;&nbsp; tb_invalidate_phys_page_range(ram_addr, ram_addr + 1, 0);<BR>&nbsp;&nbsp;&nbsp; rcu_read_unlock();<BR>}<BR>#endif /* !defined(CONFIG_USER_ONLY) */</P>
<P>void tb_check_watchpoint(CPUState *cpu)<BR>{<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb;</P>
<P>&nbsp;&nbsp;&nbsp; tb = tb_find_pc(cpu-&gt;mem_io_pc);<BR>&nbsp;&nbsp;&nbsp; if (tb) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* We can use retranslation to find the PC.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_restore_state_from_tb(cpu, tb, cpu-&gt;mem_io_pc);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_phys_invalidate(tb, -1);<BR>&nbsp;&nbsp;&nbsp; } else {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* The exception probably happened in a helper.&nbsp; The CPU state should<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; have been saved before calling it. Fetch the PC from there.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CPUArchState *env = cpu-&gt;env_ptr;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; target_ulong pc, cs_base;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_page_addr_t addr;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int flags;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_get_tb_cpu_state(env, &amp;pc, &amp;cs_base, &amp;flags);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; addr = get_page_addr_code(env, pc);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_invalidate_phys_range(addr, addr + 1);<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>#ifndef CONFIG_USER_ONLY<BR>/* in deterministic execution mode, instructions doing device I/Os<BR>&nbsp;&nbsp; must be at the end of the TB */<BR>void cpu_io_recompile(CPUState *cpu, uintptr_t retaddr)<BR>{<BR>#if defined(TARGET_MIPS) || defined(TARGET_SH4)<BR>&nbsp;&nbsp;&nbsp; CPUArchState *env = cpu-&gt;env_ptr;<BR>#endif<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb;<BR>&nbsp;&nbsp;&nbsp; uint32_t n, cflags;<BR>&nbsp;&nbsp;&nbsp; target_ulong pc, cs_base;<BR>&nbsp;&nbsp;&nbsp; uint64_t flags;</P>
<P>&nbsp;&nbsp;&nbsp; tb = tb_find_pc(retaddr);<BR>&nbsp;&nbsp;&nbsp; if (!tb) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_abort(cpu, "cpu_io_recompile: could not find TB for pc=%p",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (void *)retaddr);<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; n = cpu-&gt;icount_decr.u16.low + tb-&gt;icount;<BR>&nbsp;&nbsp;&nbsp; cpu_restore_state_from_tb(cpu, tb, retaddr);<BR>&nbsp;&nbsp;&nbsp; /* Calculate how many instructions had been executed before the fault<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; occurred.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; n = n - cpu-&gt;icount_decr.u16.low;<BR>&nbsp;&nbsp;&nbsp; /* Generate a new TB ending on the I/O insn.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; n++;<BR>&nbsp;&nbsp;&nbsp; /* On MIPS and SH, delay slot instructions can only be restarted if<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; they were already the first instruction in the TB.&nbsp; If this is not<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; the first instruction in a TB then re-execute the preceding<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; branch.&nbsp; */<BR>#if defined(TARGET_MIPS)<BR>&nbsp;&nbsp;&nbsp; if ((env-&gt;hflags &amp; MIPS_HFLAG_BMASK) != 0 &amp;&amp; n &gt; 1) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; env-&gt;active_tc.PC -= (env-&gt;hflags &amp; MIPS_HFLAG_B16 ? 2 : 4);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu-&gt;icount_decr.u16.low++;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; env-&gt;hflags &amp;= ~MIPS_HFLAG_BMASK;<BR>&nbsp;&nbsp;&nbsp; }<BR>#elif defined(TARGET_SH4)<BR>&nbsp;&nbsp;&nbsp; if ((env-&gt;flags &amp; ((DELAY_SLOT | DELAY_SLOT_CONDITIONAL))) != 0<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &amp;&amp; n &gt; 1) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; env-&gt;pc -= 2;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu-&gt;icount_decr.u16.low++;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; env-&gt;flags &amp;= ~(DELAY_SLOT | DELAY_SLOT_CONDITIONAL);<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif<BR>&nbsp;&nbsp;&nbsp; /* This should never happen.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; if (n &gt; CF_COUNT_MASK) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cpu_abort(cpu, "TB too big during recompile");<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; cflags = n | CF_LAST_IO;<BR>&nbsp;&nbsp;&nbsp; pc = tb-&gt;pc;<BR>&nbsp;&nbsp;&nbsp; cs_base = tb-&gt;cs_base;<BR>&nbsp;&nbsp;&nbsp; flags = tb-&gt;flags;<BR>&nbsp;&nbsp;&nbsp; tb_phys_invalidate(tb, -1);<BR>&nbsp;&nbsp;&nbsp; if (tb-&gt;cflags &amp; CF_NOCACHE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (tb-&gt;orig_tb) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* Invalidate original TB if this TB was generated in<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; * cpu_exec_nocache() */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_phys_invalidate(tb-&gt;orig_tb, -1);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_free(tb);<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; /* FIXME: In theory this could raise an exception.&nbsp; In practice<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; we have already translated the block once so it's probably ok.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; tb_gen_code(cpu, pc, cs_base, flags, cflags);<BR>&nbsp;&nbsp;&nbsp; /* TODO: If env-&gt;pc != tb-&gt;pc (i.e. the faulting instruction was not<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; the first in the TB) then we end up generating a whole new TB and<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; repeating the fault, which is horribly inefficient.<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Better would be to execute just this insn uncached, or generate a<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; second new TB.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; cpu_resume_from_signal(cpu, NULL);<BR>}</P>
<P>void tb_flush_jmp_cache(CPUState *cpu, target_ulong addr)<BR>{<BR>&nbsp;&nbsp;&nbsp; unsigned int i;</P>
<P>&nbsp;&nbsp;&nbsp; /* Discard jump cache entries for any tb which might potentially<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; overlap the flushed page.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; i = tb_jmp_cache_hash_page(addr - TARGET_PAGE_SIZE);<BR>&nbsp;&nbsp;&nbsp; memset(&amp;cpu-&gt;tb_jmp_cache[i], 0,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; TB_JMP_PAGE_SIZE * sizeof(TranslationBlock *));</P>
<P>&nbsp;&nbsp;&nbsp; i = tb_jmp_cache_hash_page(addr);<BR>&nbsp;&nbsp;&nbsp; memset(&amp;cpu-&gt;tb_jmp_cache[i], 0,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; TB_JMP_PAGE_SIZE * sizeof(TranslationBlock *));<BR>}</P>
<P>void dump_exec_info(FILE *f, fprintf_function cpu_fprintf)<BR>{<BR>&nbsp;&nbsp;&nbsp; int i, target_code_size, max_target_code_size;<BR>&nbsp;&nbsp;&nbsp; int direct_jmp_count, direct_jmp2_count, cross_page;<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb;</P>
<P>&nbsp;&nbsp;&nbsp; target_code_size = 0;<BR>&nbsp;&nbsp;&nbsp; max_target_code_size = 0;<BR>&nbsp;&nbsp;&nbsp; cross_page = 0;<BR>&nbsp;&nbsp;&nbsp; direct_jmp_count = 0;<BR>&nbsp;&nbsp;&nbsp; direct_jmp2_count = 0;<BR>&nbsp;&nbsp;&nbsp; for (i = 0; i &lt; tcg_ctx.tb_ctx.nb_tbs; i++) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb = &amp;tcg_ctx.tb_ctx.tbs[i];<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; target_code_size += tb-&gt;size;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (tb-&gt;size &gt; max_target_code_size) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; max_target_code_size = tb-&gt;size;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (tb-&gt;page_addr[1] != -1) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cross_page++;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (tb-&gt;tb_next_offset[0] != 0xffff) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; direct_jmp_count++;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (tb-&gt;tb_next_offset[1] != 0xffff) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; direct_jmp2_count++;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; /* XXX: avoid using doubles ? */<BR>&nbsp;&nbsp;&nbsp; cpu_fprintf(f, "Translation buffer state:\n");<BR>&nbsp;&nbsp;&nbsp; cpu_fprintf(f, "gen code size&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; %td/%zd\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_ptr - tcg_ctx.code_gen_buffer,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_highwater - tcg_ctx.code_gen_buffer);<BR>&nbsp;&nbsp;&nbsp; cpu_fprintf(f, "TB count&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; %d/%d\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs, tcg_ctx.code_gen_max_blocks);<BR>&nbsp;&nbsp;&nbsp; cpu_fprintf(f, "TB avg target size&nbsp; %d max=%d bytes\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs ? target_code_size /<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs : 0,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; max_target_code_size);<BR>&nbsp;&nbsp;&nbsp; cpu_fprintf(f, "TB avg host size&nbsp;&nbsp;&nbsp; %td bytes (expansion ratio: %0.1f)\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs ? (tcg_ctx.code_gen_ptr -<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_buffer) /<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs : 0,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; target_code_size ? (double) (tcg_ctx.code_gen_ptr -<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_buffer) /<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; target_code_size : 0);<BR>&nbsp;&nbsp;&nbsp; cpu_fprintf(f, "cross page TB count %d (%d%%)\n", cross_page,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs ? (cross_page * 100) /<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs : 0);<BR>&nbsp;&nbsp;&nbsp; cpu_fprintf(f, "direct jump count&nbsp;&nbsp; %d (%d%%) (2 jumps=%d %d%%)\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; direct_jmp_count,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs ? (direct_jmp_count * 100) /<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs : 0,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; direct_jmp2_count,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs ? (direct_jmp2_count * 100) /<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.nb_tbs : 0);<BR>&nbsp;&nbsp;&nbsp; cpu_fprintf(f, "\nStatistics:\n");<BR>&nbsp;&nbsp;&nbsp; cpu_fprintf(f, "TB flush count&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; %d\n", tcg_ctx.tb_ctx.tb_flush_count);<BR>&nbsp;&nbsp;&nbsp; cpu_fprintf(f, "TB invalidate count %d\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.tb_phys_invalidate_count);<BR>&nbsp;&nbsp;&nbsp; cpu_fprintf(f, "TLB flush count&nbsp;&nbsp;&nbsp;&nbsp; %d\n", tlb_flush_count);<BR>&nbsp;&nbsp;&nbsp; tcg_dump_info(f, cpu_fprintf);<BR>}</P>
<P>void dump_opcount_info(FILE *f, fprintf_function cpu_fprintf)<BR>{<BR>&nbsp;&nbsp;&nbsp; tcg_dump_op_count(f, cpu_fprintf);<BR>}</P>
<P>#else /* CONFIG_USER_ONLY */</P>
<P>void cpu_interrupt(CPUState *cpu, int mask)<BR>{<BR>&nbsp;&nbsp;&nbsp; cpu-&gt;interrupt_request |= mask;<BR>&nbsp;&nbsp;&nbsp; cpu-&gt;tcg_exit_req = 1;<BR>}</P>
<P>/*<BR>&nbsp;* Walks guest process memory "regions" one by one<BR>&nbsp;* and calls callback function 'fn' for each region.<BR>&nbsp;*/<BR>struct walk_memory_regions_data {<BR>&nbsp;&nbsp;&nbsp; walk_memory_regions_fn fn;<BR>&nbsp;&nbsp;&nbsp; void *priv;<BR>&nbsp;&nbsp;&nbsp; target_ulong start;<BR>&nbsp;&nbsp;&nbsp; int prot;<BR>};</P>
<P>static int walk_memory_regions_end(struct walk_memory_regions_data *data,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; target_ulong end, int new_prot)<BR>{<BR>&nbsp;&nbsp;&nbsp; if (data-&gt;start != -1u) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int rc = data-&gt;fn(data-&gt;priv, data-&gt;start, end, data-&gt;prot);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (rc != 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return rc;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; data-&gt;start = (new_prot ? end : -1u);<BR>&nbsp;&nbsp;&nbsp; data-&gt;prot = new_prot;</P>
<P>&nbsp;&nbsp;&nbsp; return 0;<BR>}</P>
<P>static int walk_memory_regions_1(struct walk_memory_regions_data *data,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; target_ulong base, int level, void **lp)<BR>{<BR>&nbsp;&nbsp;&nbsp; target_ulong pa;<BR>&nbsp;&nbsp;&nbsp; int i, rc;</P>
<P>&nbsp;&nbsp;&nbsp; if (*lp == NULL) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return walk_memory_regions_end(data, base, 0);<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; if (level == 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PageDesc *pd = *lp;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (i = 0; i &lt; V_L2_SIZE; ++i) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int prot = pd[i].flags;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pa = base | (i &lt;&lt; TARGET_PAGE_BITS);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (prot != data-&gt;prot) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rc = walk_memory_regions_end(data, pa, prot);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (rc != 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return rc;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; } else {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; void **pp = *lp;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (i = 0; i &lt; V_L2_SIZE; ++i) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pa = base | ((target_ulong)i &lt;&lt;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (TARGET_PAGE_BITS + V_L2_BITS * level));<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; rc = walk_memory_regions_1(data, pa, level - 1, pp + i);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (rc != 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return rc;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; return 0;<BR>}</P>
<P>int walk_memory_regions(void *priv, walk_memory_regions_fn fn)<BR>{<BR>&nbsp;&nbsp;&nbsp; struct walk_memory_regions_data data;<BR>&nbsp;&nbsp;&nbsp; uintptr_t i;</P>
<P>&nbsp;&nbsp;&nbsp; data.fn = fn;<BR>&nbsp;&nbsp;&nbsp; data.priv = priv;<BR>&nbsp;&nbsp;&nbsp; data.start = -1u;<BR>&nbsp;&nbsp;&nbsp; data.prot = 0;</P>
<P>&nbsp;&nbsp;&nbsp; for (i = 0; i &lt; V_L1_SIZE; i++) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int rc = walk_memory_regions_1(&amp;data, (target_ulong)i &lt;&lt; (V_L1_SHIFT + TARGET_PAGE_BITS),<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; V_L1_SHIFT / V_L2_BITS - 1, l1_map + i);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (rc != 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return rc;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; return walk_memory_regions_end(&amp;data, 0, 0);<BR>}</P>
<P>static int dump_region(void *priv, target_ulong start,<BR>&nbsp;&nbsp;&nbsp; target_ulong end, unsigned long prot)<BR>{<BR>&nbsp;&nbsp;&nbsp; FILE *f = (FILE *)priv;</P>
<P>&nbsp;&nbsp;&nbsp; (void) fprintf(f, TARGET_FMT_lx"-"TARGET_FMT_lx<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; " "TARGET_FMT_lx" %c%c%c\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; start, end, end - start,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ((prot &amp; PAGE_READ) ? 'r' : '-'),<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ((prot &amp; PAGE_WRITE) ? 'w' : '-'),<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ((prot &amp; PAGE_EXEC) ? 'x' : '-'));</P>
<P>&nbsp;&nbsp;&nbsp; return 0;<BR>}</P>
<P>/* dump memory mappings */<BR>void page_dump(FILE *f)<BR>{<BR>&nbsp;&nbsp;&nbsp; const int length = sizeof(target_ulong) * 2;<BR>&nbsp;&nbsp;&nbsp; (void) fprintf(f, "%-*s %-*s %-*s %s\n",<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; length, "start", length, "end", length, "size", "prot");<BR>&nbsp;&nbsp;&nbsp; walk_memory_regions(f, dump_region);<BR>}</P>
<P>int page_get_flags(target_ulong address)<BR>{<BR>&nbsp;&nbsp;&nbsp; PageDesc *p;</P>
<P>&nbsp;&nbsp;&nbsp; p = page_find(address &gt;&gt; TARGET_PAGE_BITS);<BR>&nbsp;&nbsp;&nbsp; if (!p) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return 0;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; return p-&gt;flags;<BR>}</P>
<P>/* Modify the flags of a page and invalidate the code if necessary.<BR>&nbsp;&nbsp; The flag PAGE_WRITE_ORG is positioned automatically depending<BR>&nbsp;&nbsp; on PAGE_WRITE.&nbsp; The mmap_lock should already be held.&nbsp; */<BR>void page_set_flags(target_ulong start, target_ulong end, int flags)<BR>{<BR>&nbsp;&nbsp;&nbsp; target_ulong addr, len;</P>
<P>&nbsp;&nbsp;&nbsp; /* This function should never be called with addresses outside the<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; guest address space.&nbsp; If this assert fires, it probably indicates<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a missing call to h2g_valid.&nbsp; */<BR>#if TARGET_ABI_BITS &gt; L1_MAP_ADDR_SPACE_BITS<BR>&nbsp;&nbsp;&nbsp; assert(end &lt; ((target_ulong)1 &lt;&lt; L1_MAP_ADDR_SPACE_BITS));<BR>#endif<BR>&nbsp;&nbsp;&nbsp; assert(start &lt; end);</P>
<P>&nbsp;&nbsp;&nbsp; start = start &amp; TARGET_PAGE_MASK;<BR>&nbsp;&nbsp;&nbsp; end = TARGET_PAGE_ALIGN(end);</P>
<P>&nbsp;&nbsp;&nbsp; if (flags &amp; PAGE_WRITE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; flags |= PAGE_WRITE_ORG;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; for (addr = start, len = end - start;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; len != 0;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; len -= TARGET_PAGE_SIZE, addr += TARGET_PAGE_SIZE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PageDesc *p = page_find_alloc(addr &gt;&gt; TARGET_PAGE_BITS, 1);</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* If the write protection bit is set, then we invalidate<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; the code inside.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!(p-&gt;flags &amp; PAGE_WRITE) &amp;&amp;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; (flags &amp; PAGE_WRITE) &amp;&amp;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p-&gt;first_tb) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_invalidate_phys_page(addr, 0, NULL, false);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p-&gt;flags = flags;<BR>&nbsp;&nbsp;&nbsp; }<BR>}</P>
<P>int page_check_range(target_ulong start, target_ulong len, int flags)<BR>{<BR>&nbsp;&nbsp;&nbsp; PageDesc *p;<BR>&nbsp;&nbsp;&nbsp; target_ulong end;<BR>&nbsp;&nbsp;&nbsp; target_ulong addr;</P>
<P>&nbsp;&nbsp;&nbsp; /* This function should never be called with addresses outside the<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; guest address space.&nbsp; If this assert fires, it probably indicates<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a missing call to h2g_valid.&nbsp; */<BR>#if TARGET_ABI_BITS &gt; L1_MAP_ADDR_SPACE_BITS<BR>&nbsp;&nbsp;&nbsp; assert(start &lt; ((target_ulong)1 &lt;&lt; L1_MAP_ADDR_SPACE_BITS));<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; if (len == 0) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return 0;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; if (start + len - 1 &lt; start) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* We've wrapped around.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return -1;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; /* must do before we loose bits in the next step */<BR>&nbsp;&nbsp;&nbsp; end = TARGET_PAGE_ALIGN(start + len);<BR>&nbsp;&nbsp;&nbsp; start = start &amp; TARGET_PAGE_MASK;</P>
<P>&nbsp;&nbsp;&nbsp; for (addr = start, len = end - start;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; len != 0;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; len -= TARGET_PAGE_SIZE, addr += TARGET_PAGE_SIZE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p = page_find(addr &gt;&gt; TARGET_PAGE_BITS);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!p) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return -1;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!(p-&gt;flags &amp; PAGE_VALID)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return -1;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if ((flags &amp; PAGE_READ) &amp;&amp; !(p-&gt;flags &amp; PAGE_READ)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return -1;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (flags &amp; PAGE_WRITE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!(p-&gt;flags &amp; PAGE_WRITE_ORG)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return -1;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* unprotect the page if it was put read-only because it<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; contains translated code */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!(p-&gt;flags &amp; PAGE_WRITE)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (!page_unprotect(addr, 0, NULL)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return -1;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; return 0;<BR>}</P>
<P>/* called from signal handler: invalidate the code and unprotect the<BR>&nbsp;&nbsp; page. Return TRUE if the fault was successfully handled. */<BR>int page_unprotect(target_ulong address, uintptr_t pc, void *puc)<BR>{<BR>&nbsp;&nbsp;&nbsp; unsigned int prot;<BR>&nbsp;&nbsp;&nbsp; PageDesc *p;<BR>&nbsp;&nbsp;&nbsp; target_ulong host_start, host_end, addr;</P>
<P>&nbsp;&nbsp;&nbsp; /* Technically this isn't safe inside a signal handler.&nbsp; However we<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; know this only ever happens in a synchronous SEGV handler, so in<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; practice it seems to be ok.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; mmap_lock();</P>
<P>&nbsp;&nbsp;&nbsp; p = page_find(address &gt;&gt; TARGET_PAGE_BITS);<BR>&nbsp;&nbsp;&nbsp; if (!p) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mmap_unlock();<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return 0;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; /* if the page was really writable, then we change its<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; protection back to writable */<BR>&nbsp;&nbsp;&nbsp; if ((p-&gt;flags &amp; PAGE_WRITE_ORG) &amp;&amp; !(p-&gt;flags &amp; PAGE_WRITE)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; host_start = address &amp; qemu_host_page_mask;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; host_end = host_start + qemu_host_page_size;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; prot = 0;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; for (addr = host_start ; addr &lt; host_end ; addr += TARGET_PAGE_SIZE) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p = page_find(addr &gt;&gt; TARGET_PAGE_BITS);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; p-&gt;flags |= PAGE_WRITE;<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; prot |= p-&gt;flags;</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* and since the content will be modified, we must invalidate<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; the corresponding translated code. */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_invalidate_phys_page(addr, pc, puc, true);<BR>#ifdef DEBUG_TB_CHECK<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_invalidate_check(addr);<BR>#endif<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mprotect((void *)g2h(host_start), qemu_host_page_size,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; prot &amp; PAGE_BITS);</P>
<P>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mmap_unlock();<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return 1;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; mmap_unlock();<BR>&nbsp;&nbsp;&nbsp; return 0;<BR>}<BR>#endif /* CONFIG_USER_ONLY */