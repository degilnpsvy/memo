/* Called with mmap_lock held for user mode emulation.&nbsp; */<BR>TranslationBlock *tb_gen_code(CPUState *cpu,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; target_ulong pc, target_ulong cs_base,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; int flags, int cflags)<BR>{<BR>&nbsp;&nbsp;&nbsp; CPUArchState *env = cpu-&gt;env_ptr;<BR>&nbsp;&nbsp;&nbsp; TranslationBlock *tb;<BR>&nbsp;&nbsp;&nbsp; tb_page_addr_t phys_pc, phys_page2;<BR>&nbsp;&nbsp;&nbsp; target_ulong virt_page2;<BR>&nbsp;&nbsp;&nbsp; tcg_insn_unit *gen_code_buf;<BR>&nbsp;&nbsp;&nbsp; int gen_code_size, search_size;<BR>#ifdef CONFIG_PROFILER<BR>&nbsp;&nbsp;&nbsp; int64_t ti;<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; phys_pc = get_page_addr_code(env, pc);<BR>&nbsp;&nbsp;&nbsp; if (use_icount &amp;&amp; !(cflags &amp; CF_IGNORE_ICOUNT)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cflags |= CF_USE_ICOUNT;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; tb = tb_alloc(pc);<BR>&nbsp;&nbsp;&nbsp; if (unlikely(!tb)) {<BR>&nbsp;buffer_overflow:<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* flush must be done */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb_flush(cpu);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* cannot fail at this point */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tb = tb_alloc(pc);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; assert(tb != NULL);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; /* Don't forget to invalidate previous TB info.&nbsp; */<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tcg_ctx.tb_ctx.tb_invalidated_flag = 1;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>&nbsp;&nbsp;&nbsp; gen_code_buf = tcg_ctx.code_gen_ptr;<BR>&nbsp;&nbsp;&nbsp; tb-&gt;tc_ptr = gen_code_buf;<BR>&nbsp;&nbsp;&nbsp; tb-&gt;cs_base = cs_base;<BR>&nbsp;&nbsp;&nbsp; tb-&gt;flags = flags;<BR>&nbsp;&nbsp;&nbsp; tb-&gt;cflags = cflags;</P>
<P>#ifdef CONFIG_PROFILER<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_count1++; /* includes aborted translations because of<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; exceptions */<BR>&nbsp;&nbsp;&nbsp; ti = profile_getclock();<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; tcg_func_start(&amp;tcg_ctx);</P>
<P>&nbsp;&nbsp;&nbsp; gen_intermediate_code(env, tb);</P>
<P>&nbsp;&nbsp;&nbsp; trace_translate_block(tb, tb-&gt;pc, tb-&gt;tc_ptr);</P>
<P>&nbsp;&nbsp;&nbsp; /* generate machine code */<BR>&nbsp;&nbsp;&nbsp; tb-&gt;tb_next_offset[0] = 0xffff;<BR>&nbsp;&nbsp;&nbsp; tb-&gt;tb_next_offset[1] = 0xffff;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_next_offset = tb-&gt;tb_next_offset;<BR>#ifdef USE_DIRECT_JUMP<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_jmp_offset = tb-&gt;tb_jmp_offset;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_next = NULL;<BR>#else<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_jmp_offset = NULL;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_next = tb-&gt;tb_next;<BR>#endif</P>
<P>#ifdef CONFIG_PROFILER<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.tb_count++;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.interm_time += profile_getclock() - ti;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_time -= profile_getclock();<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; /* ??? Overflow could be handled better here.&nbsp; In particular, we<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; don't need to re-do gen_intermediate_code, nor should we re-do<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; the tcg optimization currently hidden inside tcg_gen_code.&nbsp; All<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; that should be required is to flush the TBs, allocate a new TB,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; re-initialize it per above, and re-do the actual code generation.&nbsp; */<BR>&nbsp;&nbsp;&nbsp; gen_code_size = tcg_gen_code(&amp;tcg_ctx, gen_code_buf);<BR>&nbsp;&nbsp;&nbsp; if (unlikely(gen_code_size &lt; 0)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; goto buffer_overflow;<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; search_size = encode_search(tb, (void *)gen_code_buf + gen_code_size);<BR>&nbsp;&nbsp;&nbsp; if (unlikely(search_size &lt; 0)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; goto buffer_overflow;<BR>&nbsp;&nbsp;&nbsp; }</P>
<P>#ifdef CONFIG_PROFILER<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_time += profile_getclock();<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_in_len += tb-&gt;size;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.code_out_len += gen_code_size;<BR>&nbsp;&nbsp;&nbsp; tcg_ctx.search_out_len += search_size;<BR>#endif</P>
<P>#ifdef DEBUG_DISAS<BR>&nbsp;&nbsp;&nbsp; if (qemu_loglevel_mask(CPU_LOG_TB_OUT_ASM)) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; qemu_log("OUT: [size=%d]\n", gen_code_size);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; log_disas(tb-&gt;tc_ptr, gen_code_size);<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; qemu_log("\n");<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; qemu_log_flush();<BR>&nbsp;&nbsp;&nbsp; }<BR>#endif</P>
<P>&nbsp;&nbsp;&nbsp; tcg_ctx.code_gen_ptr = (void *)<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ROUND_UP((uintptr_t)gen_code_buf + gen_code_size + search_size,<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CODE_GEN_ALIGN);</P>
<P>&nbsp;&nbsp;&nbsp; /* check next page if needed */<BR>&nbsp;&nbsp;&nbsp; virt_page2 = (pc + tb-&gt;size - 1) &amp; TARGET_PAGE_MASK;<BR>&nbsp;&nbsp;&nbsp; phys_page2 = -1;<BR>&nbsp;&nbsp;&nbsp; if ((pc &amp; TARGET_PAGE_MASK) != virt_page2) {<BR>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; phys_page2 = get_page_addr_code(env, virt_page2);<BR>&nbsp;&nbsp;&nbsp; }<BR>&nbsp;&nbsp;&nbsp; tb_link_page(tb, phys_pc, phys_page2);<BR>&nbsp;&nbsp;&nbsp; return tb;<BR>}