Linux 4.6 include/linux/compiler.h 
<P></P>
<P>#ifndef __LINUX_COMPILER_H<BR>#define __LINUX_COMPILER_H</P>
<P></P>
<P>#ifndef __ASSEMBLY__</P>
<P><FONT class=extract>#ifdef __CHECKER__<BR># define __user&nbsp;&nbsp;__attribute__((noderef, address_space(1)))<BR># define __kernel&nbsp;__attribute__((address_space(0)))<BR># define __safe&nbsp;&nbsp;__attribute__((safe))<BR># define __force&nbsp;__attribute__((force))<BR># define __nocast&nbsp;__attribute__((nocast))<BR># define __iomem&nbsp;__attribute__((noderef, address_space(2)))<BR># define __must_hold(x)&nbsp;__attribute__((context(x,1,1)))<BR># define __acquires(x)&nbsp;__attribute__((context(x,0,1)))<BR># define __releases(x)&nbsp;__attribute__((context(x,1,0)))<BR># define __acquire(x)&nbsp;__context__(x,1)<BR># define __release(x)&nbsp;__context__(x,-1)<BR># define __cond_lock(x,c)&nbsp;((c) ? ({ __acquire(x); 1; }) : 0)<BR># define __percpu&nbsp;__attribute__((noderef, address_space(3)))<BR># define __pmem&nbsp;&nbsp;__attribute__((noderef, address_space(5)))<BR>#ifdef CONFIG_SPARSE_RCU_POINTER<BR># define __rcu&nbsp;&nbsp;__attribute__((noderef, address_space(4)))<BR>#else /* CONFIG_SPARSE_RCU_POINTER */<BR># define __rcu<BR>#endif /* CONFIG_SPARSE_RCU_POINTER */<BR># define __private&nbsp;__attribute__((noderef))<BR>extern void __chk_user_ptr(const volatile void __user *);<BR>extern void __chk_io_ptr(const volatile void __iomem *);<BR># define ACCESS_PRIVATE(p, member) (*((typeof((p)-&gt;member) __force *) &amp;(p)-&gt;member))<BR>#else /* __CHECKER__ */<BR># define __user<BR># define __kernel<BR># define __safe<BR># define __force<BR># define __nocast<BR># define __iomem<BR># define __chk_user_ptr(x) (void)0<BR># define __chk_io_ptr(x) (void)0<BR># define __builtin_warning(x, y...) (1)<BR># define __must_hold(x)<BR># define __acquires(x)<BR># define __releases(x)<BR># define __acquire(x) (void)0<BR># define __release(x) (void)0<BR># define __cond_lock(x,c) (c)<BR># define __percpu<BR># define __rcu<BR># define __pmem<BR># define __private<BR># define ACCESS_PRIVATE(p, member) ((p)-&gt;member)<BR>#endif /* __CHECKER__ */</FONT></P>
<P>/* Indirect macros required for expanded argument pasting, eg. __LINE__. */<BR>#define ___PASTE(a,b) a##b<BR>#define __PASTE(a,b) ___PASTE(a,b)</P>
<P>#ifdef __KERNEL__</P>
<P>#ifdef __GNUC__<BR>#include &lt;linux/compiler-gcc.h&gt;<BR>#endif</P>
<P>#if defined(CC_USING_HOTPATCH) &amp;&amp; !defined(__CHECKER__)<BR>#define notrace __attribute__((hotpatch(0,0)))<BR>#else<BR>#define notrace __attribute__((no_instrument_function))<BR>#endif</P>
<P>/* Intel compiler defines __GNUC__. So we will overwrite implementations<BR>&nbsp;* coming from above header files here<BR>&nbsp;*/<BR>#ifdef __INTEL_COMPILER<BR># include &lt;linux/compiler-intel.h&gt;<BR>#endif</P>
<P>/* Clang compiler defines __GNUC__. So we will overwrite implementations<BR>&nbsp;* coming from above header files here<BR>&nbsp;*/<BR>#ifdef __clang__<BR>#include &lt;linux/compiler-clang.h&gt;<BR>#endif</P>
<P>/*<BR>&nbsp;* Generic compiler-dependent macros required for kernel<BR>&nbsp;* build go below this comment. Actual compiler/compiler version<BR>&nbsp;* specific implementations come from the above header files<BR>&nbsp;*/</P>
<P>struct ftrace_branch_data {<BR>&nbsp;const char *func;<BR>&nbsp;const char *file;<BR>&nbsp;unsigned line;<BR>&nbsp;union {<BR>&nbsp;&nbsp;struct {<BR>&nbsp;&nbsp;&nbsp;unsigned long correct;<BR>&nbsp;&nbsp;&nbsp;unsigned long incorrect;<BR>&nbsp;&nbsp;};<BR>&nbsp;&nbsp;struct {<BR>&nbsp;&nbsp;&nbsp;unsigned long miss;<BR>&nbsp;&nbsp;&nbsp;unsigned long hit;<BR>&nbsp;&nbsp;};<BR>&nbsp;&nbsp;unsigned long miss_hit[2];<BR>&nbsp;};<BR>};</P>
<P>/*<BR>&nbsp;* Note: DISABLE_BRANCH_PROFILING can be used by special lowlevel code<BR>&nbsp;* to disable branch tracing on a per file basis.<BR>&nbsp;*/<BR>#if defined(CONFIG_TRACE_BRANCH_PROFILING) \<BR>&nbsp;&nbsp;&nbsp; &amp;&amp; !defined(DISABLE_BRANCH_PROFILING) &amp;&amp; !defined(__CHECKER__)<BR>void ftrace_likely_update(struct ftrace_branch_data *f, int val, int expect);</P>
<P>#define likely_notrace(x)&nbsp;__builtin_expect(!!(x), 1)<BR>#define unlikely_notrace(x)&nbsp;__builtin_expect(!!(x), 0)</P>
<P>#define __branch_check__(x, expect) ({&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;int ______r;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;static struct ftrace_branch_data&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;__attribute__((__aligned__(4)))&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;__attribute__((section("_ftrace_annotated_branch"))) \<BR>&nbsp;&nbsp;&nbsp;&nbsp;______f = {&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;.func = __func__,&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;.file = __FILE__,&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;.line = __LINE__,&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;};&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;______r = likely_notrace(x);&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;ftrace_likely_update(&amp;______f, ______r, expect); \<BR>&nbsp;&nbsp;&nbsp;______r;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;})</P>
<P>/*<BR>&nbsp;* Using __builtin_constant_p(x) to ignore cases where the return<BR>&nbsp;* value is always the same.&nbsp; This idea is taken from a similar patch<BR>&nbsp;* written by Daniel Walker.<BR>&nbsp;*/<BR># ifndef likely<BR>#&nbsp; define likely(x)&nbsp;(__builtin_constant_p(x) ? !!(x) : __branch_check__(x, 1))<BR># endif<BR># ifndef unlikely<BR>#&nbsp; define unlikely(x)&nbsp;(__builtin_constant_p(x) ? !!(x) : __branch_check__(x, 0))<BR># endif</P>
<P>#ifdef CONFIG_PROFILE_ALL_BRANCHES<BR>/*<BR>&nbsp;* "Define 'is'", Bill Clinton<BR>&nbsp;* "Define 'if'", Steven Rostedt<BR>&nbsp;*/<BR>#define if(cond, ...) __trace_if( (cond , ## __VA_ARGS__) )<BR>#define __trace_if(cond) \<BR>&nbsp;if (__builtin_constant_p(!!(cond)) ? !!(cond) :&nbsp;&nbsp;&nbsp;\<BR>&nbsp;({&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;int ______r;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;static struct ftrace_branch_data&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;__attribute__((__aligned__(4)))&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;__attribute__((section("_ftrace_branch")))&nbsp;\<BR>&nbsp;&nbsp;&nbsp;______f = {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;.func = __func__,&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;.file = __FILE__,&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp;.line = __LINE__,&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;};&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;______r = !!(cond);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;______f.miss_hit[______r]++;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;______r;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;}))<BR>#endif /* CONFIG_PROFILE_ALL_BRANCHES */</P>
<P>#else<BR># define likely(x)&nbsp;__builtin_expect(!!(x), 1)<BR># define unlikely(x)&nbsp;__builtin_expect(!!(x), 0)<BR>#endif</P>
<P>/* Optimization barrier */<BR>#ifndef barrier<BR># define barrier() __memory_barrier()<BR>#endif</P>
<P>#ifndef barrier_data<BR># define barrier_data(ptr) barrier()<BR>#endif</P>
<P>/* Unreachable code */<BR>#ifndef unreachable<BR># define unreachable() do { } while (1)<BR>#endif</P>
<P>#ifndef RELOC_HIDE<BR># define RELOC_HIDE(ptr, off)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp; ({ unsigned long __ptr;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;&nbsp; __ptr = (unsigned long) (ptr);&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp; (typeof(ptr)) (__ptr + (off)); })<BR>#endif</P>
<P>#ifndef OPTIMIZER_HIDE_VAR<BR>#define OPTIMIZER_HIDE_VAR(var) barrier()<BR>#endif</P>
<P>/* Not-quite-unique ID. */<BR>#ifndef __UNIQUE_ID<BR># define __UNIQUE_ID(prefix) __PASTE(__PASTE(__UNIQUE_ID_, prefix), __LINE__)<BR>#endif</P>
<P>#include &lt;uapi/linux/types.h&gt;</P>
<P>#define __READ_ONCE_SIZE&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>({&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;switch (size) {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;case 1: *(__u8 *)res = *(volatile __u8 *)p; break;&nbsp;&nbsp;\<BR>&nbsp;case 2: *(__u16 *)res = *(volatile __u16 *)p; break;&nbsp;&nbsp;\<BR>&nbsp;case 4: *(__u32 *)res = *(volatile __u32 *)p; break;&nbsp;&nbsp;\<BR>&nbsp;case 8: *(__u64 *)res = *(volatile __u64 *)p; break;&nbsp;&nbsp;\<BR>&nbsp;default:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;barrier();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;__builtin_memcpy((void *)res, (const void *)p, size);&nbsp;\<BR>&nbsp;&nbsp;barrier();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;}&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>})</P>
<P>static __always_inline<BR>void __read_once_size(const volatile void *p, void *res, int size)<BR>{<BR>&nbsp;__READ_ONCE_SIZE;<BR>}</P>
<P>#ifdef CONFIG_KASAN<BR>/*<BR>&nbsp;* This function is not 'inline' because __no_sanitize_address confilcts<BR>&nbsp;* with inlining. Attempt to inline it may cause a build failure.<BR>&nbsp;* &nbsp;<A href="https://gcc.gnu.org/bugzilla/show_bug.cgi?id=67368">https://gcc.gnu.org/bugzilla/show_bug.cgi?id=67368</A><BR>&nbsp;* '__maybe_unused' allows us to avoid defined-but-not-used warnings.<BR>&nbsp;*/<BR>static __no_sanitize_address __maybe_unused<BR>void __read_once_size_nocheck(const volatile void *p, void *res, int size)<BR>{<BR>&nbsp;__READ_ONCE_SIZE;<BR>}<BR>#else<BR>static __always_inline<BR>void __read_once_size_nocheck(const volatile void *p, void *res, int size)<BR>{<BR>&nbsp;__READ_ONCE_SIZE;<BR>}<BR>#endif</P>
<P>static __always_inline void __write_once_size(volatile void *p, void *res, int size)<BR>{<BR>&nbsp;switch (size) {<BR>&nbsp;case 1: *(volatile __u8 *)p = *(__u8 *)res; break;<BR>&nbsp;case 2: *(volatile __u16 *)p = *(__u16 *)res; break;<BR>&nbsp;case 4: *(volatile __u32 *)p = *(__u32 *)res; break;<BR>&nbsp;case 8: *(volatile __u64 *)p = *(__u64 *)res; break;<BR>&nbsp;default:<BR>&nbsp;&nbsp;barrier();<BR>&nbsp;&nbsp;__builtin_memcpy((void *)p, (const void *)res, size);<BR>&nbsp;&nbsp;barrier();<BR>&nbsp;}<BR>}</P>
<P><FONT class=extract>/*<BR>&nbsp;* Prevent the compiler from merging or refetching reads or writes. The<BR>&nbsp;* compiler is also forbidden from reordering successive instances of<BR>&nbsp;* READ_ONCE, WRITE_ONCE and ACCESS_ONCE (see below), but only when the<BR>&nbsp;* compiler is aware of some particular ordering.&nbsp; One way to make the<BR>&nbsp;* compiler aware of ordering is to put the two invocations of READ_ONCE,<BR>&nbsp;* WRITE_ONCE or ACCESS_ONCE() in different C statements.<BR>&nbsp;*<BR>&nbsp;* In contrast to ACCESS_ONCE these two macros will also work on aggregate<BR>&nbsp;* data types like structs or unions. If the size of the accessed data<BR>&nbsp;* type exceeds the word size of the machine (e.g., 32 bits or 64 bits)<BR>&nbsp;* READ_ONCE() and WRITE_ONCE() will fall back to memcpy(). There's at<BR>&nbsp;* least two memcpy()s: one for the __builtin_memcpy() and then one for<BR>&nbsp;* the macro doing the copy of variable - '__u' allocated on the stack.<BR>&nbsp;*<BR>&nbsp;* Their two major use cases are: (1) Mediating communication between<BR>&nbsp;* process-level code and irq/NMI handlers, all running on the same CPU,<BR>&nbsp;* and (2) Ensuring that the compiler does not&nbsp; fold, spindle, or otherwise<BR>&nbsp;* mutilate accesses that either do not require ordering or that interact<BR>&nbsp;* with an explicit memory barrier or atomic instruction that provides the<BR>&nbsp;* required ordering.<BR>&nbsp;*/</FONT></P>
<P><FONT class=extract>#define __READ_ONCE(x, check)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>({&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;union { typeof(x) __val; char __c[1]; } __u;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;if (check)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;__read_once_size(&amp;(x), __u.__c, sizeof(x));&nbsp;&nbsp;\<BR>&nbsp;else&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;__read_once_size_nocheck(&amp;(x), __u.__c, sizeof(x));&nbsp;\<BR>&nbsp;__u.__val;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>})<BR>#define READ_ONCE(x) __READ_ONCE(x, 1)</FONT></P>
<P><FONT class=extract>/*<BR>&nbsp;* Use READ_ONCE_NOCHECK() instead of READ_ONCE() if you need<BR>&nbsp;* to hide memory access from KASAN.<BR>&nbsp;*/<BR>#define READ_ONCE_NOCHECK(x) __READ_ONCE(x, 0)</FONT></P>
<P><FONT class=extract>#define WRITE_ONCE(x, val) \<BR>({&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;union { typeof(x) __val; char __c[1]; } __u =&nbsp;\<BR>&nbsp;&nbsp;{ .__val = (__force typeof(x)) (val) }; \<BR>&nbsp;__write_once_size(&amp;(x), __u.__c, sizeof(x));&nbsp;\<BR>&nbsp;__u.__val;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>})</FONT></P>
<P>/**<BR>&nbsp;* smp_cond_acquire() - Spin wait for cond with ACQUIRE ordering<BR>&nbsp;* @cond: boolean expression to wait for<BR>&nbsp;*<BR>&nbsp;* Equivalent to using smp_load_acquire() on the condition variable but employs<BR>&nbsp;* the control dependency of the wait to reduce the barrier on many platforms.<BR>&nbsp;*<BR>&nbsp;* The control dependency provides a LOAD-&gt;STORE order, the additional RMB<BR>&nbsp;* provides LOAD-&gt;LOAD order, together they provide LOAD-&gt;{LOAD,STORE} order,<BR>&nbsp;* aka. ACQUIRE.<BR>&nbsp;*/<BR>#define smp_cond_acquire(cond)&nbsp;do {&nbsp;&nbsp;\<BR>&nbsp;while (!(cond))&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;cpu_relax();&nbsp;&nbsp;&nbsp;\<BR>&nbsp;smp_rmb(); /* ctrl + rmb := acquire */&nbsp;\<BR>} while (0)</P>
<P>#endif /* __KERNEL__ */</P>
<P>#endif /* __ASSEMBLY__ */</P>
<P>#ifdef __KERNEL__<BR>/*<BR>&nbsp;* Allow us to mark functions as 'deprecated' and have gcc emit a nice<BR>&nbsp;* warning for each use, in hopes of speeding the functions removal.<BR>&nbsp;* Usage is:<BR>&nbsp;* &nbsp;&nbsp;int __deprecated foo(void)<BR>&nbsp;*/<BR>#ifndef __deprecated<BR># define __deprecated&nbsp;&nbsp;/* unimplemented */<BR>#endif</P>
<P>#ifdef MODULE<BR>#define __deprecated_for_modules __deprecated<BR>#else<BR>#define __deprecated_for_modules<BR>#endif</P>
<P>#ifndef __must_check<BR>#define __must_check<BR>#endif</P>
<P>#ifndef CONFIG_ENABLE_MUST_CHECK<BR>#undef __must_check<BR>#define __must_check<BR>#endif<BR>#ifndef CONFIG_ENABLE_WARN_DEPRECATED<BR>#undef __deprecated<BR>#undef __deprecated_for_modules<BR>#define __deprecated<BR>#define __deprecated_for_modules<BR>#endif</P>
<P>#ifndef __malloc<BR>#define __malloc<BR>#endif</P>
<P>/*<BR>&nbsp;* Allow us to avoid 'defined but not used' warnings on functions and data,<BR>&nbsp;* as well as force them to be emitted to the assembly file.<BR>&nbsp;*<BR>&nbsp;* As of gcc 3.4, static functions that are not marked with attribute((used))<BR>&nbsp;* may be elided from the assembly file.&nbsp; As of gcc 3.4, static data not so<BR>&nbsp;* marked will not be elided, but this may change in a future gcc version.<BR>&nbsp;*<BR>&nbsp;* NOTE: Because distributions shipped with a backported unit-at-a-time<BR>&nbsp;* compiler in gcc 3.3, we must define __used to be __attribute__((used))<BR>&nbsp;* for gcc &gt;=3.3 instead of 3.4.<BR>&nbsp;*<BR>&nbsp;* In prior versions of gcc, such functions and data would be emitted, but<BR>&nbsp;* would be warned about except with attribute((unused)).<BR>&nbsp;*<BR>&nbsp;* Mark functions that are referenced only in inline assembly as __used so<BR>&nbsp;* the code is emitted even though it appears to be unreferenced.<BR>&nbsp;*/<BR>#ifndef __used<BR># define __used&nbsp;&nbsp;&nbsp;/* unimplemented */<BR>#endif</P>
<P>#ifndef __maybe_unused<BR># define __maybe_unused&nbsp;&nbsp;/* unimplemented */<BR>#endif</P>
<P>#ifndef __always_unused<BR># define __always_unused&nbsp;/* unimplemented */<BR>#endif</P>
<P>#ifndef noinline<BR>#define noinline<BR>#endif</P>
<P>/*<BR>&nbsp;* Rather then using noinline to prevent stack consumption, use<BR>&nbsp;* noinline_for_stack instead.&nbsp; For documentation reasons.<BR>&nbsp;*/<BR>#define noinline_for_stack noinline</P>
<P>#ifndef __always_inline<BR>#define __always_inline inline<BR>#endif</P>
<P>#endif /* __KERNEL__ */</P>
<P>/*<BR>&nbsp;* From the GCC manual:<BR>&nbsp;*<BR>&nbsp;* Many functions do not examine any values except their arguments,<BR>&nbsp;* and have no effects except the return value.&nbsp; Basically this is<BR>&nbsp;* just slightly more strict class than the `pure' attribute above,<BR>&nbsp;* since function is not allowed to read global memory.<BR>&nbsp;*<BR>&nbsp;* Note that a function that has pointer arguments and examines the<BR>&nbsp;* data pointed to must _not_ be declared `const'.&nbsp; Likewise, a<BR>&nbsp;* function that calls a non-`const' function usually must not be<BR>&nbsp;* `const'.&nbsp; It does not make sense for a `const' function to return<BR>&nbsp;* `void'.<BR>&nbsp;*/<BR>#ifndef __attribute_const__<BR># define __attribute_const__&nbsp;/* unimplemented */<BR>#endif</P>
<P>/*<BR>&nbsp;* Tell gcc if a function is cold. The compiler will assume any path<BR>&nbsp;* directly leading to the call is unlikely.<BR>&nbsp;*/</P>
<P>#ifndef __cold<BR>#define __cold<BR>#endif</P>
<P>/* Simple shorthand for a section definition */<BR>#ifndef __section<BR># define __section(S) __attribute__ ((__section__(#S)))<BR>#endif</P>
<P>#ifndef __visible<BR>#define __visible<BR>#endif</P>
<P>/*<BR>&nbsp;* Assume alignment of return value.<BR>&nbsp;*/<BR>#ifndef __assume_aligned<BR>#define __assume_aligned(a, ...)<BR>#endif</P>
<P><BR>/* Are two types/vars the same type (ignoring qualifiers)? */<BR>#ifndef __same_type<BR># define __same_type(a, b) __builtin_types_compatible_p(typeof(a), typeof(b))<BR>#endif</P>
<P>/* Is this type a native word size -- useful for atomic operations */<BR>#ifndef __native_word<BR># define __native_word(t) (sizeof(t) == sizeof(char) || sizeof(t) == sizeof(short) || sizeof(t) == sizeof(int) || sizeof(t) == sizeof(long))<BR>#endif</P>
<P>/* Compile time object size, -1 for unknown */<BR>#ifndef __compiletime_object_size<BR># define __compiletime_object_size(obj) -1<BR>#endif<BR>#ifndef __compiletime_warning<BR># define __compiletime_warning(message)<BR>#endif<BR>#ifndef __compiletime_error<BR># define __compiletime_error(message)<BR>/*<BR>&nbsp;* Sparse complains of variable sized arrays due to the temporary variable in<BR>&nbsp;* __compiletime_assert. Unfortunately we can't just expand it out to make<BR>&nbsp;* sparse see a constant array size without breaking compiletime_assert on old<BR>&nbsp;* versions of GCC (e.g. 4.2.4), so hide the array from sparse altogether.<BR>&nbsp;*/<BR># ifndef __CHECKER__<BR>#&nbsp; define __compiletime_error_fallback(condition) \<BR>&nbsp;do { ((void)sizeof(char[1 - 2 * condition])); } while (0)<BR># endif<BR>#endif<BR>#ifndef __compiletime_error_fallback<BR># define __compiletime_error_fallback(condition) do { } while (0)<BR>#endif</P>
<P>#define __compiletime_assert(condition, msg, prefix, suffix)&nbsp;&nbsp;\<BR>&nbsp;do {&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;bool __cond = !(condition);&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;extern void prefix ## suffix(void) __compiletime_error(msg); \<BR>&nbsp;&nbsp;if (__cond)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;&nbsp;prefix ## suffix();&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;__compiletime_error_fallback(__cond);&nbsp;&nbsp;&nbsp;\<BR>&nbsp;} while (0)</P>
<P>#define _compiletime_assert(condition, msg, prefix, suffix) \<BR>&nbsp;__compiletime_assert(condition, msg, prefix, suffix)</P>
<P>/**<BR>&nbsp;* compiletime_assert - break build and emit msg if condition is false<BR>&nbsp;* @condition: a compile-time constant condition to check<BR>&nbsp;* @msg:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; a message to emit if condition is false<BR>&nbsp;*<BR>&nbsp;* In tradition of POSIX assert, this macro will break the build if the<BR>&nbsp;* supplied condition is *false*, emitting the supplied error message if the<BR>&nbsp;* compiler has support to do so.<BR>&nbsp;*/<BR>#define compiletime_assert(condition, msg) \<BR>&nbsp;_compiletime_assert(condition, msg, __compiletime_assert_, __LINE__)</P>
<P>#define compiletime_assert_atomic_type(t)&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;compiletime_assert(__native_word(t),&nbsp;&nbsp;&nbsp;&nbsp;\<BR>&nbsp;&nbsp;"Need native word sized stores/loads for atomicity.")</P>
<P><FONT class=extract>/*<BR>&nbsp;* Prevent the compiler from merging or refetching accesses.&nbsp; The compiler<BR>&nbsp;* is also forbidden from reordering successive instances of ACCESS_ONCE(),<BR>&nbsp;* but only when the compiler is aware of some particular ordering.&nbsp; One way<BR>&nbsp;* to make the compiler aware of ordering is to put the two invocations of<BR>&nbsp;* ACCESS_ONCE() in different C statements.<BR>&nbsp;*<BR>&nbsp;* ACCESS_ONCE will only work on scalar types. For union types, ACCESS_ONCE<BR>&nbsp;* on a union member will work as long as the size of the member matches the<BR>&nbsp;* size of the union and the size is smaller than word size.<BR>&nbsp;*<BR>&nbsp;* The major use cases of ACCESS_ONCE used to be (1) Mediating communication<BR>&nbsp;* between process-level code and irq/NMI handlers, all running on the same CPU,<BR>&nbsp;* and (2) Ensuring that the compiler does not&nbsp; fold, spindle, or otherwise<BR>&nbsp;* mutilate accesses that either do not require ordering or that interact<BR>&nbsp;* with an explicit memory barrier or atomic instruction that provides the<BR>&nbsp;* required ordering.<BR>&nbsp;*<BR>&nbsp;* If possible use READ_ONCE()/WRITE_ONCE() instead.<BR>&nbsp;*/<BR>#define __ACCESS_ONCE(x) ({ \<BR>&nbsp; __maybe_unused typeof(x) __var = (__force typeof(x)) 0; \<BR>&nbsp;(volatile typeof(x) *)&amp;(x); })<BR>#define ACCESS_ONCE(x) (*__ACCESS_ONCE(x))</FONT></P>
<P>/**<BR>&nbsp;* lockless_dereference() - safely load a pointer for later dereference<BR>&nbsp;* @p: The pointer to load<BR>&nbsp;*<BR>&nbsp;* Similar to rcu_dereference(), but for situations where the pointed-to<BR>&nbsp;* object's lifetime is managed by something other than RCU.&nbsp; That<BR>&nbsp;* "something other" might be reference counting or simple immortality.<BR>&nbsp;*/<BR>#define lockless_dereference(p) \<BR>({ \<BR>&nbsp;typeof(p) _________p1 = READ_ONCE(p); \<BR>&nbsp;smp_read_barrier_depends(); /* Dependency order vs. p above. */ \<BR>&nbsp;(_________p1); \<BR>})</P>
<P>/* Ignore/forbid kprobes attach on very low level functions marked by this attribute: */<BR>#ifdef CONFIG_KPROBES<BR># define __kprobes&nbsp;__attribute__((__section__(".kprobes.text")))<BR># define nokprobe_inline&nbsp;__always_inline<BR>#else<BR># define __kprobes<BR># define nokprobe_inline&nbsp;inline<BR>#endif<BR>#endif /* __LINUX_COMPILER_H */